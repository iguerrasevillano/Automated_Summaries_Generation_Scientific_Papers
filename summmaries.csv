target,BART Greedy,BART Sampling,T5 Greedy,T5 Sampling
"A new framework based variational inference for out-of-distribution detection Describes a probabilistic approach to quantifying uncertainty in DNN classification tasks that outperforms other SOTA methods in the task of out-of-distribution detection. A new framework for out-of-distribution detection, based on variaitonal inference and a prior Dirichlet distribution, that reports state of the art results on several datasets. An out-of distribution detection via a new method to approximate the confidence distribution of classification probability using variational inference of Dirichlet distribution.","A variational Dirichlet framework for deep neural network classification. This work introduces a new uncertainty metric for image classification that is more accurate than existing uncertainty measures. The study presents a new dataset-based uncertainty measure for deep learning, which can be used to detect out-of-distribution examples. The authors investigate the problem of over-concentration in deep neural networks in order to address the problem.","A variational Dirichlet framework for deep neural network classification. This paper proposes a new uncertainty metric that can be used to identify in-and out-of-distribution examples. The authors propose a variational approach to classify images from both out-domain and in-domain regions of the dataset. This study proposes a variative Dirichlett framework for image classification which is more accurate than existing uncertainty measures, and proposes a method to address this problem.","A variational Dirichlet algorithm for deep neural networks classification problem and define a higher-order uncertainty measure. This work presents a variational dirichlet framework for deep network classification problem, which can greatly widen the distance between in-and out-of-distribution data to achieve significant results on various datasets and architectures. The authors present a variable label-wise distribution generated from a lower-order distribution over the simplex S k",A variational Dirichlet framework for deep neural network classification problem and a higher-order uncertainty measure. This work introduces a variational dirichlet algorithm to improve the accuracy of in-and out-of-distribution datasets by introducing a variable label-wise distribution P(y) over the simplex S k. The paper considers the image classification problem with image classification as x and output label as y.
"Unsupervised methods for finding, analyzing, and controlling important neurons in NMT This paper presents unsupervised approaches to discovering important neurons in neural machine translation systems and analyzes linguistic properties controlled by those neurons. Unsupervised methods for ranking neurons in machine translation where important neurons are thus identified and used to control the MT output.","An unsupervised method for analyzing the contribution of individual neurons to language translation. This paper presents a novel translation control method for language translation that uses a combination of neural networks and a hierarchical model. The authors present a novel approach to interpret language translation using a hierarchical network architecture, and show that neural networks are more interpretable than non-linear models.","An unsupervised method for analyzing the contribution of individual neurons to NMT models. This paper proposes a novel approach to interpret language between pairs of trained NMTs, proposing a novel translation control method based on modifying the activation of the neurons in each pair of neural networks. The authors propose a novel method for learning languages from neural networks that is able to predict the identity of the current token by modifying its activation.",An unsupervised method for analyzing the contribution of individual neurons to NMT models. This work introduces a novel translation control technique that can be used to predict tokens inside/outside of parentheses by modifying the activation of the tense neurons from previous section TAB2. The authors present an unsupervised translation control approach for learning a combination of linguistically interpretable vectors and canonical correlation analysis (PCA) and SVCCA.,An unsupervised approach for analyzing the contribution of individual neurons to NMT models. This work introduces a novel translation control method for translating neural networks into a vector space using a combination of multiple vectors and canonical correlation analysis. The authors study the role of tense neurons in the translation of linguistically interpretable neural networks by modifying the activation of the active neurons from the previous section TAB2.
We provide a theoretical study of the properties of Deep circulant-diagonal ReLU Networks and demonstrate that they are bounded width universal approximators. The paper proposes using circulant and diagonal matrices to speed up computation and reduce memory requirements in eural networks. This work proves that bounded width diagonal-circulent ReLU networks (DC-ReLU) are universal approximators.,"A deep diagonal-circulant ReLU network that can be decomposed into 4k + 1 diagonal and circulant matrices. This work presents a new method for training deep neural networks that can approximate deep ReLU networks with low rank approximators. This article presents a method to train deep neural nets with high rank decomposition of the matrix A, which can be used to approximate deep RecLU networks.",A deep diagonal-circulant ReLU network that can be decomposed into products of diagonal and circulant matrices This paper proposes to replace the weight matrix of a fully connected layer with a new matrix. The article proposes a method for building deep ReLU networks by replacing the weight matrices of the original layer with more compact weights. This work proposes a new approach to decompose the matrix of an unconnected layer into a new product of diagonal/circular matrices,"Using a deep neural network architecture that approximates the Johson-Lindenstrauss transform by replacing large weight matrices from fully connected layers with more compact circulant layers. This study introduces a method to replace the weight matrix of a fully connected layer with a circulant layer, which can be used for dimensionality reduction.",A deep neural network architecture that can approximate a deep ReLU network in which the dense matrices are of low rank. This study studies the applicability of a Deep diagonal-circulant ReLU networks by showing that any matrix can be decomposed into products of bounded width and small depth is more useful than the one by Huhtanen & Per«œm«œki because it can be used to approximate the first one.
"The most robust capacity for analogical reasoning is induced when networks learn analogies by contrasting abstract relational structures in their input domains. The paper investigates the ability of a neural network to learn analogy, showing that a simple neural network is able to solve certain analogy problems This study describes an approach to train neural networks for analogical reasoning tasks, specifically considering visual analogy and symbolic analogies.","A novel neural network architecture that can learn to make analogies with visual and symbolic inputs, but only if they are contrasted with alternative incorrect answers that are plausible at the level of relations rather than simple perceptual attributes. This work presents a novel approach to analogical reasoning in neural networks by proposing a new training regime for neural networks that is more naturalistic than human-like.","A novel neural network architecture that learns to make analogies with visual and symbolic inputs. This paper proposes a new approach to learning to use visual analogy, which is based on the idea of associative reasoning. The authors propose an approach to solving visual analogy problems by using visual analogy as a method for generating representations of objects.","An analogy-like model that learns from random candidates is perceptually plausible, so that the problem can be solved trivially by matching the correct answer to one of the answers. This work studies the problem of contrasting abstract relational structures in neural network architectures using an analogy regime and a novel approach to interpolation. The authors present a model for neural network learning from random candidate answers which uses a link between the two domains.","A neural network that learns from contrasting abstract relational structures on an analogical problem by using an analogy-like model architecture. This study investigates the problem of semantically plausible relational representations in a neural network, and shows that it is more likely to be used to solve an ananalogical problems. The authors present a model for neural networks that learn from random candidates who choose incorrect answers from the same domain as the correct answer."
"We propose a deep Multi Instance Learning framework based on recurrent neural networks which uses pooling functions and attention mechanisms for the concept annotation tasks. The work addresses the classification of medical time-series data and proposes to model the temporal relationship between the instances in each series using a recurrent neural network architecture. Proposes a novel Multiple Instance Learning (MIL) formulation called Relation MIL (RMIL), and discussed a number of its variants with LSTM, Bi-LSTM, S2S, etc. and explores integrating RMIL with various attention mechanisms, and demonstrates its usage on medical concept prediction from time series data.",A novel concept annotation task for medical time series data. This work introduces a novel task of predicting and localizing medical concepts by modeling the medical time-series data as input. The study presents a novel method to predict and localize medical concepts based on a combination of machine learning and deep learning models.,"A novel concept annotation task for medical time series data. This paper proposes a novel method for predicting and localizing medical concepts by using medical time-series data as input. The authors propose a novel application of machine learning models to medical information that can be used to predict and localize medical concepts. This work introduces a novel approach to the problem of describing medical concepts based on medical context, with the goal of incorporating medical context into the framework.","A new concept annotation task for medical time series data that can be used to predict and localize medical concepts. This work introduces a new concept-annotation task which can be applied to the medical data by generating medical information from the data. The authors address the problem of concept annotation for medical data, namely, when the data are not available or when the annotations are available they could be subjective and prone to human errors.","An annotation task for medical time series data, i.e., to localize medical concepts. This work introduces the concept annotation task as the problem of predicting and localizing medical concepts by using the medical data as input. The authors present a method for generating medical information from medical data such as intubation, extubation and resuscitate."
"We demonstrate that by leveraging a multi-way output encoding, rather than the widely used one-hot encoding, we can make deep models more robust to adversarial attacks. This work proposes replacing the final cross-entropy layer trained on one-hot labels in classifiers by encoding each label as a high-dimensional vector and training the classifier to minimize L2 distance from the encoding of the correct class. Authors propose new method against adversarial attacks that shows significant amount of gains compared to baselines","A novel multi-way encoding method for binary classification that relaxes and improves the encoding dimensionality. This paper introduces a multi-direction encoding method to reduce the number of possible gradients in binary classification. The authors introduce a new encoding method, called 1of K, which reduces the likelihood of adversarial attacks on binary classification models by reducing the complexity of the encoding.","A novel multi-way encoding method for binary classification that relaxes the adversarial gradient search. This paper proposes a multi-direction encoding method to reduce the number of possible gradients in binary classification by relaxing and increasing the encoding dimensionality. The authors propose a new multi-dimensional encoding method, based on 1of K and RO encodings, which reduces the likelihood of adversarial attacks.","A multi-way encoding framework that obstructs the adversarial gradient search. This work introduces a new attack for a binary model watermarking algorithm, which trains a model to misclassify at the final encoder layer. The authors present a multi-directional attack for both the source and target models, and demonstrate the strength of the approach.","A deep encoding framework that obstructs the adversarial gradient search. This study introduces a multi-way attack for both the source and target models, and shows that it is more efficient than one-hot (1of K) attacks. This work presents a deep learning framework that can be used to determine the direction of an input from the input to the blue class, or vice versa."
"We introduce Spherical CNNs, a convolutional network for spherical signals, and apply it to 3D model recognition and molecular energy regression. The paper proposes a framework for constructing spherical convolutional networks based on a novel synthesis of several existing concepts This article focuses on how to extend convolutional neural networks to have built-in spherical invariance, and adapts tools from non-Abelian harmonic analysis to achieve this goal. The authors develop a novel scheme for representing spherical data from the ground up","A spherical CNN that can detect patterns regardless of how they are rotated over the sphere. This article presents a new CNN for spherical signals that is equivariant to the rotation invariant properties of the sphere, and shows that it is more efficient than other CNNs. This work introduces a new class of CNNs, called spherical CNNs (S 2-CNNs), that can be used to detect patterns on the sphere and vice versa.","A spherical CNN that can detect patterns regardless of how they are rotated over the sphere. This paper proposes a method for detecting patterns on the sphere, which is equivariant to the rotation invariant properties of spherical CNNs. The article proposes a new network architecture based on the spherical correlation and describes it as an extension of the Wigner D-functions.","A spherical CNN that can detect patterns regardless of how they are rotated over the sphere. This work introduces a new group correlation function on the Sphere, which acts naturally on the input space of the network. The paper presents a method for detecting patterns in a three-dimensional manifold called SO(3) 2 and provides a simple definition of the SenseCNN (S2 -CNN).","A spherical CNN that can detect patterns regardless of how they are rotated over the sphere. This work introduces a new neural network to detect patterns in a three-dimensional manifold called SO(3) 2. The authors present a method for detecting patterns in the space of moves for the plane, and show that it is possible to find patterns on the plane with a 3D translation."
"Relational Forward Models for multi-agent learning make accurate predictions of agents' future behavior, they produce intepretable representations and can be used inside agents. A way of reducing variance in model free learning by having an explicit model, that uses a graph conv net-like architecture, of actions that other agents will take. Predicting multi-agent behavior using a relational forward model with a recurrent component, outperforming two baselines and two ablations","A deep reinforcement learning framework for understanding the dynamics of multi-agent systems. This work presents a novel approach to understanding the behavior of agents in multi-player games. The authors present an RFM module that learns to predict the actions of each agent in a game, and provide insights into the relational and social structures of the agents.","A deep reinforcement learning framework for understanding the dynamics of multi-agent systems. This paper proposes a novel RFM model that learns to predict the actions of each agent given the state of the environment. The authors propose an RFM framework for predicting the behavior of agents, and provide insights into how agents interact with each other in real-world settings.","A new model for multi-agent learning that predicts the forward dynamics of agents' systems, and provides insights into the relational and social structures present in the data. This work introduces a new algorithm to learn how agents interact with each other on a single agent basis, and presents a novel method for modeling agents' behavior as well as an analysis tool for characterizing their actions.","A deep learning model for multi-agent systems with a rich and orderly structure that can be leveraged to understand these systems, and to improve how artificial agents learn to operate in them. This study introduces a deep learning framework for multiagent system modeling behavior of multiple agents, and uses it to predict the forward dynamics of each agent's system. The authors present an analysis tool for characterizing interactions between different agents"
"We introduce a transparent middleware for neural network acceleration, with own compiler engine, achieving up to 11.8x speed up on CPUs and 2.3x on GPUs. This article proposes a transparent middleware layer for neural network acceleration and obtains some acceleration results on basic CPU and GPU architectures",Introduces a transparent middleware layer for neural network acceleration. This article introduces a new framework for deep neural networks acceleration that combines hardware-specific optimizations with deep learning frameworks. This work addresses the problem of optimizing neural networks on multiple hardware platforms by combining hardware and deep learning libraries. The authors introduce a new middleware framework for the optimization of both prediction and training of neural networks. This paper presents a method for optimizing neural network architectures on several hardware platforms,"Introduces a transparent middleware layer for neural network acceleration. This article introduces a new framework for deep learning that combines hardware-specific optimizations with deep learning frameworks. The authors propose a method to accelerate neural networks by combining hardware and deep learning libraries in order to speed up inference and training. This work proposes a new architecture for the optimization of neural networks, which can be easily integrated into existing frameworks.","This article introduces a transparent middleware layer for neural network acceleration, allowing one to combine device-specific libraries and custom optimizations while supporting numerous hardware devices. The authors address the problem of inference and inference in deep neural networks by using a compiler for deep learning that is transparent to the user and should support all hardware platforms and deep learning libraries.","This paper introduces a transparent middleware layer for neural network acceleration, allowing one to combine device-specific libraries and custom optimizations while supporting numerous hardware platforms. The authors address the problem of inference and inference in deep neural networks by using a compiler for deep learning frameworks, and show that it is transparent to the user and should support all hardware platforms and deep learning libraries."
"Agents interact (speak, act) and can achieve goals in a rich world with diverse language, bridging the gap between chit-chat and goal-oriented dialogue. This article studies a multiagent dialog task in which the learning agent aims to generate natural language actions that elicit a particular action from the other agent, and shows RL-agents can achieve higher task completion levels than imitation learning baselines. This work explores the goal-oriented dialogue setting with reinforcement learning in a Fantasy Text Adventure Game and observes that the RL approaches outperform supervised learning models.","Real-time dialogue agents are trained to imitate human actions given a goal (a ""goal-oriented"" model). This work presents a novel approach to solving the problem of language drift in video game dialogue by using a large transformer architecture. The authors present a novel model of dialogue agents that can be used to learn to communicate with other agents in a multi-player setting.","Real-time dialogue agents are trained to imitate human actions given a goal (an ""inverse model"") This paper proposes a novel approach to improving the quality of real-time dialog in video games. The authors propose a new approach to dialogue, where an agent is tasked with answering questions given by a user, and then learns to use that information to solve a task.","In the literature on artificial dialogue agents, a distinction is often made between ""goal-oriented"" dialogue, where an agent is tasked with filling slots or otherwise obtaining or disseminating specified information from the user to help complete a task, and ""chit-chat"". The authors present a cluster of human-written game actions that are trained to imitate human actions given a goal (an ""inverse model"")","A new algorithm for artificial dialogue agents that can be trained to imitate human actions given a goal. This work introduces a cluster of AI models, which can be used to improve the quality of the textual descriptions of the world. The authors study the problem of artificial dialogue agent training with self-chat, and show that it is possible to use a set of AI Models as a baseline for comparing them to a RL model."
"CharNMT is brittle This paper investigates the impact of character-level noise on 4 different neural machine translation systems This study empirically investigates the performance of character-level NMT systems in the face of character-level noise, both synthesized and natural. This study investigates the impact of noisy input on Machine Translation and tests ways to make NMT models more robust","A novel character-based CNN model that learns to address synthetic noise by training on noisy texts. This study investigates the problem of synthetic noise generation in NLP and shows that it is more robust to natural human errors than the meanChar model. The authors investigate the issue of natural human noise generation, and show that a character based CNN can learn to address multiple types of noise in a sentence.","A novel character-based CNN model that learns to address multiple types of natural noise in a given sentence. This paper presents a novel method for learning to deal with natural noise, and proposes a novel way of doing so. The authors propose a new neural network which learns to handle natural noise by training it on a variety of different kinds of noise.","A charCNN model that is more robust to different kinds of noise, by training on noisy texts. This work introduces a charcNN-based approach to solving the problem of typos and noise in a text-based way. The authors present a new method for learning a word-to-word translation using a combination of a single key and a two-step process to solve the problems of language-specific errors.","A charCNN model that is more robust to different kinds of noise, by training on noisy texts. This study studies the robustness of text translations in a Wrot-like language, and shows that it can be used to address typos and noise. The authors introduce a charcNN model which uses a keyboard type to detect errors in the first and last letters, and show that it performs well on Key in French, but not elsewhere."
"Feedforward neural networks that can have weights pruned after training could have had the same weights pruned before training Shows that there exists sparse subnetworks that can be trained from scratch with good generalization performance and proposes a unpruned, randomly initialized NNs contain subnetworks that can be trained from scratch with similar generalization accuracy. The study examines the hypothesis that randomly initialized neural networks contain sub-networks that converge equally fast or faster and can reach the same or better classification accuracy","An iterative pruning strategy for improving the accuracy and validation accuracy of a fully-connected neural network with a small number of parameters. This study studies the problem of pruning neural networks using stochastic gradient descent, and shows that it is more difficult to find winning tickets than prior pruning strategies. This article presents a method for finding winning tickets for neural networks with a large number of parameter sets.","An iterative pruning strategy for improving the accuracy and validation accuracy of a fully-connected hyperparameter. This article proposes an iterative method for optimizing hyperparameters with low validation accuracy and faster early-stopping times to smaller network sizes. This study studies the problem of iterative random pruning in hyperparametrics, and shows that it is possible to improve the accuracy of these architectures by reducing the number of training iterations necessary to get to smaller networks.","A method for iterative pruning of a fully-connected network. This article considers the problem of training a pruned model with a small capacity. The authors present a method for learning pruned models from scratch, and use it as a proxy for the speed at which a network learns. The paper presents a strategy to improve validation accuracy in an early-stopping manner.","A method to train a pruned network with a small capacity. The authors use iterative pruning as a proxy for the speed at which a network learns, but not after re-initializing the pruned layers and retraining them. This article considers the problem of training a fully connected network on a pruning task like MNIST."
"A new regularization term can improve your training of wasserstein gans The work proposes a regularization scheme for Wasserstein GAN based on relaxation of the constraints on the Lipschitz constant of 1. The work deals with regularization/penalization in the fitting of GANs, when based on a L_1 Wasserstein metric.","A novel GAN-GP that penalizes the deviation of the gradient norm of the critic function (as a function of the network's input) from one, was proposed as an alternative that improves training. This work introduces a new GAN algorithm for generating real-looking data points by using alternating gradient descent updates. The authors introduce a new algorithm called WGAN-GP which penalizes deviations of the gradients of the discriminator function with respect to its input.","Improving GAN training with a regularization term that penalizes the deviation of the gradient norm of the critic (as a function of the network's input) from one, was proposed as an alternative that improves training. This paper proposes to improve GAN-GP by reducing the Wasserstein-1 distance between the generator and the discriminator networks.","A GAN-based regularization term that penalizes the deviation of the norm of the critic function (as a function of the network's input) from one. This work presents a method to improve GAN training by reducing the infimum and minimizing the Wasserstein-1 distance, which can be achieved by alternating gradient descent updates for the generator and the 1-Lipschitz function f.","A new training method for generating GANs by increasing the loss by regularization term that penalizes the deviation of the norm of the critic function (as a function of the network's input) from one. This work presents a new training technique to improve GAN training, with the aim of reducing the infimum by minimizing the Wasserstein-1 distance on Earth-Mover distance."
"DeFINE uses a deep, hierarchical, sparse network with new skip connections to learn better word embeddings efficiently. This article describes a new method for learning deep word-level representations efficiently by using a hierarchical structure with skip-connections for the use of low dimensional input and output layers.","A hierarchical group embedding method for deep neural networks. This work introduces a hierarchical group-based embedding framework that enables deep neural network representations to be learned jointly while reducing the number of parameters. The authors introduce a new embedding matrix, called DeFINE, to improve the performance of deep neural models by reducing the computational overhead.","Improving the performance of deep neural networks by incorporating a new connectivity pattern that establishes a direct link between the input and output layers. This work proposes a hierarchical group transformation method for deep neural network embeddings, where the input layer is connected to the output layer via a hierarchical connection. The authors propose a novel embedding method for learning deep neural representations from different subsets of the input vector.","This article introduces a new adaptive embedding method for learning input and output representations jointly while significantly reducing the number of parameters presented by these layers. The authors introduce a weight-tying mechanism that allows for faster, memory-efficient end-to-end training while providing similar or better benefits compared to existing post-training methods which require a hierarchical group transformation (HGT) to learn deep representations efficiently using sparse and dense connections.","This work introduces a new layer-to-layer approach for learning input and output representations jointly while significantly reducing the number of network parameters. The authors address the problem of learning representations from different subsets of the first layer using sparse and dense connections, allowing HGT to learn deep representations efficiently by learning a hierarchical link between the input layers and the output layers."
"We prove fluctuation-dissipation relations for SGD, which can be used to (i) adaptively set learning rates and (ii) probe loss surfaces. Paper's concepts work in the discrete-time formalism, use the master equation, and remove reliance on a locally quadratic approximation of the loss function or on any Gaussian asumptions of the SGD noise. The authors derive the stationary fluctuation-dissipation relations that link measurable quantities and hyperparameters in SGD and use the relations to set training schedule adaptively and analyze the loss-function landscape.",This study studies the fluctuation-dissipation relations of a stationary-state distribution in SGD and shows that they can be used to determine the shape of the loss-function landscape. This work studies the effect of noise on the learning rate of a stochastic gradient on the training rate of an SGD model. The authors investigate the existence of a non-Gaussian distribution in the loss function landscape of a Gaussian model,"This paper studies the fluctuation-dissipation relations of noise in mini-batched data and proposes a method for measuring the noise distribution at each time step during training. This article analyzes the behavior of the noise distributions in real-world models by studying the dynamics of the loss-function landscape. The authors propose a new way of measuring the stochastic momentum of a model that is not dependent on the stationary distribution, and show that it is more stable than the stationary one.","An analogous fluctuation-dissipation relation that quantitatively link the noise in mini-batched data to the observable evolution of the model performance. This work introduces a new lossfunction landscape with a two-point noise matrix, which can be used to test stationarity and delineate the shape of the landscape.","This work introduces an analogy of fluctuation-dissipation relations that quantitatively link the noise in mini-batched data to the evolution of the model performance and facilitates the learning process. The authors present a method for determining the properties of the lossfunction landscape, including the strength of its Hessian counterpart and the degree of anharmonicity."
"We show that NN parameter and hyperparameter cost landscapes can be generated as quantum states using a single quantum circuit and that these can be used for training and meta-training. Describes a method where a deep learning framework can be quantised by considering the two state form of a Bloch sphere/qubit and creating a quantum binary neural network. This work proposes quantum amplitude amplification, a new algorithm for training and model selection in binary neural networks. Proposes a novel idea of outputting a quantum state that represents a complete cost landscape of all parameters for a given binary neural network, by constructing a quantum binary neural network (QBNN).","Quantum neural network architecture based on a quantum gate-based form of quantum computation as opposed to the classical annealing devices of the past. This work presents a novel method for learning the state of a neural network using binary activation functions, which can be used to train neural networks in parallel. The authors present a new approach to learning a representation of the landscape of a deep neural network by using a binary activation function.","Quantum neural network architecture based on a quantum gate-based form of computation. This paper proposes a novel approach to learn the state of a neural network by using a binary activation function, which can be used to train a deep neural network in parallel. The authors propose a new type of machine learning architecture that is more general than classical neural networks and uses binary activation functions.","This paper introduces a new method for binary classification using a gate-based quantum computation. The article presents a novel way to train binary qubits in the form of qRAM, which is based on a different, more general form of quantum computation as opposed to the latter.","A quantum annealing device that takes in a given set of weights and an empty register, and outputs the resultant accuracy according to the chosen neural network. This work introduces a new gate-based quantum computation method for binary qubits, which is used to perform binary classification, and shows that it can be used to train binary quebits by using a reversibility gate."
"Transfer learning for estimating causal effects using neural networks. Develops algorithms to estimate conditional average treatment effect by auxiliary dataset in different environments, both with and without base learner. The authors propose methods to address a novel task of transfer learning for estimating the CATE function, and evaluate them using a synthetic setting and a real-world experimental dataset. Using neural network regression and comparing transfer learning frameworks to estimate a conditional average treatment effect under string ignorability assumptions","A meta-learning method for transfer learning that can speed up the transfer process. This paper presents a method for transferring data from one dataset to another in order to obtain a more accurate estimate of the true CATE for each sample. The study presents a meta learning method to transfer data from a dataset to a new dataset, which is then used to generate a CATE estimator.","Transfer learning for voter persuasion based on real data This paper proposes a meta-learning method to evaluate transfer learning in the context of voter persuasion. The authors propose a new method for transfer learning that is more efficient and faster than current methods. The article proposes a method for transferring information from a sample of MNIST digits to a different sample of samples, which can be used to generate a CATE estimator.","A method for assessing transfer learning for CATE estimation on real data. This article presents a method to evaluate transfer learning in observational studies, where the number of covariates is large. The authors introduce a new network layer that can be used to train DGPs with memory to solve forgetting during transfer by using lateral connections to existing frozen layers. This study explores the problem of learning CATEs from a set of large field experiments.","A method for evaluating CATE estimation on real data that can be used in observational studies. This work presents a method for learning CATEs from the perspective of transfer learning by combining them with non-parametric methods. The authors introduce a new algorithm to learn features from the label presented in the image X, and show that it is possible to train CATE models using a set of different input functions."
"We show that catastrophic forgetting occurs within what is considered to be a single task and find that examples that are not prone to forgetting can be removed from the training set without loss of generalization. Studies the forgetting behavior of training examples during SGD, and shows there exist ""support examples"" in neural network training across different network architectures. This study analyzes the extent to which networks learn to correctly classify specific examples and then forget these examples over the course of training. The study studies whether some examples in training neural networks are harder to learn than others. Such examples are forgotten and relearned multiple times through learning.","Unforgettable examples can be learned during training, while others are forgotten during training. This study investigates the phenomenon of forgetting events in deep neural networks and investigates the correlation between forgetting statistics and the intrinsic dimension of the learning problem. The authors investigate the relationship between forgetting events and generalization performance of deep neural architectures, and show that forgetting events can be used to identify ""important"" samples.","Unforgettable examples can be learned during training, while unforgettable examples are not. This study investigates the forgetting process in deep neural networks and proposes a new metric for forgetting examples that can be used to identify ""important"" samples and detect outliers and examples with noisy labels. The authors propose a new approach to learning unforgettable examples by using forgetting statistics to identify which examples are forgotten during training.","A method for identifying important, or most informative examples that are never forgotten once learnt. This work investigates the problem of forgetting dynamics in neural networks by studying the extent to which a neural network learns unforgettable examples. The authors present a method for learning memorable examples that can be used to identify ""important"" samples and detect outliers and examples with noisy labels.","An implicit regularization method for learning unforgettable examples, based on forgetting dynamics, to identify important or most informative examples. This study investigates the problem of learning outliers with noisy labels in a neural network and shows that it is possible to find out how many memorable examples are forgotten once learnt. The authors address the issue of learning unimportant examples as a result of a linearly separable learning process."
"A class of networks that generate simple models on the fly (called explanations) that act as a regularizer and enable consistent model diagnostics and interpretability. The authors claim that the previous art directly integrate neural networks into the graphical models as components, which renders the models uninterpretable. Proposal for a combination of neural nets and graphical models by using a deep neural net to predict the parameters of a graphical model.",CENs are competitive with the state-of-the-art for image and text classification and survival analysis tasks. This work introduces a new class of probabilistic models that can be used to generate explanations for complex data. The study presents a new framework for understanding the explanations generated by a deep neural network in order to improve interpretability.,"CENs are a probabilistic framework for image and text classification and survival analysis tasks. This paper proposes a new class of deep neural networks based on context-specific explanations, which can be used to improve interpretability. The authors propose a method for generating explanations that is more suitable for the task of survival analysis than prior methods.","A novel algorithm for image and text classification and survival analysis. This work introduces a novel algorithm to interpret explanations by using a domain-specific deep architecture. The authors present a method for learning the decision boundary of a prediction model, which can be used in a social context, and show that post-hoc approximations of CEN's decision boundary are consistent with the generated explanations.","Using a domain-specific deep architecture for image and text classification and survival analysis, our results demonstrate that CENs are competitive with the state-of-the-art while offering additional insights behind each prediction, valuable for decision support. This work introduces a class of probabilistic models to be used in a social context, demonstrating that post-hoc approximations of CEN's decision boundary are consistent with the generated explanations."
"We proposed ""Difference-Seeking Generative Adversarial Network"" (DSGAN) model to learn the target distribution which is hard to collect training data. This study presents DS-GAN, which aims to learn the difference between any two distributions whose samples are difficult or impossible to collect, and shows its effectiveness on semi-supervised learning and adversarial training tasks. This paper considers the problem of learning a GAN to capture a target distribution with only very few training samples from that distribution available.","Generative approaches are developed for learning data distribution from its samples and thereafter produce novel and high-dimensional samples from learned distributions, such as image and speech synthesis BID18 ). This work introduces a new GAN, DSGAN, which learns a mixture distribution from the data generated by the generator and discriminator. The work presents a new method for generating samples from the generated data that is suitable for semi-supervised learning.","Generative approaches are developed for learning data distribution from its samples and thereafter produce novel and high-dimensional samples from learned distributions, such as image and speech synthesis BID18 ). This paper proposes a method to train GANs that learns the generator distribution p g under mild conditions. The authors propose a new method for training GAN based on the mixture distribution of the generator and the discriminator in a semi-supervised manner.","A GAN prone generator to output samples located in high-density areas of pd, and adversarial training requires a bad GAN for semi-supervised learning. This work introduces a GAN that learns the mixture distribution of the generator and the generator distribution by minimizing the statistical distance between the two support sets. The paper presents a method for training GANs with the ability to learn different target distributions","A Generative Approach for learning data distribution from its samples and thereafter produce novel and high-dimensional samples from its learned distributions, such as image and speech synthesis. This work introduces a GAN method to learn the generator distribution from mixed distributions and shows that it is more stable to train DSGAN in a semi-supervised environment."
"We present NormCo, a deep coherence model which considers the semantics of an entity mention, as well as the topical coherence of the mentions within a single document to perform disease entity normalization. Uses a GRU autoencoder to represent the ""context"" (related enitities of a given disease within the span of a sentence), solving the BioNLP task with significant improvements over the best-known methods.","Improving disease normalization with a combination of semantic features and topical coherence. This work presents a novel method for improving the accuracy and predictive quality of biomedicine by combining two different approaches. The authors present a new approach to disease normalizing that combines semantic features with coherence, which improves the accuracy of the previous methods.","Improving disease normalization with two sub-models. The authors propose a novel method for improving the accuracy and coherence of biomedicine by combining two different approaches. This paper proposes a new approach to disease normalizing based on a combination of semantic features, coherence, and contextual coherence. This article presents a novel approach to problem of diseases normalization that leverages both semantic features and context information in order to improve the accuracy of the existing methods.","A combination of two sub-models which leverage both topical coherence and semantic features to perform disease normalization. This work focuses on the problem of disease normalisation, an essential step in the construction of a biomedical knowledge base as diseases are central to biomedicine.","A biomedical knowledge base with a combination of two sub-models which leverage both topical coherence and semantic features to perform disease normalization. This work presents a novel method for addressing the problem of disease normization by combining two datasets of distantly supervised data, extracted through two corpora of scattered datasets created for non-normalization purposes."
"We present a single shot analysis of a trained neural network to remove redundancy and identify optimal network structure This article proposes a set of heuristics for identifying a good neural network architecture, based on PCA of unit activations over the dataset This work presents a framework for optimising neural networks architectures through the identification of redundant filters across layers","This article analyzes all layers of neural networks in a single shot and identifies an optimal structure in terms of both width and depth, without any iterative searches for thresholds. This article presents a method for segmenting neural networks based on the number of significant filters in each layer of the network. The authors present a method to reduce the dimensionality of a neural network by reducing its number of 'principal filters'.","A method for reducing the number of significant filters in a single shot and identifying an optimal structure in terms of both width and depth, without any iterative searches for thresholds. This paper analyzes all layers of neural networks in one shot and identifies the optimal structure for each layer. The authors propose a method to reduce the size of the filter space in order to improve the performance of the network.","This paper introduces a new method for determining the number of significant filters in a subset selection problem. The authors address the problem of pruning out a particular filter and retraining the system to reduce the dimensionality of the space that the data resides in after passing through a layer. This work presents a novel approach to identifying a network structure that has many principal filters, and uses it as a starting point to fine tune the network.","A new neural network with a number of principal filters and retrain from scratch. This work explores the problem of pruning out a particular filter to reduce the dimensionality of the space that the data resides in after passing through a layer, and shows that the number of significant filters is an intrinsic property of a specific network structure."
"The first deep learning approach to MFSR to solve registration, fusion, up-sampling in an end-to-end manner. This study proposes an end-to-end multi-frame super-resolution algorithm, that relies on a pair-wise co-registrations and fusing blocks (convolutional residual blocks), embedded in a encoder-decoder network 'HighRes-net' that estimates the super-resolution image. This article proposes a framework including recursive fusion to co-registration loss to solve the problem of super-resolution results and high-resolution labels not being pixel aligned.","A deep learning framework that solves the co-registration, fusion and registration-at-loss problems in an end-to-end learning framework. This work introduces a deep learning approach to solve the problem of single image super-resolution (MFSR) by combining two differentiable registration and registration components. The authors present a deep-learning framework for multi-image super-resolution that combines multiple low-resolution images into one image.","Single Image Super-Resolution (SISR), as a special case of MFSR, has attracted much attention in the computer vision, machine learning and deep learning communities in the last 5 years, with neural networks learning complex image priors to upsample and interpolate images (Xu et al., 2014; Srivastava et al. 2015) and generating super-resolution images for end-to-end training. This article presents a novel deep learning framework that solves the co-registration, fusion and registration-at-the-loss problems of single image super-resolution (MFSR).","This work introduces a deep-learning approach that solves the co-registration, fusion and registration-at-theloss problems in an end-to-end learning framework. The authors present a single image super-resolution system that can be paired with HighRes-net to account for pixel and sub-pixel shifts in the loss.","This paper introduces a deep-learning approach that solves the co-registration, fusion and registration-at-theloss problems in an end-to-end learning framework. The authors address the problem of single image super-resolution (SISR) with a new loss mechanism that can be used to learn high-frequency representations during training."
We introduce a technique that allows for gradient based training of quantized neural networks. Proposes a unified and general way of training neural networks with reduced precision quantized synaptic weights and activations. A new approach to quantizing activations which is state of the art or competitive on several real image problems. A method for learning neural networks with quantized weights and activations by stochastically quantizing values and replacing the resulting categotical distribution with a continuous relaxation,Stochastic rounding can be used to reduce the precision of neural network quantization. This paper introduces a new method for quantizing neural networks with reduced numerical precision. The authors present a method for reducing numerical precision of a neural network by using a stochastic rounding procedure. This work presents a method to reduce numerical precision in neural networks by reducing the number of quantization operations in the network.,"Stochastic rounding can be used to reduce the precision of neural network quantization. This paper proposes a method for quantizing neural networks with stochastic rounding in which the quantizer selects the two closest grid points with probability depending on the distance between the weights and activations. The authors propose a new method for training neural networks that is more efficient than the current method, based on a deterministic rounding procedure.","A method for quantizing neural networks with a stochastic rounding that can be seen as a special case of the proposed approach. This article introduces a method to quantize neural networks by using a ""soft"" quantizer, which is used to train the network in a manner that corresponds to discretizing p(x) onto the input signal and then sampling grid points g i from it.",A method for quantizing neural networks with a stochastic rounding that can be seen as a special case of the proposed approach. This study presents a method to quantize neural networks by reducing the precision of the arithmetic operations in the network. The paper introduces a novel quantization method for determining the distribution of the input signal and then sampling grid points from it.
"Interpretation by Identifying model-learned features that serve as indicators for the task of interest. Explain model decisions by highlighting the response of these features in test data. Evaluate explanations objectively with a controlled dataset. This paper proposes a method for producing visual explanations for deep neural network outputs and releases a new synthetic dataset. A method for Deep Neural Networks that identifies automatically relevant features of the set of the classes, supporting interpretation and explanation without relying on additional annotations.","An automatic neural network prediction method based on feature selection This paper introduces a method to predict the class of interest of a given neural network in a given dataset. The authors present a method for predicting a class using a network-encoded feature label, which provides a visual explanation of the predicted class of an image.",A method for generating explanations for a given class of interest based on feature selection. This paper proposes an automatic method to generate explanations for classes of interest using neural network-encoded features that are important for the prediction of the class. The authors propose a method to provide explanations for different classes of generative models by using a neural network encoder and a filter-wise response in order to identify the relevant filters.,"A method for identifying the top-responding filters that are important for the prediction of a given class of interest. This paper introduces a method to automatically identify the network-encoded features that serve as indicators for the classification of the classes of interest to be predicted using heatmap visualizations. The authors present a novel algorithm for defining the class label of an image, a set of identified filters and a class prediction.","A method to automatically identifie the network-encoded features that are important for the prediction of a given class. This work introduces a method for identifying the class of interest in an image, a set of identified relevant filters, and a class prediction using heatmap visualizations of the top-responding relevant filters for the predicted class."
"A method that build representations of sequential data and its dynamics through generative models with an active process Combines neural networks and Gaussian distributions to create an architecture and generative model for images and video which minimizes the error between generated and supplied images. The paper proposes a Bayesian network model, realized as a neural network, that learns different data in the form of a linear dynamical system",A novel machine learning architecture that learns to adapt to changing dynamics in the environment. This work presents a novel model of machine learning that is able to learn to adapt dynamically to changing environments. The authors present a method for learning a generative model of the environment by learning a latent representation of the inputs and the dynamics of the data.,Generative adversarial networks (GANs) can learn to adapt to changing situations. This work proposes a new architecture for generating generative models of data that is able to adapt dynamically to changing environments. The authors propose a novel approach to learning the dynamics of neural networks based on observations made in an environment where the inputs and outputs are adapted to different conditions.,"A hierarchical model for generative adversarial networks (GANs), where the inputs are constant and the representations have to adapt to the input over several iterations. This work introduces a hierarchic architecture that uses an encoder to determine how the observations change over time. The authors present a method for defining the dynamics of interactions in a latent space, which can be understood as the transition from Z t to Z T+1","A new model for generative adversarial networks that is capable of adapting to changing scenarios. This work introduces a hierarchical architecture where the activations of layers at the same level of a coder and a generator are laterally used to send information about the last prediction during inference, and about the inference for the generation of data."
"Obtains state-of-the-art accuracy for quantized, shallow nets by leveraging distillation. Proposes small and low-cost models by combining distillation and quantization for vision and neural machine translation experiments This article presents a framework of using the teacher model to help the compression for the deep learning model in the context of model compression.","Quantized distillation and leverages distillation during the training process, by incorporating distillation loss, expressed with respect to the teacher, into the training of a student network whose weights are quantized to a limited set of levels. This work introduces a new method for distillation of deep neural networks, where the weight is quantized in order to improve the accuracy of the model.","Quantized distillation and compression for deep teacher models This paper proposes a new method to compress deep teacher networks, which leverages distillation during the training process, by incorporating distillation loss, expressed with respect to the teacher, into the training of a student network whose weights are quantized to a limited set of levels. The authors propose two methods for reducing the number of layers in a deep teacher model to reduce the amount of layers that can be quantized.","A method for quantized distillation and leverages distillation in the training process by incorporating distillation loss, expressed with respect to the teacher, into the training of a student network whose weights are quantized to a limited set of levels. This study introduces a method to quantize weights of the student's weights in a quantized model, and shows that quantization can provide better compression than a distillation process.","A method for incorporating distillation loss, expressed with respect to the teacher, into the training of a student network. This study introduces a method for quantizing and leveraged distillation in the training process by incorporating it into the learning process. The authors present two methods for combining full-precision and deep neural networks with compression in terms of depth, and show that quantized shallow students can reach similar accuracy levels to full-presence and deeper teacher models."
"We use question-answering to evaluate how much knowledge about the environment can agents learn by self-supervised prediction. Proposes QA as a tool to investigate what agents learn about in the world, arguing this as an intuitive method for humans which allows for arbitrary complexity. The authors propose a framework to assess representations built by predictive models that contain sufficient information to answer questions about the environment they are trained on, showing those by SimCore contained sufficient information for the LSTM to answer questions accurately.","A question-answering evaluation paradigm for agents trained to answer questions about the environment. The study presents a method for answering questions from an environment-based exploration objective by using a QA decoder trained on the agent's internal memory. This work investigates the problem of answering questions in a context where the agent is learning to understand the environment, and shows that QA can be used to train agents to answer more complex questions than previously thought.",A question-answering evaluation paradigm based on the agent's internal memory. This paper proposes a method for answering questions about the environment in which agents are trained to encode relevant aspects of the environment into their internal representations. The authors propose a new approach to answering questions from an exploration objective by using a QA decoder that is trained independent of the agent policy and can be easily decoded as answers to questions.,QA decoders are trained to extract complex high-level information from the agent's internal state. This work introduces a new auxiliary network that learns to encode relevant aspects of the environment in a way that is self-supervised by a loss on the agentÉ??s future prediction against the ground-truth egocentric observation at tk.,"QA performance is indicative of the agent's ability to capture global environment structure and semantics solely through egocentric prediction. This work introduces a novel decoder network that learns to encode relevant aspects of the environment in a representation amenable to easy decoding into symbols. The authors use question-answering as a general purpose answer for higher-order conceptual knowledge, which can be used to solve complex questions about the environment."
"We train with state aligned vector rewards an agent predicting state changes from action distributions, using a new reinforcement learning technique inspired by quantile regression. Presents algorithm that aims to speed up reinforcement learning in situations where the reward is aligned with the state space. This study addresses RL in the continuous action space, using a re-parametrised policy and a novel vector-based training objective. This study proposes to mix distributional RL with a net in charge of modeling the evolution of the world in terms of quantiles, claiming improvements in sample efficiency.","A deep reinforcement learning algorithm that approximates the quantile functions of the action dimensions in a d-dimensional hypercube. This article introduces a new reinforcement learning method for training agents on vector rewards using quantile regression. This work introduces a deep neural network architecture to train agents on vectors with a quantile function, and shows that it can be trained faster than other methods.","A deep reinforcement learning algorithm that learns to approximate the quantile functions of state aligned vector rewards. This paper proposes a new reinforcement learning method for training convolutional neural networks based on state aligned action and quantile function. The authors propose a new approach to train convolutionary neural networks using quantile regression in combination with deep learning. This article proposes a method to learn a quantile-based policy for convolutionally defined actions in a d-dimensional hypercube, where the action probability distribution is implicitly defined.","A new reinforcement learning algorithm to train stochastic continuous action policies with arbitrary action probability distributions. This article introduces a novel reinforcement learning approach to learn a quantile function of the action dimensions and the quantile functions of the actions. The paper presents a method for learning a state-to-state vector reward from two samples of the same network, which can be used to train a deep neural network to approximate the action probability functions.",A deep reinforcement learning algorithm to train stochastic continuous action policies with arbitrary action probability distributions. This work introduces a new reinforcement learning architecture that learns the quantile function of the action dimensions and state space in order to maximize the expected (discounted) reward. The authors extend the reinforcement learning paradigm to allow for faster training based on more informative state aligned vector rewards.
"Learn representations for images that factor out a single attribute. This work builds on Conditional VAE GANs to allow attribute manipulation in the synthesis process. This paper proposes a generative model to learn the representation which can separate the identity of an object from an attribute, and extends the autoencoder adversarial by adding an auxiliary network.","A novel convolutional GAN architecture that learns to factor attributes out of the latent space in order to achieve competitive scores on a facial attribute classification task. This article introduces a new convolutionAL GAN, IFcVAE-GAN, which learns a latent space representation that separates an object category from its attributes. This work presents a novel Convolutional Generative Adversarial Ecosystem (VAE) model that learns an auxiliary classifier to factorize the representation. The authors present a convolutionial GAN based on the VAE, which can be used for image attribute synthesis.","Information Factorization (VAE) is an information factorization technique for image attribute manipulation. This paper proposes a novel VAE-GAN model that learns to factor attributes out of the latent space representation in order to achieve competitive scores on facial attribute classification tasks. The study proposes a new convolutional GAN architecture for image attributions, which can be used to factor labels out of latent space representations. This work proposes an Information Factorization approach to image attribute editing by incorporating information factors into the VAE.","A VAE-GAN that learns a latent space representation that separates an object category from its attributes. The authors introduce a VAE architecture for image synthesis that is competitive with state of the art. This article presents a new VAE model for image attribute manipulation, where label information is partially contained in rather than solely in y.","This paper introduces a VAE-GAN for image synthesis that is more competitive with state of the art. The authors introduce a new convolutional GAN, DCGAN, architecture to improve classification results. This work introduces an IFcVAE-gAN which can be trained in a latent space representation that separates an object category from its attributes and performs better than fine-grain image manipulation."
We take face recognition as a breaking point and propose model distillation with knowledge transfer from face classification to alignment and verification This work proposes to transfer the classifier from the model for face classification to the task of alignment and verification. The manuscript presents experiments on distilling knowledge from a face classification model to student models for face alignment and verification.,"A method for distillation of knowledge in face alignment and verification by transferring the distilled knowledge from the teacher network to the student network. This work introduces a new distillation method for face alignment, which uses a common initialization trick to further boost the distillation performance of the teacher networks. The study presents a method to distill knowledge from a teacher network into a deep ResNet-50/8 model.","A method for distillation of knowledge in face alignment and verification. This paper proposes to distill knowledge from the teacher network into a deep ResNet-50/8 model. The authors propose a new distillation method, ResNet 50/8, that uses a common initialization trick to boost the distillation performance of the ResNet network.","A method to distill knowledge from the teacher network by distilling its soft-prediction, which is effective in face alignment and verification. This work presents a method for distillation of classifiers using a distillation trick to boost the distillation performance of classification. The paper introduces a new distillation method that initializes the deep layers of the student network by regressing the mid-level target of the school network.","A method to distill the knowledge from the teacher network by learning its soft-prediction. This work introduces a new distillation method for face classification, which uses a distillation trick to improve the distillation performance of classifying tasks. The authors present a method for distillation of the knowledge in face alignment and verification by transferring it from the classifier to the instructor network. Presents an initialization method for class classification tasks with the same data and identity labels."
"New state-of-the-art framework for image restoration The paper proposes a convolutional neural network architecture that includes blocks for local and non-local attention mechanisms, which are claimed to be responsible for achieving excellent results in four image restoration applications. This paper proposes a residual non-local attention network for image restoration","Local and non-local attention to better guide feature extraction in deep neural networks. This work presents a deep neural network architecture that learns to extract features from hierarchical layers of the image. The authors study the problem of image generation in deep networks, and show that local attention is beneficial for image generation.","A new approach for image restoration using residual non-local attention. This paper proposes a method to train deep neural networks with local attention in order to better guide feature extraction. The authors propose a method for training deep networks that can be used for image reconstruction and image super-resolution. This work proposes a technique for learning local attention from hierarchical features, which is more suitable for image re-processing.","This article presents a novel method for image restoration using residual non-local attention to train very deep networks by preserving more low-level features, being more suitable for image super-resolution. This work introduces a new approach for image reconstruction that can be used to improve the quality of information in the mask branch. The authors present a method for photo restoration which uses a large receptive field size to extract features from the hierarchical representations.","Using residual non-local attention learning to train very deep networks by preserving more low-level features, being more suitable for image restoration. This work presents a novel method for capturing information from hierarchical features in the context of images that can be used to improve image super-resolution. The authors present a new approach to extract information from the mask branches of the mask branch and show that it's possible to obtain more sophisticated attention map in mask branches."
"We present an influence-directed approach to constructing explanations for the behavior of deep convolutional networks, and show how it can be used to answer a broad set of questions that could not be addressed by prior work. A way to measure influence that satisfies certain axioms, and a notion of influence that can be used to identify what input part is most influential for the output of a neuron in a deep neural network. This work proposes to measure the influence of single neurons with regard to a quantity of interest represented by another neuron.",Localizing relevance of neurons in convolutional neural networks This work presents a new approach to interpreting the influence of neural networks on the output of images. The authors present a method for learning the influence on the outputs of convolutionally neural networks by using an axiomatic way of explaining the structure of a neural network.,"Localizing relevance in convolutional neural networks This paper proposes a new approach to understanding the influence of neurons on the classification process of deep neural networks. The authors propose a method for estimating the influence on the distribution of interest of a neural network's internal units, which is based on attributing relevance solely to the input features. This study proposes a novel way to evaluate the influence and relevance of neural networks' internal units on classification predictions.","A method for interpreting predictions for convolutional neural networks. This study presents a method to interpret the prediction of neural networks using an influence-directed explanation of the network's internal units. This work introduces a new approach to understanding the role of neural network activations in the classification of neurons in the input image, and shows that it is better at localizing the features used by the network in its prediction.","A method to interpret predictions for convolutional neural networks by focusing on the essence of a class, and identifying influential neurons over the entire population. This work introduces a method for interpreting predictions for an image that is more relevant to the outcomes of the neurons in the input model. The authors present a new way of understanding the effect of influence on a slice of the network with two natural invariance properties."
"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent ""bottleneck state"" predictions, which are useful for planning. A method on prediction of frames in a video, the approach including that target prediction is floating, resolved by a minimum on the error of prediction. Reformulates the task of video prediction/interpolation so that a predictor is not forced to generate frames at fixed time intervals, but instead is trained to generate frames that happen at any point in the future.","A novel method to train time-agnostic CVAE-GANs with a fixed minimum over time loss. This paper presents a novel method for training video prediction models that can be applied to multiple tasks at once. The authors present a new method for learning video prediction, called TAP, which is based on a generalized minimum-over-time loss, and shows that it is more efficient than deterministic methods.","A novel method to train time-agnostic CVAE-GANs with a generalized minimum over time loss. This paper proposes a novel approach to the video prediction problem, proposing a novel technical approach to solve this problem. The authors propose a novel method for training video prediction models that can be trained with a ""generalized minimum-over-time loss"" which minimizes uncertainty in the prediction.","A novel technical approach to solve video prediction problem by reframeing the prediction problem to be time-agnostic. This work introduces a method for identifying ""bottleneck states"" across several tasks, and shows that these bottleneck states correspond to subgoals that aid in planning towards complex end goals. The authors address the problem of video prediction using video prediction as a subgoal for hierarchical planners.","A novel technical approach to solve video prediction problem. This work introduces a method for reframeing the prediction problem to be time-agnostic, and shows that bottleneck states correspond to subgoals that aid in planning towards complex end goals. The authors consider the use of bottleneck predictions as subgoals for a hierarchical planner, which is loosely related to options."
We perform functional variational inference on the stochastic processes defined by Bayesian neural networks. Fitting of variational Bayesian Neural Network approximations in functional form and considering matching to a stochastic process prior implicitly via samples. Presents a novel ELBO objective for training BNNs which allows for more meaningful priors to be encoded in the model rather than the less informative weight priors features in the literature. Presents a new variational inference algorithm for Bayesian neural network models where the prior is specified functionally rather than via a prior over weights.,"An implicit variational inference algorithm that approximates the functional ELBO using finite measurement sets and the spectral Stein gradient estimator. This article presents a method for training neural networks with a generative prior, which can be used to estimate the log density derivative function of a function. The authors present a novel approach for learning generative inference based on the log-ML distribution of functions in a neural network.","An implicit variational inference method for estimating the log density derivative function of a functional ELBO using finite measurement sets and the spectral Stein gradient estimator. This paper proposes a novel variational approach to estimate the log-Density derivative functions of a neural network, based on a spectral Stein Gradient Estimator (SSGE). The article proposes a new generative inference method that approximates the functional ELB using a sampling-based approach","A variational inference method that approximates the functional ELBO by using finite measurement sets and the spectral Stein gradient estimator. This article introduces a method for estimating the posterior dependencies of a shallow BNN, showing that under certain assumptions, the limiting distribution is a Gaussian process (GP). The authors present a technique for measuring the posterior function of an implicit distribution, which can be applied to stochastic processes.","This work introduces a variational inference method that approximates the functional ELBO using finite measurement sets and the spectral Stein gradient estimator. The authors present a method for estimating posterior dependencies of a shallow BNN, showing that an implicit distribution is a Gaussian process (GP). This study presents a technique to estimate the posterior function of an implicit distributed by combining finite measurements and the Stein gradient estimation method."
"Learning deep latent variable MRFs with a saddle-point objective derived from the Bethe partition function approximation. A method for learning deep latent-variable MRF with an optimization objective that utilizes Bethe free energy, that also solves the underlying constraints of Bethe free energy optimizations. An objective for learning latent variable MRFs based on Bethe free energy and amortized inference, different from optimizing the standard ELBO.","A saddlepoint objective for learning deep, undirected graphical models with latent variables variational inference. This article presents a saddlepoint approach to learning deep neural HMMs using the Bethe free energy approximation to the model's partition functions. This work introduces a saddle-point objective to learn deep, unsupervised graphical models using latent variables, and shows that it outperforms other approaches.","A saddlepoint objective for learning deep, undirected graphical models with latent variables. This paper proposes a saddle-point objective that makes use of the Bethe free energy approximation to the model's partition functions in order to improve inference performance. The authors propose a saddle point objective for training neural HMMs with latent variable variational inference, which improves inference performance on text based models. This work proposes a new approach to learn deep, unsupervised graphical models from latent variables by using a Bethe Free Energy approximation.","Using a saddlepoint objective to learn deep, undirected graphical models using the Bethe free energy approximation to the model's partition functions. This article introduces a method for learning deep-linear text HMMs with latent variables that can be optimized efficiently without sampling and outperforms other approximate inference methods in terms of held out log likelihood.","A method for learning undirected graphical models with discrete latent variables that can be optimized efficiently without sampling. This work introduces an approach to learning neural text HMMs using the Bethe free energy approximation, which makes use of a saddlepoint objective to improve the expressiveness of MRFs with arbitrary pairwise factors in terms of held out log likelihood."
"In this work, we point to a new connection between DNNs expressivity and SharkovskyÉ??s Theorem from dynamical systems, that enables us to characterize the depth-width trade-offs of ReLU networks Shows how the expressive power of NN depends on its depth and width, furthering the understanding of the benefit of deep nets for representing certain function classes. The authors derive depth-width tradeoff conditions for when relu networks are able to represent periodic functions using dynamical systems analysis.","A deep neural network that can be approximated by a shallow neural network. This article studies the composition of periodic functions in deep neural networks and shows that they can be easily approximated with shallow neural networks. The authors show that deep neural nets can be trained to represent periodic functions as a function of the depth, and show that such deep networks are more stable than shallow networks.","A deep neural network with period 3 points that can be approximated by a shallow neural network. This paper proposes a new method to represent periodic functions in deep neural networks, which is based on the idea of triangle wave functions. The article presents a new way of representing periodic functions and shows that it is possible for deep neural nets to express periodic functions as a function of the depth.","A method for predicting periodic functions as a function of the depth. The paper presents a method to predict periodic functions that can be represented by shallow vs deep neural networks. This article introduces a technique for determining the case of periodic functions in a wide variety of layers, and shows that they can be approximated by shallow networks unless they are exponentially large.","A method to predict periodic functions as a function of the depth. This work presents a method for predicting periodic functions that can be represented by DNNs, i.e., by some particular choice of weights on their edges (and for a wide variety of standard activation units in their layers). The authors show that the composition of t(x; 2) with itself k times will create exponentially many oscillations."
"We propose a method that infers the time-varying data quality level for spatiotemporal forecasting without explicitly assigned labels. Introduces a new definition of data quality that relies on the notion of local variation defined in (Zhou and Scholkopf) and extends it to multiple heterogenous data sources. This article proposed a new way to evaluate the quality of different data sources with the time-vary graph model, with the quality level used as a regularization term in the objective function",Graph convolutional neural networks can be used to improve the predictive performance of neural networks via experiments on urban heat island prediction in Los Angeles. This paper presents a graph convolutionAL neural network with graph connectivity that is more robust to local variation than other networks. The authors present a graph-based neural network architecture that is able to predict temperature in the summer and winter seasons using data from different nodes.,"Graph convolutional neural networks can be used to improve the quality of data generated by experiments on urban heat island prediction in Los Angeles. This paper proposes a method for measuring graph connectivity at each vertex of a given node, which is based on a graph-convolutional network architecture. The study proposes a graph convolution algorithm that measures the local variation between different vertices of a node and its neighbors.","Graph convolutional neural networks provide an efficient architecture to extract localized patterns from regular grids, such as images BID14. This work introduces a graph convolutionary neural network architecture that can be used to compute the data quality at vertex i. The study presents a method for generating localised patterns on graph connectivity by using a combination of two methods and a model with a different number of neighboring signals in the vertex.","A graph convolutional neural network architecture that can be used to extract localized patterns from regular grids, such as images BID14. This work introduces a graph connectivity architecture for generating localized signals at vertex i with the help of data quality. The study presents a computational framework for estimating the local variation of a vertex signal at the vertex's vertex in a way that is less fluctuated by the number of neighbors."
"We show that training a deep network using batch normalization is equivalent to approximate inference in Bayesian models, and we demonstrate how this finding allows us to make useful estimates of the model uncertainty in conventional networks. This study proposes using batch normalisation at test time to get the predictive uncertainty, and shows Monte Carlo prediction at test time using batch norm is better than dropout. Proposes that the regularization procedure called batch normalization can be understood as performing approximate Bayesian inference, which performs similarly to MC dropout in terms of the estimates of uncertainty that it produces.","A Bayesian approach for estimating model uncertainty in deep neural networks. This paper presents a Bayesian framework for estimating the uncertainty of deep neural network predictions. The authors provide a Bayes-based approach to estimating uncertainty in neural networks based on batch normalization, and show that it performs on par with MCDO. This work studies the predictive uncertainty of neural networks using batch normalized models","A Bayesian approach to estimating predictive uncertainties in deep neural networks This paper proposes a method for estimating the uncertainty of deep neural network predictions. The authors propose a Bayesian model that approximates the uncertainty for each prediction and provides a theoretical framework for predicting the accuracy of each prediction. This work proposes a Bayes-based approach to estimate uncertainty in deep networks, based on the KL divergence of the models.","This study presents a method for estimating uncertainty in deep neural networks by minimizing the divergence of the model prior to the mini-batch optimization. This work introduces a new algorithm for batch normalization, which can be used to standardize the distribution of each unit's input into a Bayesian setting.",A deep-net-based model-wise operation to normalize the distribution of each unit's input into a batch normalized network. This work introduces a new method for estimating uncertainty in deep neural networks by using a Bayesian approach. The authors present a deep learning method that can be used as a mini-batch optimization method and provide a better understanding of the problem of quantifiable variables in a wide range of tasks.
"Understanding the neural network Hessian eigenvalues under the data generating distribution. This article analyzes the spectrum of the Hessian matrix of large neural networks, with an analysis of max/min eigenvalues and visualization of spectra using a Lanczos quadrature approach. This work uses the random matrix theory to study the spectrum distribution of the empirical Hessian and true Hessian for deep learning, and proposes an efficient spectrum visualization methods.","A method to analyze the spectral differences between the Empirical Hessian and the True Hessian. This work studies the spectral perturbations between the two distributions, and presents a method for studying the spectral difference between the true and false Hessian distributions. The authors investigate the relationship between the values of the two different distributions and show that the true Hessian is more robust than the False Hessian on a large dataset.","Using random matrix theory to analyze the spectral differences between the Empirical Hessian and True Hessian. This article proposes a novel method for analyzing the spectral perturbations between the true Hessian, evaluated via a finite data sample (hence related to the empirical risk) and what we term the True Hessians, given under the expectation of the true data generating distribution. A new method for studying the spectral difference between the real and false Hessian in deep learning.","A random matrix theory to derive analytic results for the eigenspectrum perturbations between the Empirical Hessian and False Heissian. This work introduces a method for evaluating the spectral perturbations of the True Heses by using a random-matrix theory, which is used to test the validity of the theoretical results in Section 4.2.","A method to analyse spectral perturbations between the Empirical Hessian and False Shepard. This study uses random matrix theory to derive an analysis of the eigenspectrum differences between the True Hesid and Fal-Emergency Hepard, which can be used to determine the perturbation between the two models."
"We introduce the Recurrent Discounted Unit which applies attention to any length sequence in linear time This study proposes the Recurrent Discounted Attention (RDA), an extension to Recurrent Weighted Average (RWA) by adding a discount factor. Extends the recurrent weight average to overcome the limitation of the original method while maintaining its advantage and proposes the method of using Elman nets as the base RNN","A new recurrent unit for the LSTM that is able to discount the attention applied to previous timesteps. This article introduces a new unit for LSTMs that can be used to compress information in a sequence. The authors introduce a new RWA, which extends the Recurrent Discounted Attention (RWA) unit by allowing it to discount its attention on previous inputs based on later information.","A new attention matrix that extends the Recurrent Discounted Attention (RWA) unit to reduce the attention it assigns to previous timesteps. This article introduces a new attention-based unit which extends the RWA, LSTM and GRU units by allowing them to discount the attention applied to previously encoded information. The paper proposes an extension of the recurrent discounted attention (RDA) unit in order to reduce its attention on previous inputs.","This article introduces a Recurrent Discounted Attention Unit, which extends the RWA by allowing it to discount the attention applied to previous timesteps. This work introduces an attention matrix for each encoded state and a translated word combination that can be used to calculate the weighted average of each of them. The paper presents a method for determining where in the sequence to attend to and how much attention it assigns to multiple tasks is needed.","This article introduces a Recurrent Discounted Attention Unit, which extends the RWA by allowing it to discount the attention applied to previous timesteps. This work introduces an attention matrix for each encoded state and translated word combination in order to learn where in the sequence to attend to."
"How you should evaluate adversarial attacks on seq2seq The authors investigate ways of generating adversarial examples, showing that adversarial training with the attack most consistent with the introduced meaning-preservation criteria results in improved robustness to this type of attack without degradation in the non-adversarial setting. The paper is about meaning-preserving adversarial perturbations in the context of Seq2Seq models","A new method to evaluate the effectiveness of adversarial attacks on word-based MT systems and show, via human and automatic evaluation, that they produce more semantically similar adversarial inputs than unconstrained attacks. This article presents a novel method for evaluating the efficacy of adversarially inspired word substitution attacks on machine learning systems.","Improving the effectiveness of adversarial attacks on word-based MT systems and show, via human and automatic evaluation, that they produce more semantically similar adversarial inputs than unconstrained attacks. This article proposes a new method for learning to replace words with non-sequential ones in order to preserve meaning.",A new constraint for adversarial attacks on word-based MT systems that produce more semantically similar adversarials. This study introduces a method of imbuing gradient-based word substitution attacks with simple constraints aimed at increasing the chance that the meaning is preserved (3.2). The authors present a novel defense technique for adversaries against word substitution and show that constrained substitution attacks do preserve meaning to a higher degree than unconstrained attacks.,"A new constraint for adversarial attacks on word-based MT systems, and a method of imbuing gradient-based word substitution attacks with simple constraints aimed at increasing the chance that the meaning is preserved. This work presents a novel defense technique for constrained words substitution attacks that replace one word in a sentence to maximize an adversarially loss function L adv, similar to the substitution attacks proposed in BID1."
Imposing graph structure on neural network layers for improved visual interpretability. A novel regularizer to impose graph structure upon hidden layers of a Neural Network to improve the interpretability of hidden representations. Highlights the contribution of graph spectral regularizer to the interpretability of neural networks.,"A graph-structured neural network with spectral regularization that can be used to enforce spectral properties of the activations generated by them. This work introduces a new class of convolutional regularizations for the activation of neural networks, which is based on graph-translated Gaussians as dictionary atoms. The authors introduce a graph-based regularization method for generating spectral patterns in neural networks.","A graph-structured neural network with spectral regularization This article proposes a new type of convolutional regularization that can be used to enforce spectral properties of the latent representations obtained by hidden layers of neural networks. The authors propose a new form of regularization for deep learning, which is based on graph-translated Gaussians as dictionary atoms in the neuron graph. This paper introduces a new class of regularizations that are defined in the spectral domain rather than the neuron domain.","A new approach for interpreting latent representations obtained by hidden layers of neural networks. This work introduces a new set of regularizations that are defined in the spectral domain, rather than in the neuron domain, in order to directly enforce spectrral properties of the activation signal. This article presents a novel method for translating latent information into a graph topology and a generalization of the regularization used in deep learning.","A new approach for generating human interpretable patterns in the latent representation obtained by hidden layers of neural networks. This work introduces a new set of regularizations that are defined in the spectral domain, rather than in the neuron domain, in order to directly enforce specral properties of the activation signal."
A framework for learning high-quality sentence representations efficiently. Proposes a faster algorithm for learning SkipThought-style sentence representations from corpora of ordered sentences that swaps the word-level decoder for a contrastive classification loss. This article proposes a framework for unsupervised learning of sentence representations by maximizing a model of the probability of true context sentences relative to random candidate sentences,A novel approach for learning sentence encoders with skip-thought vectors. This work introduces a new model for sentence embedding that is more efficient than existing models. The authors introduce a new approach to sentence encoder learning which uses skip-grams as a representation of the input and the output of the decoder. This article presents a novel way of learning sentences using skip-words,Improving sentence embedding with skip-thought vectors This work proposes a novel approach to learning sentence embedders that is more efficient than autoencoder models. The authors propose a new approach to learn sentence encoders by reducing the size of the input and the loss of the decoder function.,"An autoencoder model that reconstructs the surface form of a sentence, which forces the model to not only predict its semantics, but also aspects that are irrelevant to the meaning of the sentence as well. This article introduces a de-noising autoencoding approach for sentence reconstruction and encapsulates the Skip-gram approach of BID24 when words play the role of sentences.","An autoencoder model that learns to reconstruct the surface form of a sentence, which forces the model to not only predict its semantics, but aspects that are irrelevant to the meaning of the sentence as well. This work introduces a novel de-noising autoencoding approach for identifying the correct context sentence instead of neighboring sentences. The authors present a framework for encoding sentence representations that learn sentence concatenation functions."
Provides an unbiased version of truncated backpropagation by sampling truncation lengths and reweighting accordingly. Proposes stochastic determination methods for truncation points in backpropagation through time. A new approximation to backpropagation through time to overcome the computational and memory loads that arise when having to learn from long sequences.,"Stochastic gradient descent with biased estimates, such as the one provided by truncated BPTT, can lead to divergence even in simple situations and even with large truncation lengths FIG3. This article presents a novel gradient descent algorithm for recurrent learning that is unbiased and provably unbiased. The authors introduce a new algorithm for training deep neural networks, called Fixed-Truncated Probabilistic Gradient Extraction (ARTBP), which is based on a deterministic gradient descent scheme.","Stochastic gradient descent with biased estimates, such as the one provided by truncated BPTT, can lead to divergence even in simple situations and even with large truncation lengths FIG3. This paper proposes a new algorithm for recurrent learning based on truncated bPTT (ARTBP).","ARTBP is experimentally compared to truncated BPTT. This article introduces a method for recurrent learning, which can be used on short-term optimization, but must reflect on long-term effects once in a while. The authors present a technique for evaluating the theoretical properties of RTBP and demonstrate the soundness of the RTPB on real-world data using a stochastic gradient estimate.","ARTBP is experimentally compared to truncated BPTT. This study introduces a novel gradient estimation method that can be used for training sequences with short-term effects, but requires a reflection on the long-term effect. The authors present a method for recurrent learning algorithms, and show that it is possible to perform a linear gradient estimate using a parametric dynamical system instead of a priori."
"Exploration using Distributional RL and truncagted variance. Presents an RL method to manage exploration-explotation trade-offs via UCB techniques. A method to use the distribution learned by Quantile Regression DQN for exploration, in place of the usual epsilon-greedy strategy. Proposes new algorithsms (QUCB and QUCB+) to handle the exploration tradeoff in Multi-Armed Bendits and more generally in Reinforcement Learning",An exploration algorithm for multi-armed bandits using symmetric probability density functions. This article studies the asymmetry of the distributions estimated by random random variables in a multi-arm bandits setting. The study presents a method to estimate the upper confidence bound of the distribution of the return for a single arm based on the empirical distribution of each arm.,"Estimation of the arm's UCB is performed via Hoeffdings Inequality 1 which is entirely based on counting the number of times the arm was pulled. This article introduces a new method for estimating the upper confidence bound of the Bayesian distribution in Bayesian RL, and proposes an algorithm to estimate the upper-confidence bound of Bayesian Distributional RL. The authors propose a new approach to Bayesian Distributional RL where Bayesian distributions are estimated using Bayesian Confidence Bases","This article introduces a new algorithm for estimation of the arm's UCB using Hoeffdings Inequality 1 which is entirely based on counting the number of times the arm was pulled. The authors present a method to estimate the confidence bound for asymmetric distributions in the setting of multi-armed bandits and RL, showing that symmetry is in fact rare in Distributional RL.",A quantitative estimation of the arm's UCB is performed via Hoeffdings Inequality 1 which is entirely based on counting the number of times the arm was pulled. This article presents a method to estimate quantiles for multi-armed bandits and RL by comparing them to asymmetric distributions. The authors present a quantitative estimation algorithm that estimates quantile numbers for each arm using the highest mean plus standard deviation.
"Building a TTS model with Gaussian Mixture VAEs enables fine-grained control of speaking style, noise condition, and more. Describes the conditioned GAN model to generate speaker conditioned Mel spectra by augmenting the z-space corresponding to the identification This article proposes a two layer latent variable model to obtain disentangled latent representation, thus facilitating fine-grained control over various attributes This paper proposes a model that can control non-annotated attributes such as speaking style, accent, background noise, etc.",A new generative model to synthesize speech that resembles the prosody of a reference utterance. This work introduces a novel generative language model (GMVAE) that combines autoencoder and conditional auto-encoding with a latent variable. The study presents a novel approach to generating generative languages by combining autoencoders with a fixed set of latent variables.,"This paper proposes a new model for speech synthesis that integrates out unlabeled latent attributes into the target speech. The authors propose a new language-to-speech model (GMVAE) based on conditional auto-encoding, and show that it outperforms previous models in terms of style transfer. This study proposes a novel approach to synthesize speech that resembles the prosody of a reference utterance",A new model for synthesis of clean speech using conditional auto-encoding. This work introduces a new latent-attribute model that incorporates the decoder inputs to include a vector inferred from the target speech and produces a conditional distribution with higher variance.,A new model for synthesis of clean speech using conditional auto-encoders. This work introduces a new language-token approach to synthesizing clean audio by using a room simulator to add background noise and reverberation to the synthesized speech. The authors study the problem of synthesising clean audio from a multi-speaker English corpus
"In this paper, we propose KL-CPD, a novel kernel learning framework for time series CPD that optimizes a lower bound of test power via an auxiliary generative model as a surrogate to the abnormal distribution. Describes a novel approach to optimising the choice of kernel towards increased testing power and shown to offer improvements over alternatives.","A new kernel parametrization framework for the kernel two-sample test. This work introduces a new kernel selection objective, KL-CPD, which aims at optimizing test power via an auxiliary generative model. The authors present a method to optimize the test power of a kernel with limited samples from the abnormal distribution Q. This study presents a new approach to kernel two sample testing that achieves better performance than previous approaches.","A new kernel parametrization framework for the kernel two-sample test. This paper proposes to optimize kernel with surrogate distribution G in order to reduce the test power of the kernel. The authors propose a method for improving kernel performance in time series CPD tasks by optimizing kernels with surrogate distributions G, Q, and G. This article proposes a new kernel based on surrogate distributions that can be used to improve kernel performance.","A deep kernel parametrization for two-sample test using auxiliary generative models, which endows a data-driven kernel via optimizing test power in Eq. This article presents a deep neural learning framework that optimizes kernels with very limited samples from the abnormal distribution Q and shows how it improves performance in time series CPD. The authors introduce a method to optimize kernels by optimizing their surrogate distributions","A deep kernel parametrization framework which endows a data-driven kernel for the kernel two-sample test. This work presents a deep neural learning framework that optimizes kernel selection with very limited samples from the abnormal distribution Q. The authors introduce a method for optimizing kernel selection using surrogate distribution G to improve test power when samples from Q are insufficient, and show that optimization of kernels with only limited samples of Q can reduce performance degradation."
"A bottom-up algorithm that expands CNNs starting with one feature per layer to architectures with sufficient representational capacity. Proposes to dynamically adjust the feature map depth of a fully convolutional neural network, formulating a measure of self-resemblance and boosting performance. Introduces a simple correlation-based metric to measure whether filters in neural networks are being used effectively, as a proxy for effective capacity. Aims to address the deep learning architecture search problem via incremental addition and removal of channels in intermediate layers of the network.",A new algorithm to train deep neural networks with one feature per layer and widen them until a task depending suitable representational capacity is achieved. This article introduces a new method for training deep neural network architectures with one or more features per layer. The authors introduce a new approach to training deep convolutional neural networks using a top-down pruning procedure that adds features at each layer and expands the representation capacity.,Improving the accuracy of deep neural networks by increasing the number of features per layer This paper proposes a new approach to improve the accuracy and train-accuracy of deep DNNs. The authors propose an algorithm to increase the size of each layer in order to reduce the computational overhead of training a deep neural network with fewer features.,"Using a normalized pruning method to increase representational complexity by adding features to architectures that started with just one feature per layer, but large speed-ups can be introduced by adding stacks of features. This work presents a method for reducing the time evolution of the normalized cross-correlation for all weights with respect to their state at initialization and shows that this is a major detriment to the traditional DNN optimization method.","A method to improve representational complexity of deep neural networks by adding features to existing architectures. This work presents a method for optimizing deep neural network models, which can be used to train large architectures with less than perchance expected computational overhead. The authors present a way to reduce the cost of training deep neural systems by adding additional features on top of a DNN optimization procedure, and show that it is possible to learn more complex sub-sampling functions."
"A noval GAN framework that utilizes transformation-invariant features to learn rich representations and strong generators. Proposes a modified GAN objective consisting of a classic GAN term and an invariant encoding term. This work presents the IVE-GAN, a model that introduces en encoder to the Generative Adversarial Network framework.","A novel GAN framework for learning rich and transformation invariant representation of the data in their latent space. This work presents a novel GANA framework for training generative Adversarial Networks (IVE-GAN) that learns a rich representation of data in the latent space without mode collapsing issues. This study introduces a new GAN architecture for generating samples from latent space, which can be trained on a few modes of the true data distribution.",A novel GAN framework for learning rich and transformation invariant representation of the data in their latent space. This paper proposes a novel GANA framework that extends the classical GAN architecture by adding a discriminator D to map samples from the generator distribution to a few modes of the true data distribution. The authors propose an Invariant-Encoding Generative Adversarial Network (IVE-GAN) which learns a rich representation of data in the latent space without mode collapsing issues.,"A GAN framework that tries to learn a rich representation of the covered modes of the data in their latent space. This work introduces a new GAN architecture, which extends the classical GAN by an additional encoding unit E to map samples from the true data distribution.","A novel GAN framework that tries to capture the distribution of a given dataset to map from an arbitrary latent space to new synthetic data points, and a discriminative model that attempts to distinguish between samples from the generator and the true data. This work introduces a new GAN architecture that extends the classical GAN structure by an additional encoding unit E to map samples from each individual sample x to the original source."
"Multi-view learning improves unsupervised sentence representation learning Approach uses different, complementary encoders of the input sentence and consensus maximization. The paper presents a multi-view framework for improving sentence representation in NLP tasks using generative and discriminative objective architectures. This paper shows that multi-view frameworks are more effective than using individual encoders for learning sentence representations.","A multi-view framework for unsupervised transfer of sentences from one view to another. This work presents a multi-task framework which combines RNN-based encoders with an RNN encoder to improve the accuracy of sentence decoding on supervised tasks. The authors present a new framework for learning sentence representations from two different views, with the aim of improving the accuracy and scalability of sentence decoder.","A multi-view framework which combines RNN and a linear encoder for sentence representations. This work proposes a multi-task framework that combines the features of RNN with a linear decoder to improve the accuracy of sentence representations on supervised tasks. The authors propose a new model for sentence representation based on a combination of LNN and RNN encoders, and propose a novel approach to learning sentence representations from two views.","A multi-view framework for learning sentence representations that leverages the functionality of both RNN and linear models. This work introduces a new framework for unsupervised learning, which uses an RNN to learn sentences from two views, and shows results on unsupervised tasks. The study presents a framework for one-view learning with a differentiable similarity function and a linear decoder in order to achieve better performance on all evaluation tasks.","A multi-view framework for learning sentence representations that outperforms existing unsupervised learning models. This work introduces a multi-vision framework to learn sentences from two views, and shows results on all unsupervised tasks. The authors present a model for learning sentences from sentences using a linear decoder and a non-loglinear model with a differentiable similarity function in each view."
"Unsupervised methods for finding, analyzing, and controlling important neurons in NMT This work proposes finding ""meaningful"" neurons in Neural Machine Translation models by ranking based on correlation between pairs of models, different epochs, or different datasets, and proposes a controlling mechanism for the models.","A method for ranking neurons in neural language representations based on correlations between pairs of models. This article presents a new way of ranking neural language models based on the correlation between neuron activations. This study studies the effect of neural language learning on language translation quality, and finds that many of the neurons are correlated with specific language properties.",A method for ranking neural language neurons based on correlations between pairs of models. This article proposes a method to evaluate neural language translation quality in order to determine which neurons are most likely to capture common linguistic phenomena. The authors propose a method for evaluating neural language representations based on the correlation between neuron activation and lexical information.,"A method for ranking neurons with linguistically similar properties. This study presents a novel algorithm for ranking neural networks in the context of language pairs by using a SVCCA dataset. The authors present a method to rank neural networks on a space 120 spanned by non-erased directions, and show that many of them capture common linguistic phenomena. This article introduces a new algorithm for identifying neural networks that can be used to identify specific words.","A new method for ranking neurons with linguistically similar directions. This work introduces a new algorithm to rank neural networks on language pairs, and shows that many of them capture common linguistic phenomena. The authors study the problem of ranking neurons in a single language pairs by using a SVCCA-based coder-decoder model, and show that most of them do not require any external supervision."
"We use graph co-attention in a paired graph training system for graph classification and regression. This article injects a multi-head co-attention mechanism in GCN that allows one drug to attend to another drug during drug side effect prediction. A method to extend graph-based learning with a co-attentional layer, which outperforms other previous ones on a pairwise graph classification task.","A novel neural network architecture for pairwise graph classification. This work introduces a new model for molecule prediction, Equation 5, which combines a graph neural network with a co-attentional layer. The study presents a novel graph-based model for molecular prediction that combines information from multiple graphs into a single prediction task. The authors present a novel algorithm for molecule-to-drug prediction based on a pairwise representation of two graphs.","This paper proposes a novel method for pair-wise representation learning, which uses a co-attentional layer to provide information about different substructures across a pair of graphs. The authors propose a new approach to pair-based representation learning in which a graph neural network receives pairs of pairs of molecules at once, and extends it with a coattentive layer that provides information about the substructure of each pair of molecules.","A graph neural network that receives pairs of graphs at once, and extends it with a co-attentional layer that allows node representations to easily exchange structural information across them. This work introduces a graph-level model for graph-structured representation learning which can be used to learn substructures from other inputs.","A graph neural network that receives pairs of graphs at a time, and extends it with a co-attentional layer that allows node representations to easily exchange structural information across them. This work introduces a new model for graph-level representation learning, which can be used to learn substructures from other inputs. The authors present a pairwise graph classification task in which the two representations of each other are represented by atoms."
Devising unsupervised defense mechanisms against adversarial attacks is crucial to ensure the generalizability of the defense. This work presents a method for detecting adversarial examples in a deep learning classification setting This study presents an unsupervised method for detecting adversarial examples of neural networks.,An automated end-to-end framework for unsupervised model assurance and defending against adversarial samples. This work presents a novel approach to unsupervising data abstractions by using parallel checkpointing modules in each intermediate DL layer. The authors present a method for training adversarial models in which the defender module is trained to detect non-overlapping data points within each class of data.,An automated end-to-end framework for unsupervised model assurance and defending against adversarial samples. This paper proposes a novel approach to counter-encrypting data abstractions by using parallel checkpointing modules in each intermediate DL layer to validate the validity of the data abstracts. The authors propose a method for counter-counter-attacking adversarial attacks that is more robust than traditional checkpointing methods.,"This article introduces a new framework for unsupervised model assurance as well as defending against the adversaries. The work presents a novel approach to attack on defender modules by incorporating a loss function with a cross entropy loss, which is used to improve the security of data abstractions in an end-to-end way.","This study introduces an end-to-end framework for unsupervised model assurance as well as defending against the adversaries. The authors present a novel attack approach to verify the legitimacy of data abstractions in each DL layer, and show that parallel checkpointing modules can be used to improve the performance of the victim model. This work presents a method for training defender modules to checkpoint the data representations of data points within the rarely explored regions of the data points."
"We show how using skip connections can make speech enhancement models more interpretable, as it makes them use similar mechanisms that have been explored in the DSP literature. The authors propose incorporating Residual, Highway and Masking blocks inside a fully convolutional pipeline in order to understand how iterative inference of the output and the masking is performed in a speech enhancement task The authors interpret highway, residual and masking connections. The authors generate their own noisy speech by artificially adding noise from a well established noise data-set to a less know clean speech data-set.","A new method for learning the spectral domain of a deep neural network for speech enhancement. This article introduces skip connections in deep neural networks, and shows that they can improve the performance of models trained for speech denoising. The authors introduce skip connections, which are based on predicting time-frequency cells dominated by noise, and show that skipping connections can help to improve speech structure.","The authors propose a new approach to speech enhancement by using skip connections instead of autoencoder. This paper proposes a new method for learning from skip connections in deep neural networks, and shows that skip connections can be used to improve the performance of models trained for speech denoising. This article proposes a novel method for improving the accuracy of speech prediction models based on skip connections. The authors propose an approach to learning from skipping connections, which is based on predicting time-frequency cells dominated by noise and filtering them out. This work proposes a method to learn from skipped connections in order to improve speech prediction.","This work presents a study of the role of residual and highway connections in deep neural networks for speech enhancement, and shows that skip connections do not necessarily improve performance with regards to the number of parameters, but they make speech enhancement models more interpretable. Presents a novel method for visualizing time-frequency cells by using a skip connection instead of subtraction, which uses a multiplicative mask M to predict the magnitude spectrum of the distortion and filter it out.","This paper presents a new model for speech enhancement using skip connections, which performs operations between the input and the output of each block. The authors show that skip connections do not necessarily improve performance with regards to the number of parameters, but they also make speech enhancement models more interpretable. This study studies the role of residual and highway connections in neural networks for speech denoising"
We propose the Exemplar Guided & Semantically Consistent Image-to-image Translation (EGSC-IT) network which conditions the translation process on an exemplar image in the target domain. Discusses a core failing and need for I2I translation models. The article explores the idea that an image has two components and applies an attention model where the feature masks that steer the translation process do not require semantic labels,"A new translation method for image generation that combines multimodal and domain-specific style information. This article introduces a new translation technique, EGSC-IT, which combines the two existing methods of combining style information and domain specific style information in a shared latent space. The authors introduce a new approach to image translation by combining the style information of two different domains into a single representation.","Egsc-IT is a novel translation method that combines two latent space constraints to facilitate multimodal image translation. This paper proposes a new translation architecture based on a shared latent space constraint, which allows us to transfer the style information of the target domain to the source domain. The authors propose an approach to translate images from one domain to another domain by combining two latent spaces between the two domains in order to improve translation performance.","An adaptive instance normalization approach for multimodal image translations. This work introduces a new latent space constraint which assumes that a pair of corresponding images (x A, x B) from domains A and B can be mapped to the same representation z in a shared-latent space. This paper presents a method for translating images into images of different styles within the target domain.",This paper introduces a method to translate images from different styles in the target domain into images of different styles. The authors present an approach to translating images from a latent space to a single image in the source domain using Adaptive Instance Normalization (AdaIN) and a shared-latent space constraint that can be applied to the translation process.
A simple architecture consisting of convolutions and attention achieves results on par with the best documented recurrent models. A fast high performance paraphrasing based data augmentation method and a non-recurrent reading comprehension model using only convolutions and attention. This paper proposes applying CNNs+self-attention modules instead of LSTMs and enhancing the RC model training with passage paraphrases generated by a neural paraphrasing model in order to improve RC performance. This work presents a reading comprehension model using convolutions and attention and propose to augment additional training data by paraphrasing based on off-the-shelf neural machine translation,"A novel reading comprehension model that consists of only convolutional and self-attention, a combination that is empirically effective for both training and inference. This study presents a novel reading recognition model for the reading comprehension problem, which consists of two layers: a neural network embedding layer, and a context-query attention layer.","A novel reading comprehension model that consists of only convolutional and self-attention mechanisms, which is empirically effective for both training and inference. This paper proposes a novel reading recognition model based on the QANet algorithm. The authors propose a novel approach to reading comprehension problems by combining convolutions and self attention in order to improve the accuracy of the model.","A new feedforward model for reading comprehension that consists of only convolutional and self-attention, discarding RNNs. This article introduces a new approach to the problem of reading comprehension by using a data augmentation technique to improve the training performance of SQUAD datasets. The authors present a method for learning a novel reading comprehension model with a low level structure and a combination of self attention and context-query attention.","A feedforward model that consists of only convolutional and self-attention, discarding RNNs, which are used by most of the existing models. This work introduces a backtranslation model for reading comprehension with a combination of self attention and embedding layers to improve the performance of the training data. The authors present a new approach to the problem of refining an RNN model by using a non-convolutional neural network"
"We learn dense scores and dynamics model as priors from exploration data and use them to induce a good policy in new tasks in zero-shot condition. This paper discusses zero shot generalization into new environments, and proposes an approach with results on Grid-World, Super Mario Bros, and 3D Robotics. A method aiming to learn task-agnostic priors for zero-shot generalization, with the idea to employ a modeling approach on top of the model-based RL framework.","A novel reinforcement learning algorithm that learns to select trajectories for a task in a grid-world environment. This work introduces a new model for reinforcement learning that learns the best trajectory for a given task in an environment. The study presents a method for training a reinforcement learning agent to select different trajectories from a set of parameters, and shows that it outperforms other approaches.","A reinforcement learning agent that learns to move to the left in order to learn a new trajectory for a task. This paper proposes a method to train an intelligent agent on a wide range of tasks, including grid-world, robotics, and video games. The authors propose a novel approach to solving the problem of choosing the best trajectories for a given task by using a model based on curiosity driven reward.","A method that outperforms baseline methods on gridworld, robotics tasks and video games. The study presents a method for learning dynamic priors in a grid-world environment using the model's scoring function and the dynamics model to find the best trajectory for a task T.","A method that learns to move to the right in the upper level of Figure 1 would fail to transfer the priors to the lower level and further play the game in the new level because change of configurations and background. This work presents a method for learning a trajectory from a grid-world example to a robotics Blocked-Reach environment, which can outperform baseline methods on a wide range of applications including gridworld."
An autoregressive deep learning model for generating diverse point clouds. An approach for generating 3D shapes as point clouds which considers the lexicographic ordering of points according to coordinates and trains a model to predict points in order. The paper introduces a generative model for point clouds using a pixel RNN-like auto-regressive model and an attention model to handle longer-range interactions.,"Conditional PointGrow, a generative model for 3D point cloud generation, learns a smooth manifold of given images where 3D shape interpolation and arithmetic calculation can be performed inside. This work introduces a self-attention module to generate point clouds that can be used to generate 3D objects.","A self-attention module that captures the dependencies between points, helping to generate plausible part configurations within 3D objects. This paper proposes a method for generating point cloud samples from scratch using conditional PointGrow. The authors propose an unsupervised feature learning framework based on conditional distribution between points in order to capture the dependencies of each point.","A self-attention module that captures the long-range dependencies between points, helping to generate plausible part configurations within 3D objects. This article introduces a self attention model for point clouds that can be used in conjunction with a non-context model. The authors present a Self-attention model for image generation using conditional PointGrow, which provides an auto-attention mechanism for generating representations of distances and convolutional coordinates.","A self-attention module that captures the long-range dependencies between points, helping to generate plausible part configurations within 3D objects. This work introduces a self attention module for modeling point clouds, which can be used in conjunction with an unconditional model. The authors present a Self-attention framework for generating representations of point clouds by using a discrete coordinate and a convolutional layer layer to create a coherent representation of the point cloud."
"Degenerate manifolds arising from the non-identifiability of the model slow down learning in deep networks; skip connections help by breaking degeneracies. The authors show that elimination singularities and overlap singularities impede learning in deep neural networks, and demonstrate that skip connections can reduce the prevalence of these singularities, speeding up learning. Paper examines the use of skip connections in deep networks as a way of alleviating singularities in the Hessian matrix during training.","Overlap singularities are caused by the permutation symmetry of the hidden units at a given layer and they arise when two units become identical, e.g. when their incoming weights become identical to each other. This study introduces skip connections between adjacent layers of nonlinear linear residual networks, and shows that skip connections can be explained by stochastic gradient descent and random initialization.","Overlap singularities are caused by the permutation symmetry of the hidden units at a given layer and they arise when two units become identical, e.g. when their incoming weights become identical ( FIG1 ). This study proposes a new architecture for nonlinear linear residual networks that introduces skip connections between adjacent layers to solve the vanishing gradients problem.","This article introduces a novel residual architecture that introduces identity skip connections between adjacent layers and all layers above it. This study investigates the elimination, overlap and linear dependence singularities of a neural network by applying a malicious initialization scheme for the residual architecture to improve performance. The authors present a framework for avoiding overlap singularities in neural networks by adding the identity matrix from the initial weight matrices of the hidden units in the same layer.","This work introduces a hyper-residual architecture that introduces identity skip connections between adjacent layers and all layers above it. This study investigates the elimination, overlap and linear dependence singularities of the hidden units in the same layer, and how they can be used to improve the training accuracy. The authors present a nonlinearity network with no skip connections, and show that there is a direct correlation between elimination and linear dependency singularities."
"We formulated SGD as a Bayesian filtering problem, and show that this gives rise to RMSprop, Adam, AdamW, NAG and other features of state-of-the-art adaptive methods The paper analyzes stochastic gradient descent through Bayesian filtering as a framework for analyzing adaptive methods. The authors attempt to unify existing adaptive gradient methods under the Bayesian filtering framework with the dynamical prior",An approximate inference between adaptive SGD algorithms and natural gradient variational inference. This article presents a method to approximate gradient updates in neural networks using Bayesian (Kalman) filtering. The authors provide a method for approximating gradients in deep neural networks by incorporating momentum and momentum into the updates. This work presents a new way to approximate gradients of neural networks with Bayesian filtering,"A theoretical analysis of adaptive SGD algorithms with Bayesian filtering. The article proposes a method for learning natural gradient variational inference, which is based on Bayesian interpolation. This paper presents an approach to learning natural gradients in neural networks using Bayesian and Bayesian filters. The authors propose a method to learn natural gradient Variational Inference (VI), where the update depends only on the current value of the backpropagated gradients, and the covariance between momentum and momentum.","An adaptive algorithm for neural network optimization that combines natural gradient variational inference and Bayesian filtering. This work introduces a novel method to connect adaptive SGD algorithms to natural gradient VI updates, which is based on the current value of the parameter, and the root-mean-square normalizer BID14.",An adaptive algorithm for neural network optimization that uses Bayesian filtering to optimize parameters of BID23 BID30 BID24 BID25 BID7 BID22. This work introduces a novel method for optimizing neural networks by combining the state-of-the-art adaptive SGD algorithms with bayesian filters and natural gradient variational inference.
"We show that, in continual learning settings, catastrophic forgetting can be avoided by applying off-policy RL to a mixture of new and replay experience, with a behavioral cloning loss. Proposes a particular variant of experience replay with behavior cloning as a method for continual learning.","Continuous learning is a method for reducing catastrophic forgetting in continuous learning. This work presents a new approach to the problem of catastrophic forgetting that combines continuous learning with sequential learning. The authors present a novel method for preventing catastrophic forgetting, called continuous learning, in which a single learning network is fed experiences from different points in the training sequence. This study presents a novel way to reduce catastrophic forgetting on continuous learning tasks.","Continuous Learning (CLEAR) is a method for reducing catastrophic forgetting in DMLab. This paper proposes a new approach to continuous learning, which combines replay buffers with reinforcement learning to reduce catastrophic forgetting. The authors propose a novel approach to continual learning by combining replay buffers and reinforcement learning, focusing on the problem of catastrophic forgetting between different tasks.","A continual learning system that learns from a variety of different learning networks. This article introduces a novel method for reducing catastrophic forgetting in sequential training, where performance on a task decays immediately when training switches to another task. The authors consider the problem of continuous learning by combining 50-50 new-replay and combining significant reductions in catastrophic forgetting for all tasks.","A continuul learning system that learns new skills that are related to old ones faster than it would have de novo, a property known as constructive interference or positive transfer. This study presents a novel method for reducing catastrophic forgetting on sequential training tasks, and introduces a new strategy to reduce the catastrophic forgett. The authors address the problem of continual learning by using experience replay buffers to minimize the impact of rare experiences in RL."
"Our variational-recurrent imputation network (V-RIN) takes into account the correlated features, temporal dynamics, and further utilizes the uncertainty to alleviate the risk of biased missing values estimates. A missing data imputation network to incorporate correlation, temporal relationships, and data uncertainty for the problem of data sparsity in EHRs, which yields higher AUC on mortality rate classification tasks. The paper presented a method that combines VAE and uncertainty aware GRU for sequential missing data imputation and outcome prediction.","A deep generative model to estimate the missing values based on features correlations and temporal relations in the latent space of a GRU cell. This work presents a novel method for estimating missing values in an in-hospital mortality prediction framework. This study presents a deep generational model for estimating the missing value estimates based on the features correlations, temporal relations, and the uncertainty.","A deep generative model to estimate the missing values based on features correlations and temporal dynamics. This work proposes a novel method for estimating missing values of in-hospital mortality prediction using a recurrent imputation network. The authors propose an approach to estimate missing values by utilizing a generative framework combined with a recurrent neural network to extract the temporal dynamics from the latent space, yielding the uncertainty.",A deep generative model to estimate the missing values using a recurrent imputation network to exploit the temporal dynamics in conjunction with the utilization of the uncertainty. This work introduces a new method for estimating the latent representation by using VAEs and generating the uncertainty decay factor in the Eq. The authors present a method for improving the prediction performance of the data by leveraging the reconstructed data as the fidelity score.,"A deep generative model to estimate the missing values and the uncertainty in the latent space, yielding the uncertainty decay factor. This work introduces a new method for estimating the uncertain information by using a recurrent imputation network as a secondary problem but major concern in the task performance. The authors use a deep-generative model combined with a robust generative network to extract the uncertainty of the uncertainty and the temporal dynamics together."
"In a deep convolutional neural network trained with sufficient level of data augmentation, optimized by SGD, explicit regularizers (weight decay and dropout) might not provide any additional generalization improvement. This work proposes data augmentation as an alternative to commonly used regularisation techniques, and shows that for a few reference models/tasks that the same generalization performance can be achived using only data augmentation. This paper presents a systematic study of data augmentation in image classification with deep neural networks, suggesting that data augmentation can replicit some common regularizers like weight decay and dropout.","A systematic analysis of the impact of data augmentation on deep neural networks compared to popular techniques of explicit regularization. This article presents a systematic study of the role of deep neural network regularization in improving the generalization of the training data. The authors present a systematic review of the effect of deep learning on the training performance of neural networks, focusing on the use of implicit regularization as a substitute for explicit regularized methods.","A systematic analysis of the impact of data augmentation on deep neural networks compared to popular regularization techniques. This article presents a systematic analysis and empirical study of the role of data augmenting in deep neural network for object recognition, focusing on the use of both explicit regularization and implicit regularization. The article proposes a systematic approach to improving the performance of deep neural models by using data augments.",A systematic analysis of the impact of data augmentation on deep neural networks with and without explicit regularization. The authors present a systematic analysis to analyze how data hausse adapts to different architectures of deep neural network architectures. This work presents a method for analyzing the role of information augmentation in deep neural models by using two different augmentation schemes as well as comparing them to the most popular regularization techniques.,"A systematic analysis of the impact of data augmentation on deep neural networks compared to the most popular regularization techniques. This work presents a method for analyzing the role of explicit regularization in deep neural network architectures. The authors present an analysis of how data hausse adapts to different architectures of different depths of the network, and show that it can be used as a substitute for explicitly regularization."
"LEAP combines the strength of adaptive sampling with that of mini-batch online learning and adaptive representation learning to formulate a representative self-paced strategy in an end-to-end DNN training protocol. Introduces a method for creating mini batches for a student network by using a second learned representation space to dynamically select examples by their 'easiness and true diverseness'. Experiments the classification accuracy on MNIST, FashionMNIST, and CIFAR-10 datasets to learn a representation with curriculum learning style minibatch selection in an end-to-end framework.","A self-paced sample selection framework that learns a dynamic representation space for the training data and learns when to introduce certain samples to the DNN during training. This work introduces a new dataset selection framework called Learning Embeddings for Adap- tive Pace (LEAP) that is independent of model architecture or objective, and learns which samples to introduce during training in order to improve performance on classification tasks.","Learning Embeddings for Adap- tive Pace (LEAP) that is independent of model architecture or objective, and learns when to introduce certain samples to the DNN during training. The authors propose a self-paced approach to learning a representation space based on easiness and true diverseness as sample importance priors in order to achieve better clustering performance.","A framework for self-paced learning with Adaptive Pace that learns when to introduce certain samples to a DNN during training. This work presents a framework for learning a representation space for the student CNN, which can be used to train a classifier and a classification task. The authors present a model for learning examples in a mini-batch setting using easiness and true diverseness as sample importance priors.","A framework for self-paced learning with Adaptive Pace that learns when to introduce certain samples to the DNN during training. This work presents a framework for learning sample selection in a mini-batch setting using easiness and true diverseness as sample importance priors. The authors present a method for learning representations from multiple clusters of clusters, including CNNs and CNNs."
"We introduce an embedding space approach to constrain neural network output probability distribution. This work introduces a method to perform semi-supervised learning with deep neural networks, and the model achieves relatively high accuracy, given a small training size. This study incorporates label distribution into model learning when a limited number of training instances is available, and proposes two techniques for handling the problem of output label distribution being wrongly biased.","A novel semi-supervised learning algorithm that jointly optimizes output probability distribution on a clustered embedding space to make neural networks draw effective decision boundaries. This work introduces a new method for training deep neural networks with low dimensional feature space, where labels can be trained to draw decision boundaries correctly from a limited number of examples. The study presents a new approach to train deep neural network models with high dimensional feature spaces.","A method for jointly optimizing output probability distribution on a clustered embedding space to make neural networks draw effective decision boundaries. This paper proposes to jointly train neural networks with a clustering of labels in the hidden layer of a neural network, and propose to jointly learn the decision boundaries of the classifier. The work proposes a new algorithm that jointly optimizes output probability distributions on a sparsely labelled data set by using autoencoder and batch probability distribution.","A novel algorithm that jointly optimizes output probability distribution on a clustered embedding space to make neural networks draw effective decision boundaries. This work presents a novel algorithm for learning decision boundaries on multilayer perceptron (MLP) with limited labelled examples, which can be used to train neural networks to learn the decision boundary correctly from a limited number of examples.",A novel algorithm that jointly optimizes output probability distribution on a clustered embedding space to make neural networks draw effective decision boundaries. This work presents a novel algorithm for learning the decision boundary of a multilayer perceptron (MLP) classifier with limited examples. The authors investigate the problem of learning the choice boundary from a limited number of labels in a hidden layer of an MLP trained with 50 labelled MNIST data.
A comparison of five deep neural network architectures for detection of malicious domain names shows surprisingly little difference. Authors propose using five deep architectures for the cybersecurity task of domain generation algorithm detection. Applies several NN architectures to classify url's between begign and malware related URLs. This paper proposes to automatically recognize domain names as malicious or benign by deep networks trained to directly classify the character sequence as such.,"A new deep neural network classifier that can detect domain names as benign or malicious based solely on the domain name string. This study presents a new deep learning framework for detecting domain names that are not explicitly told to be labeled as malicious. The authors present an end-to-end approach to detecting domain name strings in a deep learning context, focusing on the problem of identifying malicious domain names and proposing an endgame model.","An end-to-end deep neural network architecture that can detect domain names as benign or malicious based solely on the domain name string. The authors propose a new approach to DGA detection based on a recurrent neural network model, which consists of an embedding layer and a convolutional layer. This paper proposes a novel framework for DGA classification based on the presence of a random string of domain names in the network.","A deep recurrent neural network that can detect DGAs without the need to reverse engineer malware families. This article introduces a long-term model for DGA detection, which uses an endgame embedding layer of convolutional neural networks (GRUs) to improve model performance and overcome overfitting by randomly excluding nodes during training.","A deep neural network architecture that can detect DGAs without the need to reverse engineer new, emerging malware families. This work introduces a deep-recurrent neural network classifier for DGA detection which uses an embedding layer to detect malicious and benign domain names in order to avoid overfitting. The authors present a long-term recurrent model of LSTMs that uses a bidirectional GRU algorithm to improve model performance."
A novel approach to maintain orthogonal recurrent weight matrices in a RNN. Introduces a scheme for learning the recurrent parameter matrix in a neural network that uses the Cayley transform and a scaling weight matrix. This study suggests an RNN reparametrization of the recurrent weights with a skew-symmetric matrix using Cayley transform to keep the recurrent weight matrix orthogonal. Novel parametrization of RNNs allows representing orthogonal weight matrices relatively easily.,"A new deep learning architecture for orthogonal and unitary RNNs. This article introduces a deep learning framework for deep learning that is able to solve the vanishing/exploding gradient problem in deep neural networks. The authors introduce a new algorithm for learning deep learning, called scoRNN, which can be used to train deep learning neural networks with low memory usage. This work introduces a new architecture of deep learning based on the Cayley transform","An orthogonal and unitary deep neural network architecture that performs better than the full-capacity uRNNs. This paper proposes a deep learning architecture for deep neural networks where the recurrent matrix is replaced by a diagonal matrix consisting of ones and negative ones. The authors propose an approach to deep learning with deep learning based on deep learning, using deep learning as the main objective.","A new activation function for orthogonal or unitary recurrents, and the full-capacity uRNN from Section 2.2. This article introduces a new activations function for scoRNN that is more efficient than other activation functions. The authors study the problem of scaling a skew-symmetric matrix with gradient descent, and show that the modReLU has improved the performance of the model.","A new activation function for orthogonal or unitary recurrent neural networks. This work introduces a method to improve the performance of the modReLU over other activation functions, such as ReLU. The authors study the problem of scaling the recurrence matrix by scaling the diagonal matrix by a negative one eigenvalue and using a gradient descent algorithm to reduce the complexity of the gradient descent steps."
"Empirical proof of a new phenomenon requires new theoretical insights and is relevent to the active discussions in the literature on SGD and understanding generalization. The paper discusses a phenomenon where neural network training in very specific settings can profit much from a schedule including large learning rates The authors analyze training of residual networks using large cyclic learning rates, and demonstrate fast convergence with cyclic learning rates and evidence of large learning rates acting as regularization.","A new adaptive learning rate method for SGD that can speed up training by an order of magnitude. This article studies the problem of super-convergence in SGD using a cyclical learning rate, and shows that using large learning rates is beneficial for training SGD with very large data sets. This work investigates the issue of hyper-parameterized learning rates in deep learning, and suggests that using very large learning rate methods can help train SGD efficiently.","Super-convergence is a phenomenon that occurs when large learning rates are used to speed up training. The authors propose a new adaptive learning rate method for SGD where the learning rate is relatively small compared to standard learning rates. This paper proposes a new method for improving SGD by using very large learning rate, and shows that it is possible to train SGD with super-conversation.","A super-convergent approach for training with very large learning rates, which adds noise in the middle part of training. This work presents a method to improve SGD performance when the amount of labeled training data is limited and shows that using CLR with very small learning rates can speed up training by an order of magnitude. The authors present a new algorithm for learning rate optimization that uses a Hessian-free optimization method to estimate optimal learning rates.","A super-convergent approach for training with very large learning rates, which adds noise in the middle part of training. The authors show that using CLR with very small learning rates can speed up training by an order of magnitude. This work presents a new method to improve the generalization performance of SGD by reducing the noise level and improving the performance of the training rate."
"A Bayesian Nonparametric Topic Model with Variational Auto-Encoders which achieves the state-of-the-arts on public benchmarks in terms of perplexity, topic coherence and retrieval tasks. This article constructs an infinite Topic Model with Variational Auto-Encoders by combining Nalisnick & Smith's stick-breaking variational auto-encoder with latent Dirichlet allocation and several inference techniques used in Miao.","A Bayesian nonparametric topic model with variational auto-Encoders for a countably infinite set of topics. This work introduces a new class of topic models that can be used to approximate the variational posterior of a given dataset. The authors introduce a new type of topic model, called iTM-VAE-Prod, which is an infinite number of topics and can be approximated using variational inference.","A Bayesian nonparametric topic model with variational auto-Encoders that can approximate a wide range of topics. This paper proposes an infinite topic model based on variational Auto-encoders, which has potentially infinite number of topics and allows the inference to grow as more documents are observed. The authors propose an infinite Topic Model with Variational Auto Encoders (iTM-VAE), which is a Bayesian semi-autometric topic models equipped with Variable Auto-Encoders.","A Bayesian nonparametric topic model equipped with a Variational Auto-Encoders (ITM-VAE), which uses a stick-breaking process BID35 to generate the mixture weights for a countably infinite set of topics. This work introduces an infinite Topic Model that can be approximated using either MCMC sampling or variational inference.","A Bayesian nonparametric topic model equipped with a Variational Auto-Encoders (ITM-VAE). This work introduces an infinite Topic Model, which uses a stick-breaking process BID35 to generate the mixture weights for a countably infinite set of topics and can grow the number of parameters with the amount of training data."
"Finetuning after quantization matches or exceeds full-precision state-of-the-art networks at both 8- and 4-bit quantization. This paper proposes to improve the performance of low-precision models by doing quantization on pre-trained models, using large batches size, and using proper learning rate annealing with longer training time. A method for low bit quantization to enable inference on efficient hardware that achieves full accuracy on ResNet50 with 4-bit weights and activations, based on observations that fine-tuning at low precision introduces noise in the gradient.","A new quantization technique for training low-precision neural networks with integer constraints. This article introduces a method to reduce the gradient noise in deep neural networks by quantizing the weights and activations of the weights. The study presents a method for training neural networks at 8-bit precision, which outperforms the current state-of-the-art methods.","A new method for training low-precision neural networks that outperforms the current state-of-the-art models. This paper proposes a method to train low precision neural networks by quantizing the weights and activations of the weights in order to combat gradient noise. The authors propose a method for improving the accuracy of high precision neural nets on Imagenet benchmark, and show that this method outperforms all other methods.",A new state-of-the-art quantization method for fine-tuning low-precision networks with 8-bit precision exceeds the accuracy of fp32 baseline networks after one epoch of fine tuning. This work presents a method to improve the accuracy and efficiency of high-resolution deep network architectures by leveraging the availability of pretrained models.,A new state-of-the-art method for training low-precision networks with integer constraints. Presents a new state of the art method to combat gradient noise introduced by weight quantization. This work presents a novel method for learning low precision networks that exceeds the accuracy of the full-presence baseline networks after just one epoch of fine-tuning.
"Translating portions of the input during training can improve cross-lingual performance. The study proposes a cross-lingual data augmentation method to improve the language inference and question answering tasks. This paper proposes to augment crosslingual data with heuristic swaps using aligned translations, like bilingual humans do in code-switching.","XNLI data augmentation is a method that replaces a segment of the input text with its translation in another language. This article introduces a new neural machine translation method for cross-lingual word embeddings that uses XNLI, a dataset of 15 different languages. The authors introduce a new method for translating text from one language to another, and show that it can be used with both pretrained and randomly initialized models.","A new method for generating cross-lingual word embeddings in a wide range of languages. This article introduces a new neural machine translation method that replaces a segment of the input text with its translation in another language. The authors introduce a new method to generate cross-language word embedding in a variety of languages, including English, French, German, and Spanish.","A cross-lingual data augmentation method that replaces a segment of the input text with its translation in another language. This work presents a method for generating word embeddings in multiple languages by using a combination of unsupervised and random initialized models. The authors present a new algorithm for combining examples in a single sentence pair and a multi-lingual dataset, which can be used to improve translation performance over a prerained model.","A cross-lingual data augmentation method that replaces a segment of the input text with its translation in a way that each example is solely in one language. The authors introduce a new algorithm for multilingual word embeddings, which can be used to train examples in multiple languages without having to explicitly further align them. This study studies the effectiveness of cross-linguistic neural networks as cross-language augmentors"
new GNN formalism + extensive experiments; showing differences between GGNN/GCN/GAT are smaller than thought The work proposes a new Graph Neural Network architecture that uses Feature-wise Linear Modulation to condition the source-to-target node message-passing based on the target node representation.,"GNN-FiLM outperforms baseline methods on a regression task on molecular graphs and performs competitively on other tasks. This article presents a novel convolutional neural network architecture for molecular graphs that uses graph edges instead of linear layers. The study presents a new Convolutional Neural Network architecture for the molecular graphs, which is based on graph edges and shows that it is more efficient than existing convolutionals.","GNN-FiLM outperforms baseline methods on a regression task on molecular graphs and performs competitively on other tasks. This paper proposes a novel Convolutional Neural Networks (RGDCN) that replaces the learnable message transformation function with a graph activation function. The authors propose a new convolutional neural network for molecular graphs, which uses graph activation functions to replace the learningable message transform function.",Graph Dynamic Convolutional Networks (RGDCN) is a GNN-FiLM model that learns to ignore graph edges based on the representation of target and source nodes. This work presents a new framework for learning to ignore message transformations in a graph domain by using a learnable function f that operates on the edge-type-dependent weights of each edge.,A GNN-FiLM model for molecular graphs that outperforms baseline methods on a regression task and performs competitively on other tasks. This work introduces a new approach for learning to ignore graph edges by replacing the learnable parameters of the model with an edge-type-dependent weight based on the message transformation of target nodes.
"We propose Hierarchical Complement Objective Training, a novel training paradigm to effectively leverage category hierarchy in the labeling space on both image classification and semantic segmentation. A method that regularizes the entropy of the posterior distribution over classes which can be useful for image classsification and segmentation tasks","A new training objective for deep neural models that leverages information from a label hierarchy. This work introduces a new training paradigm for deep learning that leveraged information from labels to improve model performance. This study presents a new approach to training deep neural networks using a hierarchical structure in the label space. The authors present a new method for training a deep neural network with hierarchical information, which leads to significant performance improvement over previous approaches.","A new training paradigm for deep neural models that leverages information from a label hierarchy to improve performance. This paper proposes an approach to train deep neural networks using information from the label hierarchy in order to reduce the likelihood of incorrect classes. The authors propose a new training method for deep-learning models, called Complement Objective Training (HCOT), which aims at reducing the uncertainty between the predicted probabilities of the correct classes and the wrong classes.","An explicit hierarchical model that is trained with an objective to leverage information from a label hierarchy. This article presents a method for training neural models with the goal of penalizing the ""obviously wrong"" classes, and introduces a new hierarchic model architecture that can be used to learn hierarchically. The paper addresses the problem of hierarching in the label space by proposing a Hierarchical Approach to this problem.",An explicit hierarchical model that is trained to penalize the obviously wrong classes at different granularity levels. This work introduces a training paradigm for deep neural models using an objective and a complement objective to leverage information from a label hierarchy. The study presents a method of training neural models with an objective that focuses on maximizing the probability value of the ground truth and the parental category of ground truth in order to minimize the predicted probability of the wrong class.
We introduce a new dataset of logical entailments for the purpose of measuring models' ability to capture and exploit the structure of logical expressions against an entailment prediction task. The study proposes a new model to use deep models for detecting logical entailment as a product of continuous functions over possible worlds. Proposes a new model designed for machine learning with predicting logical entailment.,"A new generative framework for the entailment of convolutional neural networks. This article presents a novel approach to entailment in neural networks, which is based on the notion that propositional logic is invariant to the structure of a given word. The authors present a novel generative process for the problem of entailment, and show that it can be used to train neural networks to capture structure in sequences of images.","A novel generative process for training neural networks to capture entailment. This work proposes a new generative method for detecting entailment in propositional logic, which is decidable but requires a worst case of O(2 n ) operations (e.g. resolution steps, truth table rows), where n is the number of unique propositional variables, to verify entailment on propositional data.","This article introduces a new framework for generative models using propositional logic, which is decidable but requires a worst case of O(2 n) operations to verify entailment. The authors present a model architecture that can capture invariance by using LSTM symbols instead of symbols, and use it as a benchmark to improve the performance of syntactic models on this dataset.","This article introduces a new model architecture that can capture invariance without needing to understand the structure of the problem. The authors present a method for generating propositional variables, which is useful for solving syntactic problems. This work presents a framework for entailment modeling using propositional logic, and discusses the problem of generating representations by using LSTM RNNs as a base-to-linear model."
"We show that training feedforward relu networks with a weak regularizer results in a maximum margin and analyze the implications of this result. Studies margin theory for neural sets and shows that max margin is monotonically increasing in size of the network This study studies the implicit bias of minimizers of a regularized cross entropy loss of a two-layer network with ReLU activations, obtaining a generalization upper bound which does not increase with the network size.","A novel algorithm for optimizing weaklyregularized logistic loss over two-layer relu networks. The authors prove that the regularization of deep neural networks can be achieved with a linear SVM, and show that it is possible to achieve the same result. This article introduces a new algorithm for solving the problem of regularizing logistic losses over two layers of neural networks, and shows that the algorithm can be used to train deep neural nets.","Improving weaklyregularized logistic loss over two-layer relu networks by making the regularization explicit. This paper proposes a new way of generalizing deep neural networks, and shows that it is possible to do so in a non-linear setting. The article proposes a novel algorithm for improving the regularized logistics loss of deep neural nets with multi-layer features.","A new method for understanding generalization on two-layer relu networks. This paper introduces a new way to understand the generalization of two layers of neural networks by making the regularization explicit. The authors present a novel method for interpreting the generalized cross-entropy loss in two layers using a linear predictor, and show that it is possible to use a single layer of neural network as a result of a multilayer neural network.","A new method for understanding the generalization of two-layer relu networks. This work introduces a new way to explain the regularization of neural networks by making it explicit. The authors present a method for proving the normalization in two layer relu network with quadratic activations, and show that there is an analogy between the two layers of the relu feature and the standard kernel SVM with relu features."
"From an incomplete RGB-D scan of a scene, we aim to detect the individual object instances comprising the scene and infer their complete object geometry. Proposes an end-to-end 3D CNN structure which combines color features and 3D features to predict the missing 3D structure of a scene from RGB-D scans. The authors propose a novel end-to-end 3D convolutional network which predicts 3D semantic instance completion as object bounding boxes, class labels and complete object geometry.","An end-to-end approach for 3D semantic instance completion based on image segmentation and instance segmentation. This paper presents a novel method for predicting object segmentation in real-world 3D scans, which uses a deep neural network to predict object segmentations. This work presents a new method for 2D semantic segmentation of 3D 3D images, which is based on a deep Neural Network (NAN) architecture.","This paper proposes a novel method for 3D semantic instance completion based on image segmentation. This work proposes a new approach for the task of predicting object segmentation in real and synthetic scans, which is based on 2 «? 1 «? 1 convolution layer for instance segmentation The authors propose a new method to predict object segmentations in 3D images that can be run on an end-to-end fashion.","A new approach for predicting object detection and instance-level completion for an input partial 3D scan of a scene. This work introduces a new method to predict image segmentation and instance segmentation in the context of semantic scenes. The authors address the problem of query segmentation on real-world scenes, and show that it is more efficient than state-of-the-art approaches.",An end-to-end approach that outperforms state-of-the-art scan completion on SUNCG as well as on real-world ScanNet benchmarks. This work introduces a new method for predicting image segmentation and instance segmentation in the context of a scene by using a convolution layer to output objectness scores for each anchor.
"We propose Convolutional CRFs a fast, powerful and trainable alternative to Fully Connected CRFs. The authors replace the large filtering step in the permutohedral lattice with a spatially varying convolutional kernel and show that inference is more efficient and training is easier. Proposes to perform message passing on a truncated Gaussian kernel CRF using a defined kernel and parallelized message passing on GPU.","A new framework for fully-connected convolution based segmentation that can be implemented on GPUs. This work introduces conditional independence to convolutional neural networks (CNNs) and introduces a conditional independence assumption for the conditional independence of convolution layers in CNNs. The authors introduce a new framework of fully connected CNNs with conditional independence, which allows convolutions to be trained as convolutions with truncated Gaussian kernel",A new framework for fully-connected convolution based segmentation using conditional independence This paper proposes a novel method for training convolutional neural networks (CRFs) with conditional independence. The authors propose to use conditional independence to train convolutions that can be used to generate high-resolution images. This work proposes an approach to learn conditional independence from CNNs in order to improve the performance of ConvCRFs.,A new framework for fully-connected CRFs that can be implemented highly efficiently on GPUs. This work introduces a new framework of fully connected ConvCRFs which uses a Gaussian kernel to improve the performance of CNNs. The authors present a novel framework for learning convolutional neural networks by using a truncated message passing operation and implementing a large proportion of the inference step as a convolution.,"A new framework for fully-connected CRFs, which can be implemented efficiently on GPUs. This work introduces a new framework of fully connected CRF with a Gaussian kernel that can be used to improve the performance of CNNs. The authors address the problem of learning a large part of the inference step to be a convolution with truncated gaussian core"
"Word2net is a novel method for learning neural network representations of words that can use syntactic information to learn better semantic features. This work extends SGNS with an architectural change from a bag-of-words model to a feedforward model, and contributes a new form of regularization by tying a subset of layers between different associated networks. A method to use non-linear combination of context vectors for learning vector representation of words, where the main idea is to replace each word embedding by a neural network.","A new embedding method based on parameter sharing in word2net that captures latent semantic properties of the word. This article introduces a new embeddings method for embedding word/tag pairs in a context of other words. The authors present word2nets, a neural network-based embedding technique that combines conditional probability and parameter sharing to capture latent semantics of words.","A new embedding method for improving the semantic properties of word/tag pairs. This paper proposes a novel embedding technique that uses parameter sharing to improve the predictive performance of word2net. The article proposes a new embeddings method, Word2net, which is based on parameter sharing between the neural network representations of words.","A method to compute semantic (and even syntactic) similarities between the neural network representations of words. This work introduces a method for computing semantic and even syntagic similarities between word2vec and Benoulli embeddings, which can capture semantic properties of the word, but tends to neglect most of the syntaktic information to improve the quality of word representations.","A method to compute syntactic similarities between the neural network representations of the words. This work introduces a new neural network that can capture semantic properties of the word, but they tend to neglect most of it. The authors show that parameter sharing in word2net performs better than applying word2vec or standard Benoulli embeddings on the augmented vocabulary of word/tag pairs."
Comparison of psychophysical and CNN-encoded texture representations in a one-class neural network novelty detection application. This work focuses on novelty detection and shows that psychophysical representations can outperform VGG-encoder features in some part of this task This article considers detecting anomalies in textures and proposes original loss function. Proposes training two anomaly detectors from three different models to detect perceptual anomalies in visual textures.,A novel objective function to train a neural network based on features of a pretrained deep convolutional neural network (CNN) for novelty detection. This work introduces a new objective function that explicitly learns a hyperplane separating reference data and image statistics in order to detect novelty detection in texture representations. The study presents a novel objective method for training neural networks based on the features of CNN-encoded textures.,A novel objective function to train a neural network based on features of a pretrained deep convolutional neural network for novelty detection. This work proposes a new objective function that explicitly learns a hyperplane separating reference data and non-reference data in order to detect visual anomalies. The authors propose a novel objective method to train neural networks based on the features of CNN-encoded texture representations.,A novel objective function to train one-class neural networks for novelty detection in visual surface inspection applications. This work introduces a new texture model based on a pretrained CNN and a method to detect visual anomalies when comparing reference and neural network features. The authors present a novel object-based texture model that learns the feature of a prerained convolutional neural network by learning a hyperplane separating reference data with same image statistics.,This work introduces a novel objective function to train one-class neural networks for novelty detection in visual surface inspection applications. The authors introduce a new objective function that explicitly learns an hyperplane separating reference data and data with the same image statistics. This work presents a model for visual surface inspectors using a neural network to detect visual texture anomalies by comparing features of a pretrained CNN.
Human-like Clustering with CNNs The paper validates the idea that deep convolutional neural networks could learn to cluster input data better than other clustering methods by noting their ability to interpret the context of every input point due to a large field of view. This study combines deep learning for feature representation with the task of human-like unsupervised grouping.,"A hierarchical clustering framework for image segmentation. This article presents a new method for clustering neural networks, based on the idea that clustering is easier for humans than it is for humans. The study presents a hierarchical cluster framework for deep CNNs, which can be used to classify objects in a given image.",A hierarchical clustering framework for image segmentation based on the compositionality of unlabeled data points. This paper proposes a new method for clustering images in order to improve the performance of deep CNNs. The authors propose a hierarchical cluster framework that is more efficient than existing deep neural networks and can be used to classify objects into meaningful clusters.,"Using hierarchical frameworks that progressively build complex patterns on top of the simpler ones (e.g., convolutional neural networks) offers a promising solution for solving clustering tasks. This article introduces a new framework for clustering in an effort to solve clustering problems by focusing on the compositionality of the real world structures and objects.","A deep learning model for clustering and a hierarchical framework that progressively builds complex patterns on top of the simpler ones. This work explores the compositionality of real-world structures and objects in a clustering process, and suggests a new approach to clustering algorithms. The authors address the problem of clustering in neural networks by proposing a differentiating the structure of a large dataset of unlabeled patterns into meaningful clusters."
"We propose tensor contraction and low-rank tensor regression layers to preserve and leverage the multi-linear structure throughout the network, resulting in huge space savings with little to no impact on performance. This article proposes new layer architectures of neural networks using a low-rank representation of tensors This paper incorporates tensor decomposition and tensor regression into CNN by using a new tensor regression layer.","A new deep convolutional neural network based on tensor decompositions, which express the output of a neural network as a low-rank multi-linear mapping from a high-order activation tensor to the softmax layer. This article introduces a new method for learning tensor regression layers in deep neural networks, and shows that it is more robust to changes in rank constraints than traditional linear regression methods.","A new method for training deep convolutional neural networks with tensor decompositions, which express the output of a neural network as a low-rank multi-linear mapping from a high-order activation tensor to the softmax layer. This paper proposes a new method to train deep convolutions with tensors that can be used to reduce the number of parameters in the latent variables. The article introduces a new class of deep Convolutional Neural Networks (CNNs) based on tensor regression and shows that it is more robust to overfitting than other methods.","Using the unfolded expression of the regression weights and the core with respect to each factor can be obtained by writing: DISPLAYFORM1 The paper introduces tensor decompositions, which express the output of a neural network as a low-rank multi-linear mapping from a high-order activation ensor to the softmax layer.",A deep convolutional neural network with a low-rank multi-linear mapping from a high-order activation tensor to the softmax layer. This work introduces a deep recognising neural network (CNN) which expresses the output of a neural network as a lower-rank Multi-Linear Mapping between the inputs and the activations of convolution layers.
"A novel network architecture to perform Deep 3D Zoom or close-ups. A method for creating a ""zoomed image"" for a given input image,and a novel back re-projection reconstruction loss that allows the network to learn underlying 3D structure and maintain a natural appearance. An algorithm for synthesizing 3D-zoom behavior when the camera is moving forward, a network structure incorporating disparity estimation in a GANs framework to synthesize novel views, and a proposed new computer vision task.","Deep 3D-Zoom Net is a novel view generation framework for the novel view synthesis problem. This work introduces a deep neural network architecture that learns to estimate the disparity and normals of the input image in a single pass. The authors introduce a new class of deep neural networks, Deep3DNet, which can be used to generate images for both the KITTI and Cityscapes datasets.",Deep 3D-Zoom Net is a novel view generation framework for the KITTI and Cityscapes datasets. This paper proposes a new neural network architecture to solve the novel view synthesis problem by incorporating disparity and normals estimations in order to improve the final quality of the generated images.,An unsupervised framework for 3D-zoom dataset of natural scenes based on the need for special equipment to ensure camera movement is restricted to the Z-axis. This work presents a novel view synthesis problem for multiple input image scenarios using an off-the-shelf structure from motion algorithm to obtain the camera pose and fixed background points of a given video sequence in combination with traditional optimization techniques to directly estimate the warping operation for each input image.,"An unsupervised framework for learning a 3D-zoom dataset of natural scenes due to the need for special equipment to ensure camera movement is restricted to the Z-axis. This study introduces a novel view synthesis problem for multiple input image scenarios, using an off-the-shelf structure from motion algorithm to obtain the camera pose and fixed background points of a given video sequence in combination with traditional optimization techniques to directly estimate the warping operation."
"We introduce the universal deep neural network compression scheme, which is applicable universally for compression of any models and can perform near-optimally regardless of their weight distribution. Introduces a pipeline for network compression that is similar to deep compression and uses randomized lattice quantization instead of the classical vector quantization, and uses universal source coding (bzip2) instead of Huffman coding.","A universal DNN quantization framework consisting of universal quantization and universal lossless source coding. This work introduces a universal quantizing framework for vector quantization in high resolution images, and shows that it is more efficient than the classical lossy compression framework. The study presents a universal method for quantizing vector quantized DNNs by adding uniform random dithers to the quantized weights.","A universal DNN compression framework consisting of universal quantization and universal lossless source coding. This article proposes a universal DN compression framework for vector quantization, where the number of shared quantized values in each cluster is uniform and the codebook overhead is smaller than that of classical lossy compression methods. The authors propose a universal method for generating vector quantized DNNs using random dithers.",A universal entropy coded vector quantization framework consisting of universal quantization and universal lossless source coding such as LempelZiv-Welch BID13 BID14 BID15 and Burrows-Wheeler transform BID17 This work introduces a universal lattice quantization method for vector quantizing in order to achieve universal performance regardless of source statistics at any rates.,"A universal lossy compression framework consisting of universal quantization and universal lossless source coding such as LempelZiv-Welch BID13 BID14 BID15 and Burrows-Wheeler transform BID16 BID17. This study introduces a universal DNN framework for entropy coded vector quantization, where the rate is infinity and the distortion diminishes."
"A quantitative refinement of the universal approximation theorem via an algebraic approach. The authors derive the universal approximation property proofs algebraically and assert that the results are general to other kinds of neural networks and similar learners. A new proof of Leshno's version of the universal approximation property for neural networks, and new insights into the universal approximation property.","A neural network with two hidden layers of sizes 2n + 1 and 4n + 3 respectively is able to approximate any function f É?? P É?œd (X, R m) to any desired approximation error threshold ◊Ê. The authors prove that the UAP can be used to approximate all non-bias functions in the first layer of a neural network.","A neural network with one hidden layer can approximate any non-bias function. This article proposes a method for learning neural networks with two hidden layers, and shows that it is possible to approximate any class of functions in the first layer without bias. The article presents a theoretical framework for learning deep neural networks based on the assumption that bias weights are not restricted to non-linear functions.","A neural network with one hidden layer can compute a certain class of functions. This article introduces a new neural network to compute non-bias weights, and shows that the first layer has a hidden layer, where the last layer is fixed and randomly chosen from a suitable range. The paper presents a novel neural network for learning non-bipolar functions, which uses a differentiable function called bias weights (resp).","A neural network with a hidden layer that can compute a certain class of functions: R n  R m, where  =  W is the class of non-linear functions. This study introduces a neural network to compute non-bias weights in the first layer, and shows that it holds if they are not fixed and randomly chosen from a suitable range."
"We propose an easy method to train Variational Auto Encoders (VAE) with discrete latent representations, using importance sampling Introducting an importance sampling distribution and using samples from distribution to compute importance-weighted estimate of the gradient This article proposes to use important sampling to optimize VAE with discrete latent variables.","An easy latent variable model that can be trained with stochastic gradient descent on a training data set. This article presents a novel latent variable learning algorithm which can be used to train VAEs with SGVB. The authors introduce a new variant of the FCVAE, where the latent variables are parametrized and the decoder is trained to generate images that fit well to all the training data.","An easy latent variable model that learns to generate binary or categorical representations using stochastic gradient descent. This paper proposes a novel method for training VAEs with SGVB, which is based on reparametrized sampling and can be used to train VAEs in a variety of tasks. The authors propose a new variant of the FC CVAE, which uses parametrization function f(x|z) to learn binary/categorical representations.","The VAE is an easy latent variable model, where the observations x  p(x|z) are dependent on latent variables. This work introduces a method for training VAEs with stochastic gradient descent by using SGVB. The authors present a new VAE estimator that can be used to train them with gbvs, and show that it is useful for learning latent representations (e.g.","The VAE is an easy latent variable model, where the observations x  p(x|z) are dependent on latent variables z  P(z). This work introduces a method to train VAEs using stochastic gradient descent on a training data set, which they call Stochastic Gradient Variational Bayes (SGVB)."
"Linking Wasserstein-trust region entropic policy gradients, and the heat equation. The paper explores the connections between reinforcement learning and the theory of quadratic optimal transport The authors studied policy gradient with change of policies limited by a trust region of Wasserstein distance in the multi-armed bandit setting, showing that in the small steps limit, the policy dynamics are governed by the heat equation (Fokker-Planck equation).","A stochastic gradient ascent for entropy-regularized rewards in the context of on-policy rewards maximization. This article introduces a new algorithm for policy regularization, which is based on the entropy gradient ascent of the policy distance between policies. The work presents a novel algorithm for randomization of policy distances between policies, where entropy is a regularization term and the reward is a free energy function.","A regularization algorithm for policy iteration based on entropy-regularised rewards. This article proposes a novel algorithm for optimizing policy iteration, where entropy is added as a regularization term in order to avoid early convergence to suboptimal policies. The paper proposes a new algorithm for improving policy iteration by adding entropy to the gradient flow of the policy distance between policies.","A regularization term for entropy-regularized policy, which is a free energy functional, named by analogy with a similar quantity in statistical mechanics 1 This article considers the process of policy iteration, that is, finding a sequence of policies ( n ) converging towards the optimal policy.","A regularization term for policy iteration that aims at finding a sequence of policies converging towards the optimal policy  *. This study introduces a new method for iterating policy gradients in the context of entropy-regularized rewards, which can be used as a regularizing term to improve policy diffusion and avoid early convergence to suboptimal policies."
We introduce a scale-invariant neural network architecture for changepoint detection in multivariate time series. The work leverages the concept of wavelet transform within a deep architecture to solve change point detection. This article proposes a pyramid based neural net and applies it to 1D signals with underlying processes occurring at different time scales where the task is change point detection,"A new deep neural network architecture that can detect both abrupt and gradual changes at multiple scales. This work presents a novel deep neural architecture for the detection of abrupt, gradual, and abrupt changepoints in multimodality time series. The study presents a deep neural model for detecting abrupt, abrupt, and gradual changepoints at different scales.","A novel deep neural network architecture that can detect abrupt and gradual changepoints in multimodality time series. This paper proposes a new deep neural net architecture that is able to detect abrupt, gradual, and continuous changepoints at multiple scales. The authors propose a deep neural model for the detection of abrupt or gradual change points in multi-domain time series using a pyramid Recurrent Layer.","A deep neural network architecture that can efficiently identify abrupt and gradual changes at multiple scales. This work introduces a new model for changepoint detection, which can encode short-term and long-term temporal patterns and detect from abrupt to extremely gradual changepoints. The authors present a deep neural networks architecture that is more efficient than baselines and can be used for learning labels for different changes in real-world datasets.","A deep neural network architecture that can efficiently identify abrupt and gradual changes at multiple scales. This work introduces a deep neural networks architecture to detect abrupt and gradually changes in real-world datasets. The authors show that changepoint detection can be treated as a supervised learning problem, and demonstrate that the proposed architecture can encode short-term and long-term temporal patterns and can detect from abrupt to extremely gradual changes over a wide range of timescales."
"A novel graph signal processing framework for quantifying the effects of experimental perturbations in single cell biomedical data. This work introduces several methods to process experimental results on biological cells and proposes a MELD algorithm mapping hard group assignments to soft assignments, allowing relevant groups of cells to be clustered.","MELD learns the EES by filtering the noisy categorical experimental label in the graph frequency domain to recover a smooth signal with continuous values. This work introduces a novel and flexible filter on graph frequency domains to identify cell states that are most or least affected by an experimental perturbation. The study presents a novel algorithm for identifying cell states with different responses to perturbations, which can be used to determine whether a cell is more or less affected than a control condition.",MELD learns the EES by filtering the noisy categorical experimental label in the graph frequency domain to recover a smooth signal with continuous values. This paper proposes a novel and flexible filter on graph frequency domains to identify cell states that are most or least affected by an experimental perturbation. The authors propose a novel method for learning an Enhanced Experimental Signal (EES) that quantifies how prototypical each cell is of each experimental condition.,"A novel clustering algorithm for identifying cell states that are most or least affected by an experimental perturbation. This work introduces a new clustering method for learning the Enhanced Experimental Signal (EES), which quantifies how prototypical each cell is of each experimental condition. The authors present a clustering approach to identify cells that are not affected by a given perturbation, and proposed a two-sample experiment using a graph of cellular states across experimental","A novel clustering algorithm for cell states that are prototypical of experimental or control conditions. This work introduces a clustering approach for learning the EES of TCR activation by filtering the noisy categorical experimental label in the graph frequency domain to recover a smooth signal with continuous values. The authors study the differences between experimental and control conditions, and proposed a new clustering method for identifying cells most or least affected by an experimental perturbation."
"We prove a non-convex convergence rate for the sign stochastic gradient method. The algorithm has links to algorithms like Adam and Rprop, as well as gradient quantisation schemes used in distributed machine learning. Provided a convergence analysis of Sign SGD algorithm for non-covex cases The work explores an algorithm that uses the sign of the gradients instead of actual gradients for training deep models","A new algorithm for deep neural network optimisation that can avoid saddle points. This article introduces a new algorithm called signGD, which is a gradient descent algorithm that avoids saddle points in order to avoid the curvature-induced error. The authors investigate the problem of avoiding saddle points and show that the algorithm can avoid them by avoiding them.","A novel algorithm for deep neural network optimisation that can avoid saddle points. This paper proposes a new algorithm to solve the problem of avoiding saddle points in deep neural networks. The authors propose a method for improving the efficiency of gradient descent algorithms by removing the stochasticity of the objective function, and show that signGD is more efficient than SGD.","Using stochastic gradient evaluations to improve the performance of signSGD. This work presents a method for optimisation that deals with the one norm of the gradient vector, and shows that it can take exponential time to escape saddle points if it gets too close to them BID5. The authors present a technique for assessing the behaviour of signsSGD around saddle points by using a learning rate and a mini-batch schedule.","Using stochastic gradient evaluations to improve the performance of signSGD. This work introduces a method for avoiding saddle points where the objective function has a lower bound, which means that it is possible to avoid large gradient steps downhill indefinitely. The authors investigate the problem of escaping saddle points with a higher bound than gradient descent, and show that there is a better way to do this than SGD on a regular basis."
"Existing pruning methods fail when applied to GANs tackling complex tasks, so we present a simple and robust method to prune generators that works well for a wide variety of networks and tasks. The authors propose a modification to the classic distillation method for the task of compressing a network to address the failure of previous solutions when applied to generative adversarial networks.","A novel compression method for generating images from compressed data that can be used to improve the quality of the compressed generator. This work introduces a new compression technique for image distillation, where the discriminator is trained alongside the teacher and the generator to generate images that are more similar to the original generator.","A novel compression method for generative classification that achieves compelling compression rates with little change in the quality of the compressed generator. This paper proposes a new compression method to improve the performance of generative neural networks by reducing the number of hyperparameters used during distillation. The authors propose a method for generating images from compressed data that can be used to train a new discriminator, which is more efficient than the original generator.","A self-supervised GAN compression method for generative learning that can be used to train a discriminator to make the generator behave more like the original generator suffers from this issue. This work introduces a new discriminator, which is already well trained on the target data set, and a selectively binarize of both networks during distillation of a classification network.",A self-supervised GAN compression method for generative training of a classification network. This work introduces a new discriminator that is already well trained on the target data set and can be used to train a discriminator to make the generator behave more like the original generator suffers from this issue. The authors use a GAN to guide pruning in order to achieve compelling compression rates with little change in the quality of the compressed generator's ouput.
We propose to solve a problem of simultaneous classification and novelty detection within the GAN framework. Proposes a GAN to unify classification and novelty detection. The work presents a method for novelty detection based on a multi-class GAN which is trained to output images generated from a mixture of the nominal and novel distributions. The paper proposes a GAN for novelty detection using a mixture generator with feature matching loss,"A mixture generator that is trained with a Feature Matching loss and which generates samples from a mixture of nominal and novel data distributions is the optimal novelty detector. This work introduces a GAN framework for simultaneous classification and novelty detection based on a mixture generator. The authors introduce a new discriminator classifier, called a mixture-generator, that is capable of generating samples from different distributions of data.","A mixture generator trained with Feature Matching loss for simultaneous classification and novelty detection. This paper proposes to train a mixture generator that generates samples from a mixture of nominal and novel data distributions is the optimal novelty detector. The authors propose a new GAN-based discriminator based on feature matching loss, which facilitates the generator's ability to generate samples from real data distributions.","A GAN-based semi-supervised generator capable of generating samples from a mixture of nominal and novel data distributions This study presents a method for multi-class discriminator training with a generator that generates samples from the mixed distributions of real data. The paper studies the problem of non-supervising Generative Networks (GANs) by minimizing a Feature Matching loss, showing that only a bad generator is able to improve","A GAN-based mixture discriminator that generates samples from a mixture of nominal and novel data distributions is the optimal novelty detector. This work presents a method for semi-supervised classification where only a small fraction of real examples have labels, and the bulk of the real data is unlabeled. The authors introduce a GAN framework to train a multi-class discriminator which is capable of generating samples from the unknown distribution."
"A novel approach to processing graph-structured data by neural networks, leveraging attention over a node's neighborhood. Achieves state-of-the-art results on transductive citation network tasks and an inductive protein-protein interaction task. This article proposes a new method for classifying nodes of a graph, which can be used in semi-supervised scenarios and on a completely new graph. The study introduces a neural network architecture to operate on graph-structured data named Graph Attention Networks. Provides a fair and almost comprehensive discussion of the state of art approaches to learning vector representations for the nodes of a graph.","A graph convolutional model that leverages sparse matrix operations, reducing the storage complexity to linear in the number of nodes and edges and enabling the execution of inductive learning on large graphs. This article introduces a new neural network architecture that combines multi-head attention with nonlinearity in the graph structure.","An attention architecture for graph convolutional neural networks that leverages sparse matrix operations, reducing the storage complexity to linear in the number of nodes and edges and enabling the execution of GAT models on large graphs. This paper proposes a new method for learning GAT based on multi-head attention, which is more efficient than previous methods. The authors propose an attention architecture that combines two different layers of neural networks with a single layer of reinforcement learning.","A new attention mechanism for inductive learning that is directly applicable to graphs that are completely unseen during training. This article introduces a new attention-memory method for learning on graphs with unsupervised access to the global structure of each node by using a shared mechanism. The authors present a novel attention-message method for induction learning, which uses a single-layer feedforward neural network and a nonlinearity function.","A new attention architecture for inductive learning that uses a single-layer feedforward neural network, and is directly applicable to tasks where the model has to generalize to completely unseen graphs. This work introduces a new approach to self-attention by introducing a multi-head approach to the use of a shared attention mechanism to all edges of the graph."
A formal method's approach to skill composition in reinforcement learning tasks The work combines RL and constraints expressed by logical formulas by setting up an automation from scTLTL formulas. Proposes a method that helps to construct policy from learned subtasks on the topic of combining RL tasks with linear temporal logic formulas.,Combine individual Q-functions of existing policies with an energy-based model. This paper presents a new approach to skill composition and multi-task learning/meta-learning where the goal is to obtain a policy that satisfies each of the constituent tasks in the shortest amount of time. The authors present a new method for skill composition that combines individual Qfunctions from existing policies into a new policy that maximizes the reward of individual tasks.,Combining individual Q-functions of existing policies with energy-based models improves skill composition and meta-learning. This paper proposes a new approach to skill composition by combining individual Qfunctions from existing policies into a composite policy that maximizes the average reward of individual tasks. The authors propose a method for skill composition which combines individual Q functions of existing policy with an energy-efficient model.,An approximately optimal composite policy can result from taking the average of the Q-functions of existing policies and finding a maximum of the reward of individual tasks. This article presents a method to learn a multi-task learning policy that achieves the AN D task composition' by using energy-based model DISPLAYFORM1 where E(s) is an energy function that can be represented by a function approximator.,"A composite policy that achieves the AN D task composition (the composite policy maximizes the average reward of individual tasks) with little to no constraints on task distribution at learning time. This work introduces a new strategy for multi-task learning, which can be achieved by using energy-based model DISPLAYFORM1 where the energy function is represented by a function approximator."
"We created a new dataset for data interpretation over plots and also propose a baseline for the same. The authors propose a pipeline to solve the DIP problem involving learning from datasets containing triplets of the form {plot, question, answer} Proposes an algorithm that can interpret data shown in scientific plots.",A multi-staged modular framework for plot question answering. This work introduces a new dataset which contains plots generated from synthetic data and asks a wide range of annotators to answer questions. The study presents a novel dataset with a large number of plot templates that can be used to solve the problem of plot question solving.,"A multi-staged modular framework for answering questions from synthetic data. This paper proposes a modular framework to solve the problem of plot question answering by learning from datasets containing triplets of the form \{plots, questions, answers}. The authors propose a new dataset which contains plots that contain multiple-choice questions and then use compositional semantic parsing to select the correct answer.","A modular framework for plot question answering. This paper presents a novel test set which contains plots based on data extracted from Open Government Data as opposed to World Bank Data. The authors present a multi-staged dataset that contains triplets of the form plot, question, answer and show that plots are realistic with different scales including floating point numbers and floating point integers in a fixed range.","A multi-staged modular framework with various sub-components to extract relevant data from the plot and convert it to a semi-structured table. This work introduces a novel test set for question answering using a plot of triplets of the form plot, question, answer as well as a new dataset which contains plots generated from synthetic data with limited (i) $x-y$ axes variables."
Combine information between pre-built word embedding and task-specific word representation to address out-of-vocabulary issue This article proposes an approach to improve the out-of-vocabulary embedding prediction for the task of modeling dialogue conversations with sizable gains over the baselines. Proposes combining external pretrained word embeddings and pretrained word embeddings on training data by keeping them as two views. Proposes method to extend the coverage of pre-trained word embeddings to deal with the OOV problem that arises when applying them to conversational datasets and applies new variants of LSTM-based model to the task of response-selection in dialogue modeling.,Combine pre-trained word embedding vectors with character-composed word vectors on Ubuntu Dialogue Corpus and obtained state-of-the-art results on the Stanford Natural Language Inference (SNLI) Corpus. Presents a new language model based on vector concatenation that combines character-level embedding and character-based word vectors. This work presents a novel language model for dialog and dialogue that combines pre-training word vectors with LSTM neural networks.,"Combine pre-trained word embedding vectors with text corpus based on vector concatenation This paper proposes a new language model that combines character-composed word embeddings and text corpus to address out-of-vocabulary word issues. The authors propose a novel language model for the task of dialog, which is based on cross-word embedding by combining the pre-training word vectors with the existing text corpus.",A new ESIM model that can be used to improve the performance of dialogue corpus and doban conversation corpus. This work introduces a novel method for learning word embedding vectors on a general text corpus by using pre-training them with semantic knowledge from ConceptNet BID25 and merging them into a common representation BID24.,A deep neural network model for addressing out-of-vocabulary word issues that can be used to enrich word representations. This study introduces a method to combine pre-trained word embedding vectors with those generated on a general text corpus and the existing model with structured knowledge from semantic network ConceptNet BID25 and merge them into a common representation BID24.
Acquire states from high frequency region for search-control in Dyna. The authors propose to do sampling in the high-frequency domain to increase the sample efficiency This article proposes a new way to select states from which do do transitions in dyna algorithm.,"A simple method to locally measure the frequency of a function by gradient norm, and provide theoretical justification for this approach. This work introduces a new algorithm for learning a function with as few samples as possible, which is more difficult to approximate and requires more training data. The authors introduce a new deep learning algorithm called Dyna-Value, which uses gradient ascent to obtain samples from high-frequency regions of the state space.","A simple method to locally measure the frequency of a function by gradient norm, and provide theoretical justification for this approach. This paper proposes a new algorithm for learning a function with as few samples as possible, based on the idea that it is more difficult to approximate a function in high-frequency regions of the state space. The authors propose a method to learn a function using a gradient norm instead of a loss function","A simple strategy to locally measure the frequency of a function's frequency by gradient norm, and provide a theoretical justification for this approach. This work introduces a dynamic algorithm to localize the frequency in a signal's domain and provides a method to quantify the difficulty of estimation. The authors present a model-free architecture for RL that can be used to estimate the frequency on a point in the state space using a gradient norm.","A method to locally measure the frequency of a function's point in the domain and provide a theoretical justification for this approach. This study introduces a method to localize the number of samples required for its reconstruction in an online RL setting. The authors present a new strategy to locally estimate the frequency on a state space by using a gradient norm, which can be used to determine how much it is needed to learn from the state space."
"We perform large scale experiments to show that a simple online variant of distillation can help us scale distributed neural network training to more machines. Proposes a method to scale distributed training beyond the current limits of mini-batch stochastic gradient descent Proposal for an online distillation method called co-distillation, applied at scale, where two different models are trained to match predictions of the other model in addition to minimizing its own loss. Online distillation technique is introduced to accelerate traditional algorithms for large-scaled distributed neural network training","An ensemble distillation algorithm for asynchronous and synchronous SGD. This work introduces a new distillation method for asynchronous SGD, which is more efficient than traditional distillation methods. The authors present a method for distillation of neural networks to reduce prediction churn and improve performance. This article presents a method to distill the predictions of two different neural networks into a single distillation term.","An ensemble distillation algorithm that does not lose the reproducibility benefits of distributed SGD. This article proposes a method for distillation of neural networks to reduce prediction churn in order to improve performance on asynchronous SGD and synchronous SGD, showing that distillation is more effective than regular distillation. The authors propose a method to distill neural networks into an ensemble with different weights which can be used to compute predictions.","Using ensemble distillation to reduce prediction churn is a good way of reducing the reproducibility benefits of codistillation. This work presents a novel method for training neural networks that can be used to improve the performance of recurrent models, and shows it does not lose the reproducibilities of ensembles of the same model. The authors present a method for learning weights that are only available on a small subset of the training data.","Using ensemble distillation to reduce prediction churn in training neural networks. This study studies the reproducibility benefits of codistillation, and shows that it does not lose the reproducibility benefits of ensembles of neural networks, reducing churin in the predictions of different retrains of the same model. The authors present a novel method for reducing prediction loss by using stale predictions instead of up-to-date predictions."
"Our approach is the first attempt to leverage a sequential latent variable model for knowledge selection in the multi-turn knowledge-grounded dialogue. It achieves the new state-of-the-art performance on Wizard of Wikipedia benchmark. A sequential latent variable model for knowledge selection in dialogue generation that extends the posterior attention model to the latent knowledge selection problem and achieves higher performances than previous state-of-the-art models. A novel architecture for selecting knowledge-grounded multi-turn dialogue that yields state of the art on relevant benchmarks datasets, and scores higher in human evaluations.","A sequential latent variable model for knowledge selection in multi-turn knowledge-grounded dialogue. This paper presents a novel method for learning from a large pool of knowledge candidates in open-domain knowledge-based dialogue. The authors present a novel latent model for the task of knowledge selection, which can be used to improve the accuracy of the knowledge selection and subsequent utterances.","A sequential latent variable model for knowledge selection in open-domain multi-turn dialogue. This paper proposes a sequential latent model to address the problem of knowledge selection, which has not been studied yet. The study proposes a novel method for learning from a dataset of open domain dialogues that combines two approaches: sequential latent modeling and autoencoder inference.","An open-domain model for multi-turn knowledge-grounded dialogue. This article introduces a latent variable model for knowledge selection, which uses the posterior knowledge distribution as a pseudo-label to improve the accuracy of knowledge selection and subsequently utterance generation. The authors present a new approach to multi-twin knowledge-based dialogue by decomposing it into two sub-problems.",A sequential latent variable model for multi-turn knowledge-grounded dialogue. This work presents a novel approach to multi-open-domain knowledge-based dialogue by decomposing it into two sub-problems: first selecting knowledge from a large pool of candidates and generating a response based on the selected knowledge and context. The authors present a method for understanding the history of knowledge selection with and without knowing the response in previous turns.
"Neural Network Verification for Temporal Properties and Sequence Generation Models This work extends interval bound propagation to recurrent computation and auto-regressive models, introduces and extends Signal Temporal Logic for specifying temporal contraints, and provides proof that STL with bound propagation can ensure neural models conform to temporal specification. A way to train time-series regressors verifiably with respect to a set of rules defined by signal temporal logic, and work in deriving bound propagation rules for the STL language.","A novel verification procedure for deep neural networks that leads to sequential outputs. This work presents a novel verification method for deep reinforcement learning, which is based on the principle of temporal specifications. The authors present a new method for training deep RL agents with temporal specifications, and show that it can be used to train models that are provably consistent with specifications.","A method for verification of deep neural networks that is provably consistent with temporal specifications. This work proposes a new language model based on Signal Temporal Logic (STL), which provides guarantees with regard to temporal specifications in RL. The paper proposes a novel language model that is able to verify the temporal specifications of RNNs and can be used to train models that are provably robust to temporal specification.",A simplified verification method for verifiably robust models. This article introduces a novel verification procedure for deep neural networks that can be trained without formal guarantees of their correctness and functionality. The paper considers the problem of learning a trace-valued function to conform to a specification of the form x  S. The study presents a method for verification of neural networks using over-approximations and a new model verification technique.,"A new verification method for deep neural networks that performs well in terms of test error or reward. This study introduces a novel verification method to verify the robustness of neural networks, and uses it as a specification language to provide guarantees on temporal specifications. The authors consider the problem of learning a trace-value function to verifiably satisfy a specific specification of the form x  S."
We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study. Analysis of embedding psaces in a non-parametric (example-based_ way,"A method for visualizing the different dimensions of an embedding space and comparing them to each other with respect to interpretable dimensions of variability. This work presents a new way of visualizing a representation of a deep learning dataset, where the goal is to obtain a better understanding of the distribution of information between different embeddings. The authors present a new approach to visualizing two different embedding spaces in order to provide a more general view of the problem.",Improving the accuracy of PCA models by visualizing the first two dimensions of each embedding space. This paper proposes a method to visualize the first and second dimensions of a PCA projection using a Cartesian view. The authors propose a method for visualizing both the original and the new embedding spaces in order to obtain more accurate information about how different representations of words relate to each other.,A better understanding of the embedded space may lead to critical insights in improving such models. This article introduces a new way of visualizing the original embedding space and topical clusters that are close in the original high-dimensional space to be close within the lower dimensional projection space.,"A better understanding of the embedded space may lead to critical insights in improving such models. This study presents a novel way to learn how embeddings relate to each other with respect to dimensions of variability, and shows that it's possible to use a set of axes to identify differences between the two dimensions of variation. The authors present a method for learning a wide range of variables in a large-scale dataset"
"a joint model and gradient sparsification method for federated learning Applies variational dropout to reduce the communication cost of distributed training of neural networks, and does experiments on mnist, cifar10 and svhn datasets. The authors propose an algorithm that reduces communication costs in federated learning by sending sparse gradients from device to server and back. Combines distributed optimization algorithm with variational dropout to sparsify the gradients sent to master server from local learners.",A federated learning framework for Bayesian neural networks that achieves convergence and communication cost while reducing the amount of gradients exchanged during the iterative training process. This work introduces a method to jointly and iteratively sparsify the parameters of the shared model to be learned as well as the gradients exchanging between the server and the participating devices during the distributed SGD training process This article presents a method for jointly learning a deep neural network using variational dropout,"A federated learning framework that jointly sparsify Bayesian neural networks while reducing the amount of gradients exchanged during the iterative training process. This paper proposes a method to jointly learn Bayesian models by sharing gradients between different devices in order to reduce communication overhead. The authors propose a method for jointly and iteratively sparsifying Bayesian deep neural networks using variational dropout, which reduces the communication overhead and improves the prediction accuracy.","A method to jointly learn a sparse model while reducing the amount of gradients exchanged during the iterative training process. The authors proposed an efficient federated learning framework that meets both model and communication constraints. This article introduces a method for sparsifying deep neural networks using variational dropout, which can be used to sparsify Bayesian neural networks by an order of magnitude without losing the prediction accuracy.",An efficient federated learning framework that meets both communication and communication constraints. This work introduces a method to jointly learn a sparse model while reducing the amount of gradients exchanged during the iterative training process. The authors present a novel method for sparsifying deep neural networks by pruning the weights whose learned dropout rates are high while still achieving comparable predictive accuracies compared to the unpruned ones.
"Discrete transformer which uses hard attention to ensure that each step only depends on a fixed context. This paper presents modifications to the standard transformer architecture with the goal of improving interpretability while retaining performance in NLP tasks. This study proposes three Discrete Transformers: a discrete and stochastic Gumbel-softmax based attention module, a two-stream syntactic and semantic transformer, and sparsity regularization.","A novel transformer architecture for machine translation with sparse attention. This work introduces a new model architecture that uses sparse attention in the context of prediction. The authors introduce a new transformer architecture that combines sparse attention with a multi-headed attention mechanism. The study presents a novel model architecture for translating sentences from soft to soft attention, where the attention layer is composed of multiple layers and each layer receives a different input.",An attention-based model for machine translation based on sparse attention. This paper proposes a new architecture for learning models with sparse attention that is more interpretable than soft attention. The authors propose to use sparse attention in machine translation by replacing the attention mechanism with a non-attention mechanism. This work proposes an attention-driven model which uses sparse attention to train models with high accuracy and low recurrence rates.,"A method for learning discrete attention by modifying the attention mechanism and objective function to improve model interpretability. This work introduces a novel approach to learning discretized attention by using a sparse attention mechanism, which can be used to improve machine translation performance. The paper presents a new approach for learning soft attention models by incorporating attention as a categorical latent variable and a ""syntactic"" attention mechanism in the input structure.","An approach for learning a discrete attention mechanism by modifying the attention mechanism and objective function to improve model interpretability. This study introduces a novel approach to learn a neural network model using attention as a categorical latent variable and a ""syntactic"" semantic variable to get discrete decisions. The authors present a method for learning more discrete inputs in a machine translation dataset"
We propose a subset selection algorithm that is trainable with gradient based methods yet achieves near optimal performance via submodular optimization. Proposes a neural network based model that integrates submodular function by combining gradient based optimization technique with submodular framework named 'Differentiable Greedy Network' (DGN). Proposes a neural network that aims to select a subset of elements (e.g. selecting k sentences that are mostly related to a claim from a set of retrieved docs),"Deep unfolding BID9 is a method to derive novel neural networks that are interpretable as inference algorithms by turning iterations of the inference algorithms into layers of a network. This work introduces a new deep learning algorithm called Deep Gaining Networks (DGN), which combines the advantages of deep learning and generative models with the benefits of inference.","Deep unfolding BID9 is a method to derive novel neural networks that are interpretable as inference algorithms by turning iterations of the inference algorithms into layers of a network. This paper proposes a new deep unfolding algorithm, DeepGN, which performs better than existing models in terms of submodular objective functions. The authors propose a new feedforward greedy algorithm for inference and show that it outperforms existing models on several tasks.","A deep unfolding technique that combines the two extremes of generative models and deep learning models. This work presents a deep-encoder-based method to derive novel network architectures that are interpretable as inference algorithms by turning iterations of the inference algorithm into layers of a network. The authors present a method for deep learning, combining the advantages of deep learning with deep learning and a deeper feed-forward approach.","A deep learning technique that combines the two extremes of generative models and deep learning models. This work presents deep unfolding BID9, a method to derive novel network architectures that are interpretable as inference algorithms by turning them into layers of a network. The authors present a deep learning approach for deep learning with an emphasis on the importance of modeling dependence between sentences and submodular objective functions."
"We propose a simple and general approach that avoids a mode collapse problem in various conditional GANs. The work proposes a regularization term for the conditional GAN objective in order to promote diverse multimodal generation and prevent mode collapse. The article proposes a method for generating diverse outputs for various conditional GAN frameworks including image-to-image translation, image-inpainting, and video prediction, which can be applied to various conditional synthesis frameworks for various tasks.","A conditional Generative Adversarial Network that learns a multi-modal mapping from input to output, and the generated distribution is getting closer to the actual distribution. This paper presents a novel conditional GAN which learns a map from latent code to output in order to resolve the mode-collapse problem in conditional generative tasks.","A conditional Generative Adversarial Network (GAN) which learns a multi-modal mapping from input to output, and the generated distribution is getting closer to the actual distribution. This paper proposes a novel adversarial network based on conditional GAN that learns a map of latent codes to similar outputs. The authors propose a new model for conditional generative networks where the generator maps latent code to different outputs.","A Generative Adversarial Network which learns both conditional generator G and discriminator D by learning a multi-modal mapping from latent code to output by optimizing the adversarial objective of the generator. This article considers the mode-collapse problem in many conditional generative tasks, especially for high-dimensional input and output.","A Generative Adversarial Network that learns both conditional generator G and discriminator D by optimizing the adversarial objective of the generator. This work introduces a multi-modal mapping method for mode-collapse, which can be used to solve the mode colapse problem in many conditional generative tasks, especially for high-dimensional inputs and outputs."
"A method that trains large capacity neural networks with significantly improved accuracy and lower dynamic computational cost A method to train a network with large capacity, only parts of which are used at inference time dependent on input, using fine-grained conditional selection and a new method of regularization, ""batch shaping.""","A batch-shaping loss for convolutional neural networks that is conditionally activated at the start of training and improves performance significantly. This work introduces a new gating method to train deep neural networks with high sparsity, and shows that it can be used to train a deep neural network with very large sparsity. The study presents a new Gating method for training deep neural nets with high levels of sparsification.",A batch-shaping loss for ResNet-BAS neural networks. This paper proposes a method to train deep neural networks that is conditionally conditioned on the input and outputs of each gate in the network to be more conditionally activated at the start of training and improve performance significantly. The authors propose a new gating module which can be used to train neural networks with less sparsification than existing Gating modules.,"A new batch-shaping loss for deep neural networks that can be trained with very large capacity. This work introduces a batch Shaping and a method for training deep neural network architectures by conditionally turning parts of the architecture on or off. This article presents a novel batch-Shaping solution to the task loss problem, which is based on two fully connected layers, with only 16 neurons in the hidden layer.","This work introduces a new batch-shaping loss that can be used to train neural networks with very large capacity while keeping the computational overhead small. The authors present a method for training neural networks without the need for sparsification by using a feed-forward design of two fully connected layers, with only 16 neurons in the hidden layer. This study studies the effectiveness of batch-Shaping losses in deep ResNet-BAS networks"
"We diagnose deep neural networks for 3D point cloud processing to explore the utility of different network architectures. The paper investigates different neural network architectures for 3D point cloud processing and proposes metrics for adversarial robustness, rotational robustness, and neighborhood consistency.","A new deep neural network architecture for 3D point cloud processing. This study presents a deep neural net architecture that learns to represent 3D objects in 3D. The authors present a new neural network based on PointConv, which is designed to be used as a reinforcement learning framework for point cloud computing. This work presents a novel approach to the problem of learning 3D object representations by using a single layer of neural networks","PointConv is a deep neural network that learns intermediate layers of 3D point clouds. This paper proposes a new approach to the problem of information discarding in 2D point cloud architectures, based on PointNet++ and PointConv. The article proposes a method for learning intermediate layers from different points of a point cloud, which uses a special orientation encoding unit to learn an orientation-aware feature for each point.","A method to quantify the utility of different network architectures. This article presents a method for evaluating the usefulness of different networks in the context of 3D point clouds, and shows that DNNs can learn an orientation-aware feature for each point cloud. The authors address the problem of determining how much information is discarded during the computation of an intermediate layer feature by using a distance encoding unit (i.e., Architecture 4).","A method for calculating the utility of different network architectures. This work presents a method for learning an intermediate layer feature that is discarded during the computation of a 3D point cloud. The authors address the problem of determining how much information is discarded during computation of an intermediate-layer feature, and show that it is possible to learn a new orientation-aware feature for each point in N(i)."
"Optimized gated deep learning architectures for sensor fusion is proposed. The authors improve upon several limitations of the baseline negated architecture by proposing a coarser-grained gated fusion architecture and a two-stage gated fusion architecture Proposes two gated deep learning architectures for sensor fusion and by having the grouped features, demonstrates improved performance, especially in the presence of random sensor noise and failures.","A new netgated architecture which learns robustly a set of fusion weights at the (feature) group level. This work introduces a new gating architecture for neural network architectures, FG-GFA, which combines feature-level and group-level fusion weights. This study presents a new net-gated framework for neural networks that is more robust to noisy or corrupted features than the baseline netgate architecture.","A new netgated architecture which learns robustly a set of fusion weights at the (feature) group level. This study proposes a new gated architecture that exploits both the feature-level and group-level fusion weights, leading to further performance improvements. The authors propose a new network architecture based on two different fusion weights: FG-GFA and 2S-GPA.","A new coarser-grained gated architecture which learns robustly a set of fusion weights at the group level, leading to further performance improvements. This work introduces a two-stage gating architecture that exploits both the feature-level and group-level fusionweights to address the limitations of the negated architecture in terms of inconsistency and lack of diverse fusion mechanisms.","A new coarser-grained gated architecture which learns robustly a set of fusion weights at the (feature) group level, leading to further performance improvements. This work introduces a two-stage gating architecture that exploits both the feature-level and group-level fusionweights to address the limitations of the negated architecture in terms of inconsistency and lack of diverse fusion mechanisms."
We present Evolutionary EM as a novel algorithm for unsupervised training of generative models with binary latent variables that intimately connects variational EM with evolutionary optimization The article presents a combination of evolutionary computation and variational EM for models with binary latent variables represented via a particle-based approximation The study makes an attempt to tightly integrate expectation-maximization training algorithms with evolutionary algorithms.,Probabilistic generative models with binary hidden variables can be used for variational optimization in the variational loop of EM. This study presents a probabilistic model that is optimized according to a variational expectation maximization objective. The authors present a probababilistic approach to variational parameter optimization of probabilized generative model with binary latent variables.,"Probabilistic generative models with binary hidden variables can be used for variational optimization. This study proposes a probabilistic approach to generate data points in the variational loop of deep neural networks, and proposes an approach to generating data points using binary latent variables. The authors propose a new model for generative modeling that is more efficient than the original model by optimizing the latent states.","A novel variational optimization algorithm for probabilistic generative models with binary hidden variables This article introduces a method for learning probabilistic latent states of individuals using variational expectation maximization (E-step) and an approximate maximum likelihood optimization algorithm. The authors present a novel variant of neural networks that can be used to learn the latent state of individual genomes, and show that evolutional algorithms can be applied to the variational E-step.",A novel probabilistic generative model with binary hidden variables that can be used for the variational optimization loop. This work introduces a novel method for learning probabilistic models with binary-hidden variables and shows that evolutional algorithms can be applied to the latent states as genomes of individuals. This study studies the applicability and scalability of probability generative models using variational expectation maximization (E-step).
"We closely analyze the VAE objective function and draw novel conclusions that lead to simple enhancements. Proposes a two-stage VAE method to generate high-quality samples and avoid blurriness. This work analyzes the Gaussian VAEs. The study provides a number of theoretical results on ""vanilla"" Gaussian Variational Auto-Encoders, which are then used to build a new algorithm called ""2 stage VAEs"".","A Gaussian-based VAE pipeline that achieves the global optimum and yet does not assign the ground-truth probability measure. The authors present a Gaussian architecture for the first-stage VAE, which is based on the assumption that the latent dimension is equal to the ambient dimension. This paper presents a Gauss-based approach to the problem of finding the ground truth probability measure for continuous data, and shows that Gaussian methods can be used to achieve the objective.",A VAE pipeline that can achieve the global optimum and yet do not assign a ground-truth probability measure. This paper proposes a new VAE model for continuous data where the latent dimension is equal to the ambient dimension. The authors propose a VAE framework that can be used to improve the quality of continuous data by using Gaussian assumptions in the first and second stages.,"A VAE pipeline that can produce stable FID scores, an influential recent metric for evaluating generated sample quality BID16. This work introduces a new VAE parameterization framework that can be used to evaluate the latent dimension of a high-dimensional manifold. The authors present a VAE model with low-dimensional representations that is capable of reconstructing all x   using any z drawn from q|x.","A VAE pipeline that can produce stable FID scores, an influential recent metric for evaluating generated sample quality BID16. This work introduces a VAE model with low-dimensional representations that performs well in the context of high-dimensional space. The authors present a novel VAE parameterization framework that generates reliable FIDs, and show that it is possible to achieve the global optimum by using a Gaussian assumption."
"We describe an end-to-end differentiable model for QA that learns to represent spans of text in the question as denotations in knowledge graph, by learning both neural modules for composition and the syntactic structure of the sentence. This article presents a model for visual question answering that can learn both parameters and structure predictors for a modular neural network, without supervised structures or assistance from a syntactic parser. Proposes for training a question answering model from answers only and a KB by learning latent trees that capture the syntax and learn the semantic of words","A neural network framework for answering compositional questions using a Knowledge Graph (KG). This work presents a model for answering question answering that combines phrases with a knowledge graph, resulting in a deep latent tree that answers the question. The study presents a neural network architecture for answer-to-question answering that is grounded in the Knowledge Graph, and shows that it can be used to solve compositional question answering tasks.","A framework for answering compositional question answering based on a Knowledge Graph (KG) model. This paper proposes an approach to answer compositional questions by building a knowledge graph with a representation of a sentence that is grounded in the KG. The authors propose a framework for solving compositional and semantic question answering, which combines phrases from different semantic types into a soft latent tree that can be used to generate answers.","A neural network approach for question answering with a parse and a latent tree that provides the answer. This work introduces a method for query answering in which phrases are grounded in the KG, and uses a recurrent neural network to combine phrases into a span representing functions that cannot yet be grounded in KG.","A neural network approach for question answering with a span of text that is represented by a denotation in a knowledge graph, and a vector that captures ungrounded aspects of meaning. This work explores the problem of question answering using a tree of interpretable expressions, and uses a recurrent neural network to build a representation for a question sentence."
"Couple the GAN based image restoration framework with another task-specific network to generate realistic image while preserving task-specific features. A novel method of Task-GAN of image coupling that couples GAN and a task-specific network, which alleviates to avoid hallucination or mode collapse. The authors propose to augment GAN-based image restoration with another task-specific branch, such as classification tasks, for further improvement.","Task Generative Adversarial Network (GAN) for image restoration. This work introduces a task-driven GAN framework to improve the accuracy of image restoration on medical imaging and natural image applications. The study presents a new approach to image restoration based on task-based GANs that includes a task network, a generator and a discriminator network.",Task Generative Adversarial Network (GAN) for image restoration. This work proposes a task-based GAN framework to improve the accuracy of image restoration on medical imaging and natural image applications. The authors propose a new GAN based model that combines task-driven adversarial networks with task-oriented adversarial Networks to improve image restoration accuracy. This paper proposes a novel approach to image restoration by combining task-generated adversarial network with task generated adversarial nets,"A GAN-based image restoration framework that combines task-driven loss and discriminator network to ensure both visually plausible and more accurate image restoration. This work introduces a task-oriented loss-based approach for super-human level automatic classification/diagnosis. The article presents a new method for image restoration, which can be used for image reconstruction by using a GAN as a result of a problem-based loss function.","A new task-based image restoration framework for realizing and preserving information important to the downstream tasks. This work introduces a task-driven loss network to ensure both visually plausible and more accurate (medical/face) image restoration. The authors present a method for super-human level automatic classification/diagnosis using GANs, which provides a generalization of the proposed method for image restoration in vivo clinical medical imaging datasets."
"Make deep reinforcement learning in large state-action spaces more efficient using structured exploration with deep hierarchical policies. A method to coordinate agent behaviour by using policies that have shared latent structure, a variational policy optimization method to optimize the coordinated policies, and a derivation of the authors' variational, hierarchical update. This article suggests an algorithmic innovation consisting of hierarchical latent variables for coordinated exploration in multi-agent settings","A structured probabilistic policy class that uses a hierarchy of stochastic latent variables to train agents in multi-agent environments. This work introduces a new deep learning framework for the multi agent reinforcement learning problem with a centralized controller. The authors introduce a hierarchical model of a multi agent policy class, and show that it improves sample complexity on cooperative games with large number of agents.","A structured probabilistic policy class that uses a hierarchy of stochastic latent variables to train agents in multi-agent environments. This paper proposes a novel approach to structured exploration, which introduces a hierarchical model of the agentÉ??s policy structure and shows that it improves sample complexity on coordination games with large number of agents.","This paper introduces a structured probabilistic policy class that uses a hierarchy of stochastic latent variables to train the policy end-to-end. Introduces an efficient and principled algorithm using variational methods to train multi-agent policies with a large number of agents. This article presents a method for learning multiple actions from a wide range of agents in a variety of different environments, and shows how they can learn more efficiently.","A structured probabilistic policy class that uses a hierarchy of stochastic latent variables to train the policy end-to-end. This work presents a method for learning multi-agent environments that explicitly require team coordination, and feature competitive pressures that are characteristic of many coordinated decision problems. The authors present a model for multi-Agent environments with a large number of agents, and show that learned latent structures correlate with meaningful co-ordination patterns."
"Explaining the generalization of stochastic deep learning algorithms, theoretically and empirically, via ensemble robustness This article presents an adaptation of the algorithmic robustness of Xu&Mannor'12 and presents learning bounds and an experimental showing correlation between empirical ensemble robustness and generalization error. Proposes a article of the generalization ability of deep learning algorithms using an extension of notion of stability called ensemble robustness and gives bounds on generalization error of a randomized algorithm in terms of stability parameter and provides empirical study attempting to connect theory with practice. The work studied the generalization ability of learning algorithms from the robustness viewpoint in a deep learning context","An ensemble robustness approach for deep neural networks based on their generalization performance. This study studies the generalization ability of deep neural nets based on the ensemble randomness of the training examples. The study presents a method for predicting the robustness of a deep neural network based on its ensemble Randomness, which is correlated with its generalization.","An ensemble robustness approach to generalization of deep neural networks. This paper proposes a method for predicting the generalization ability of deep learning algorithms based on their ensemble-based robustness and stability. The article proposes an ensemble robustity approach to training deep neural nets based on stochastic robustness, which is correlated with its generalization performance. A method for evaluating the robustness of a deep learning algorithm based on its empirical loss","A robustness algorithm for deep learning that is correlated with its generalization performance. This work introduces a robustness approach to the generalization of deep neural networks, which uses backpropagation to learn a probability distribution on the weights of a neural network by minimizing the expected lower bound on the marginal likelihood (or the variational free energy).",A deep learning algorithm that is robust to perturbed samples. This work presents a robustness approach to the generalization of deep neural networks by minimizing the expected lower bound on the variational free energy. The authors present a deep learning model with robustness and a method to learn a probability distribution on the weights of a neural network using backpropagation to minimize the expected low bound for the variable free energy in order to improve performance.
"An architecture for tabular data, which emulates branches of decision trees and uses dense residual connectivity This article proposes deep neural forest, an algorithm which targets tabular data and integrates strong points of gradient boosting of decision trees. A novel neural network architecture mimicking how decision forests work to tackle the general problem of training deep models for tabular data and showcasing effectiveness on par with GBDT.","A deep neural tree architecture that combines elements from decision trees as well as dense residual connections in a hybrid deep architecture. This work presents a novel architecture for tabular and multi-modal data, which combines elements of decision trees and sparse residual connections. The study presents a new deep neural architecture, called Deep Neural Trees (DNF), that combines the elements from a decision tree and a sparse residual connection.","A hybrid deep neural architecture that combines elements from decision trees and dense residual connections to achieve significant performance gains in tabular and multi-modal settings. This work proposes a hybrid deep network architecture for tabular data, which combines elements of decision trees as well as dense residual links. The authors propose a novel deep neural tree architecture based on the idea of embedding decision trees into a neural network.","A novel neural network architecture that combines decision trees and dense residual connections. This work presents a novel architecture for neural models that achieves performance on the level of GBDTs. The authors present a deep neural forests architecture that is intrinsically interpretable, as if it were a conventional decision tree induction algorithm. This article introduces a new neural model architecture that integrates decision trees into a multi-modal dataset with a single decision tree.","A novel deep neural network architecture that combines decision trees and dense residual connections. This work introduces a new deep neural forests architecture which combines the decision trees with dense residual links. The authors present a deep neural model architecture for tabular data that is intrinsically interpretable, as if it were a conventional decision tree induction algorithm. This study presents a method for building neural models that achieve performance on the level of GBDTs."
"An adversarial defense method bridging robustness of deep neural nets with Lyapunov stability The authors formulate training NNs as finding an optimal controller for a discrete dynamical system, allowing them to use method of successive approximations to train a NN in a way to be more robust to adversarial attacks. This article uses the theoretical view of a neural network as a discretized ODE to develop a robust control theory aimed at training the network while enforcing robustness.","Decoupled training of deep neural networks with Lyapunov stability of dynamical systems This paper presents a new method for training neural networks to improve the adversarial robustness of the models. This work introduces a new approach to training deep neural nets, which is based on a dynamical system view of neural networks.","A dynamical system view of deep neural networks that bridges adversarial robustness with Lyapunov stability. This paper proposes a new method for training neural networks to improve the robustness of the models. The authors propose a novel approach to train neural networks based on a dynamical framework, and show that it is more robust to adversarial perturbations than traditional methods.","A dynamical neural network that is robust to all adversarial perturbations. This article introduces a dynamical system view on the adversariality of neural networks, and proposed a new approach to combat adversarially robustness in deep residual networks. The paper presents a method for assessing the robustness of a neural network by adding constraint to the optimization process, which can be used to train neural networks in a wide range of ways.","A dynamical system view on the adversarial robustness of the models, and a new method that significantly defenses adversarially attacks. This work introduces a dynamical network view for deep neural networks that is robust to all (adversarial) perturbations. The authors present an optimization problem for Hamiltonian maximization, which can be solved efficiently by adding constraints in gradient descent based algorithms."
"Workers send gradient signs to the server, and the update is decided by majority vote. We show that this algorithm is convergent, communication efficient and fault tolerant, both in theory and in practice. Presents a distributed implementation of signSGD with majority vote as aggregation.","SIGNSGD is a mini-batch algorithm for distributed SGD. This work presents a mini batch algorithm for distributing SGD in a low SNR regime, and shows that it can be used to train SGD at a reasonable speed. The authors show that the algorithm can be trained at a high SNR setting, and show that it performs better than other deep learning algorithms.","SIGNSGD is a mini-batch algorithm that can be used to speed up training of Imagenet models. This paper proposes a method for solving the problem of min-batch convergence in SGD by assuming that each component of the stochastic gradient lies in a low SNR regime. The authors propose an algorithm for mini-bases, where each component is represented by a sign and the signal is represented as a sign.","This paper introduces a new mini-batch convergence behaviour for SIGNSGD, which can be applied to large neural networks. The study presents a method for reducing the communication cost of distributed SGD by 25%, resulting in a reduction in generalisation and a higher convergence rate. The authors present a model that is more efficient than adversarial gradients, and show that the majority vote should come out correct on average.","A mini-batch convergence algorithm for distributed SGD with hundreds of millions of parameters. This work introduces a new algorithm that can be used to improve the performance of large neural networks. The study presents a method for reducing the computational cost of distributed SIGNSGD by 25%, resulting in a small loss in generalisation and a reduction in the number of simultaneous parallels between the two algorithms."
"Few-shot learning PixelCNN The paper proposes on using density estimation when the availability of training data is low by using a meta-learning model. This study considers the problem of one/few-shot density estimation, using metalearning techniques that have been applied to one/few-shot supervised learning The work focuses on few shot learning with autoregressive density estimation and improves PixelCNN with neural attention and meta learning techniques.","A meta-learning method for few-shot autoregressive models that combines attention and meta learning. This article presents a meta learning method for neural density estimation, which combines attention with meta learning to achieve state-of-the-art results in terms of likelihood on Omniglot. This work studies the connection between attention and semi-attention in deep neural networks, and shows that it can be used to improve performance in the few shot setting.","A meta-learning framework for few-shot autoregressive models This paper proposes a method to train deep neural networks with attention in order to achieve state-of-the-art results on Omniglot. The authors propose a meta learning framework that combines attention and meta learning by combining the two approaches. This work proposes an approach to training deep neural nets with attention, which can improve the performance of these models.","This work presents a new study of few-shot autoregressive models and their connection to meta-learning. Presents an algorithm for neural density estimation in the context of discriminative models, which can be used to train neural networks from scratch or fine-tuning from scratch. The authors present a method for learning only few shots from scratch and show that attention can improve performance in language tasks.","This work introduces a meta-learning framework for few-shot autoregressive models, which can be used to train neural networks from scratch or fine-tuning from scratch. The authors present a new set of self-regressive model models that can be trained with attention on a wide range of target distributions, and show how attention can improve performance in language tasks."
"we proposed a new self-driving model which is composed of perception module for see and think and driving module for behave to acquire better generalization and accident explanation ability. Presents a multitask learning architecture for depth and segmentation map estimation and the driving prediction using a perception module and a driving decision module. A method for a modified end-to-end architecture that has better generalization and explanation ability, is more robust to a different testing setting, and has decoder output that can help with debugging the model. The authors present a multi-task convolutional neural network for end-to-end driving and provide evaluations with the CARLA open source simulator showing better generalization performance in new driving conditions than baselines",A new deep learning driving module based on image input that can be used to train more robust models. The study presents a new deep-learning driving module which is based on a combination of image input and the driving module weights. This study studies the generalization ability of deep learning autonomous driving models by using image input instead of driving module.,"A new deep learning driving module based on visual input that can be used to improve the generalization ability of the model. This paper proposes a new driving module for deep learning which is based on image input, and shows better generalization abilities than previous models. The study proposes a novel driving module with visual input in the form of a self-driving map.","This study presents a new driving direction selection method for learning the core of intergration in unsupervised learning. The paper introduces a model that can be used to train a driver's direction instead of memorizing the solution of the problem. This article proposed a novel way to learn a driving direction selector using saliency-map based visualization methods, and shows that the perception module is able to understand the input structure of the model.","This study presents a method for learning the core of intergration to solve driving direction selection problem in unseen test town. The article introduces a new model that can be used to learn and segment the driver's input using a saliency-map based visualization method. The authors present a novel way to improve the performance of driving models by improving the perception module weights, and show that it has a different structure than training town's."
We show how to optimize the expected L_0 norm of parametric models with gradient descent and introduce a new distribution that facilitates hard gating. The authors introduce a gradient-based approach to minimize an objective function with an L0 sparse penalty to help learn sparse neural networks,"A method to smooth the expected L 0 regularized objective with continuous distributions in a way that can maintain the exact zeros in the parameters while still allowing for efficient gradient based optimization of parametric models. This article introduces a new algorithm for training parametric neural networks with continuous random variables, and shows that it can be used to speed up gradient based learning.",A method to smooth the expected L 0 regularized objective with continuous distributions in a way that can maintain the exact zeros in the parameters while still allowing for efficient gradient based optimization of parametric models. This article proposes a new approach to sparsifying parametrization models by using continuous distributions as an expectation over the parameter free noise distribution.,"A method to smooth the expected L 0 normalized objective with continuous distributions in a way that can maintain the exact zeros in the parameters while still allowing for gradient based optimization. This study presents a method for optimizing parametric models by using a model compression and sparsification technique, where the probability of a gate being different from zero is equal to zero.",A method to smooth the expected L 0 normalized objective with continuous distributions in a way that can maintain the exact zero in the parameters while still allowing for efficient gradient based optimization. This work introduces a compression and sparsification method for optimizing parametric models by using a model compression and a generalization method.
We develop meta-learning methods for adversarially robust few-shot learning. This paper presents a method that enhances the robustness of few-shot learning by introducing adversarial query data attack in the inner-task fine-tuning phase of a meta-learning algorithm. The authors of this article propose a novel approach for training a robust few-shot model.,"A new meta-learning routine for adversarial querying that outperforms other robustness techniques by a wide margin in terms of both clean accuracy and adversarial robustness. This article introduces a new meta learning method for adversarially querying, which combines deep learning with deep learning to improve the robustness of existing deep learning methods.",A meta-learning approach to adversarial querying that outperforms other robustness techniques by a wide margin. This paper proposes a method for training deep convolutional neural networks in which the feature extractor is fixed and only the last layer is retrained during fine-tuning. The authors propose a meta learning approach to train deep convolutions in order to defend against adversarial perturbations on large datasets.,"In the few-shot setting, adversarial querying outperforms other robustness techniques by a wide margin in terms of both clean accuracy and adversariality robustness. This article introduces a method to learn from pre-trained feature extractors on large datasets and fine-tuned on new tasks.","In the few-shot setting, adversarial querying outperforms other robustness techniques by a wide margin in terms of clean accuracy and adversariality robustness. This study introduces a novel method for retrieving data from a neural network using a pre-trained feature extractor that is trained on a large corpus of data sets and fine-tuning on new tasks."
This work demonstrates how to train deep autoencoders end-to-end to achieve SoA results on time-split Netflix data set. This article presents a deep autoencoder model for rating prediction that outperforms other state-of-the-art approahces on the Netflix prize dataset. Proposes to use a deep AE to do rating prediction tasks in recommender systems. The authors present a model for more accurate Netflix recommendations demonstrating that a deep autoencoder can out-perform more complex RNN-based models that have temporal information.,"A new deep autoencoder model for the rating prediction task in recommender systems which significantly outperforms previous state-of-the art models on a time-split Netflix data set. This article introduces a new autoencoders architecture for the task of rating prediction, and shows that it performs better than previous deep learning architectures.",A new deep autoencoder model for the rating prediction task in recommender systems which significantly outperforms previous state-of-the art models on a time-split Netflix data set. This paper proposes a novel autoencoders for the ratings prediction task that can be solved by using scaled exponential linear units (SELUs).,This paper introduces a new model for the rating prediction task in recommender systems which significantly outperforms previous state-of-the-art models on time-split Netflix data sets. This work presents a method for training deep autoencoders by using a scaled exponential linear unit (SELUs) to bypass the natural sparseness of updates in collaborative filtering and further improves the model performance.,A new model for the rating prediction task in recommender systems which significantly outperforms previous state-of-the-art models on time-split Netflix data set. This work introduces a new model to train deep autoencoders that is more sparse than shallow ones. The authors present a method for training autoencoding deep models with non-linear activation functions and a novel output re-feeding training algorithm.
"We propose that training with growing sets stage-by-stage provides an optimization for neural networks. The authors compare curriculum learning to learning in a random order with stages that add a new sample of examples to the previously, randomly constructed set This work studies the influence of ordering in the Curriculum and Self paced learning, and shows that to some extent the ordering of training instances is not important.",A new method to train with random samples and add new samples according to difficulty levels improves the learning performance in both curriculum and anti-curriculum learning. This study studies the effectiveness of random samples in curriculum learning and shows that random samples are more effective than random samples. The study presents a new method for learning from random samples by adding new samples randomly without a meaningful order.,"A new method for learning from hard-to-easy data sets. This article proposes a new method to learn from easy data sets by adding new samples according to difficulty levels improves the learning performance in both curriculum and anti-curriculum learning. The authors propose a new approach to learning from difficult data sets, which is based on using random samples instead of random samples.",A small training set and adding new samples in both curriculum and anti-curriculum learning improves the learning performance. This work introduces a method to add samples randomly without a meaningful order to improve the performance of Anti-Crumulum learning by adding the samples randomly to the first stage so that the number of new samples to add at each stage is equal. The authors present a technique for improving the performance with a small group of random samples,A small training set and adding new samples to both curriculum and anti-curriculum learning makes these methods better. The authors show that adding samples randomly without a meaningful order improves the learning performance. This study investigates the problem of finding out how to add samples to the training set by adding them randomly in the first stage of the training process. The study presents a method for improving the performance of training with a group of random samples
"We replace the fully connected layers of a neural network with the multi-scale entanglement renormalization ansatz, a type of quantum operation which describes long range correlations. In the paper the authors suggest to use MERA tensorization technique for compressing neural networks. A new parameterization of linear maps for neural network use, using a hierarchical factorization of the linear map that reduces the number of parameters while still allowing for relatively complex interactions to be modelled. Studies compressing feed forward layers using low rank tensor decompositions and explore a tree like decomposition",A new deep neural network architecture that can capture correlations on different length scales using tensor trains. This work introduces a deep neural networks architecture that combines tree-like connectivity with tensor-trained neural networks. The authors introduce a deep learning architecture based on the idea of embedding a tree into a neural network to capture correlations between inputs.,A new deep neural network architecture that can capture correlations on different length scales. The authors propose a deep neural networks architecture that combines tree-like connectivity with tensor train layers to achieve the highest compression rate. This paper proposes a deep learning architecture based on the idea of embedding deep neural connections into a fully connected neural network.,A new neural network with two penultimate fully connected layers of the model that is replaced with tensor trains. This work presents a novel method to reduce the compression rate of fully connected neural networks by replacing them with one layer of rank-4 tree elements in order to evaluate how detrimental naive compression is to accuracy. The authors use MERA as a replacement for linear layers in a neural network used to classify the CIFAR-10 dataset.,"A neural network with two penultimate fully connected layers of the model replaced with MERA layers. This work presents a novel compression method for neural networks that uses a tree-like connectivity to capture correlations between inputs in a region determined by its height in the tree. The authors present a new layer of a neural network using tensor trains and a set of rank-4 tree elements, followed by a single tree element."
"A new method for gradient-descent inference of permutations, with applications to latent matching inference and supervised learning of permutations with neural networks The paper utilizes finite approximation of the Sinkhorn operator to describe how one can construct a neural network for learning from permutation valued training data. The study proposes a new method that approximates the discrete max-weight for learning latent permutations","A deep neural network that learns to find the right permutation for a given sequence of sequences. This work presents a deep neural networks that can learn to solve entropy-regularized linear assignment problems by randomly permuting pieces of random matrices. The work presents an algorithm for learning the correct permutation of a sequence of sequence of sequential sequences of sequences, and shows that it is possible to learn the correct number of sequences in a sequence.","A Sinkhorn network that learns to find the right permutation for a given set of matrices. This work proposes a method for learning to learn the correct permutation of a matrices in order to solve an entropy-regularized problem. The authors propose a new algorithm for learning the wrong permutation, and show that it can be used to solve the matching problem. This paper proposes a novel approach to solving the randomization problem by using the Sinkinghorn operator","A method to parameterize the hard choice of a permutation P through a square matrix X. This article introduces a method for solving the problem of entropy-regularization in Sinkhorn networks, which can be used as a solution to the linear assignment problem BID28. This work presents a new method for determining the length of the Permutation GSM network by using the sinkhorn iterations.","A method to parameterize the hard choice of a permutation P through a square matrix X. This work introduces a method for learning a mapping from scrambled objectsX to actual, non-scrambled X by using the Sinkhorn iterations in order to solve the matching problem. The authors present a technique for determining the length of the Permutation Equations"
Compressing trained DNN models by minimizing their complexity while constraining their loss. This paper proposes a method for deep neural network compression under accuracy constraints. This article presents a loss value constrained k-means encoding method for network compression and develops an iterative algorithm for model optimization.,"A method for compressing trained neural network models that directly minimizes its complexity while maintaining its accuracy. This paper presents a method for reducing the complexity of trained neural networks by reducing the number of centroids and reducing the computational complexity. This work introduces a method to compress neural networks in order to reduce their computational complexity, and shows that it achieves similar results for SVHN and CIFAR10 datasets.","A method for compressing trained neural network models that directly minimizes its complexity while maintaining its accuracy. This paper proposes a method for reducing the complexity of a trained model by optimizing the loss function in each iteration of the compression process. The authors propose a method to compress trained neural networks using k-means objective, which reduces the number of centroids per iteration.",A method for minimizing the complexity of a trained model by eliminating or merging unnecessary centroids. This article presents a method for solving the constrained optimization problem by using a compression algorithm to solve the problem of optimizing the training loss function. The authors present a novel way of reducing the complexity in a training model and show that it is possible to learn a new loss function by combining the loss function with a single compression algorithm.,A method for minimizing the complexity of a trained model by eliminating or merging unnecessary centroids. This work presents a method to solve the constrained optimization problem by eliminating the centroids and reducing the number of computations. The authors present a novel loss function algorithm that eliminates centroids in the training process and then calculates M based on the optimal value of the loss function.
"Imitation from pixels, with sparse or no reward, using off-policy RL and a tiny adversarially-learned reward function. The study proposes to use a ""minimal adversary"" in generative adversarial imitation learning under high-dimensional visual spaces. This paper aims at solving the problem of estimating sparse rewards in a high-dimensional input setting.","A deep reinforcement learning agent that learns to stack faster than a dense staged reward baseline agent with only demonstrations and a sparse binary reward indicating whether or not the stack has completed. This work introduces a new policy gradient for reinforcement learning, which is a state-of-the-art off-policy method for control, that can take advantage of a replay buffer to store past experiences.","A novel agent that learns to stack faster than a dense staged reward baseline agent with only demonstrations and a sparse binary reward indicating whether or not the stack has completed. This paper proposes a new agent for robotic block stacking, based on an adversary-based early termination method for actor processes. The authors propose a novel agent for robot block stacking using a replay buffer in order to evaluate the performance of the agent.","A state-of-the-art off-policy method for control that can take advantage of a replay buffer to store past experiences. This article introduces a new defense against the use of replay buffers in simulated robotic block stacking by using an adversary-based approach, which is able to stack faster than the dense staged reward baseline agent with the same amount of actor processes.",A deep-distributed Deterministic Policy Gradients (D4PG) agent that does off-policy training with experience replay with buffer B. This work introduces a deep-deterministic policy-gradient approach to block stacking in simulated robot robots using only demonstrations and a sparse binary reward indicating whether or not the stack has completed.
"Improvements to adversarial robustness, as well as provable robustness guarantees, are obtained by augmenting adversarial training with a tractable Lipschitz regularization Explores augmenting the training loss with an additional gradient regularization term to improve robustness of models against adversarial examples Uses a trick to simplify the adversarial loss by one in which the adversarial perturbation appears in closed form.",Adversarial training improves robustness to adversarial attacks by using Lipschitz regularization of the loss gradients. This article presents a novel method for learning adversarial defences based on the loss gradient of a pre-trained neural network. The authors present a novel approach for training a deep neural network that is more tractable and efficient than adversarial training methods. This work introduces a new method for training an adversarial model with a loss gradient in order to improve robustness.,"Adversarial training improves robustness to adversarial attacks by using Lipschitz regularization of loss gradients. This paper proposes a novel method for estimating the Lipsschitz constant of a deep neural network in order to improve its robustness against adversarial attack vectors. The article proposes a new approach to estimating Lipschesitz constant in deep neural networks, which can be used to estimate adversarial robustness on unseen data.",A method for estimating adversarial robustness in deep neural networks by using a one-step Signed Gradient attack vector or the gradient attack vector as Total Variation regularization This paper presents a method for estimation of adversarially robustness on unsupervised data. The authors present a new method to estimate adversarials' robustness and show that it is not tractable as a Lipschitz penalty during training.,A method for estimating adversarial robustness in deep neural networks that is not tractable as a Lipschitz penalty. This work presents a method to estimate adversarially robustness on unseen data drawn from the same distribution using either the one-step Signed Gradient attack vector or the gradient attack vector as Total Variation regularization.
"A new state-of-the-art approach for knowledge graph embedding. Presents a neural link prediction scoring function that can infer symmetry, anti-symmetry, inversion and composition patterns of relations in a knowledge base. This work proposes an approach to knowledge graph embedding by modeling relations as rotations in the complex vector space. Proposes a method for graph embedding to be used for link prediction","A probabilistic model that can model and infer all the three types of relation patterns for link prediction. This work introduces a new knowledge graph embedding model, called RotatE, which is able to model and learn all the relation patterns. The study presents a new approach to link prediction based on the idea of modeling and inferring relation patterns in a knowledge graph. The authors introduce a new framework for learning relation patterns that can be used to predict links between entities.","A new knowledge graph embedding model that is able to model and infer all the three types of relation patterns. This paper introduces a new knowledge-graph embedding framework called RotatE, which can model and learn all the different relation patterns in a given knowledge graph. The article proposes a method for learning relation patterns based on the similarity of the relation patterns between the two sets of relations.","A new model able to model and infer all the three types of relation patterns, except the symmetry pattern. This article introduces a new model for knowledge graph embeddings that can be used to infer and model all the 3 types of relationships. The authors present a novel method for inferring relations between the two types of information graphs by using a score function called DISPLAYFORM1.","A new knowledge graph embedding model that can model and infer all the three types of relation patterns. This work introduces a new method for inferring relation patterns, which is able to infer the patterns of (or between) the relations. The authors present an approach to inducing relation patterns by defining the distance function of each relation as a rotation in the complex vector spaces."
"We present Multitask Neural Model Search, a Meta-learner that can design models for multiple tasks simultaneously and transfer learning to unseen tasks. This work extends Neural Architecture Search to the multi-task learning problem where a task conditioned model search controller is learned to handle multiple tasks simultaneously. In this paper, authors summarize their work on building a framework, called Multitask Neural Model Search controller, for automated neural network construction across multiple tasks simultaneously.","Multi-task Neural Model Search (MNMS), an automated model construction framework that finds the best performing models in the search space for multiple tasks simultaneously. This work introduces a multi-task neural model search framework that learns to search for previously seen tasks simultaneously, reducing search time on previously unseen tasks. The authors introduce a new neural model architecture for ImageNet classification that is pre-trained on several different tasks simultaneously","Multitask Neural Model Search (MNMS) is an automated model construction framework that can condition model construction on successful model searches for previously seen tasks, thus significantly speeding up the search for new tasks. This paper proposes a novel multi-task neural model search framework that performs better than pre-trained models on previously unseen tasks.","This paper presents Multitask Neural Model Search (MNMS), an automated model construction framework that finds the best performing models in the search space for multiple tasks simultaneously. This work introduces a multi-task neural model search framework that has been pre-trained on previous searches, thereby speeding up the search for new tasks.","This work presents Multitask Neural Model Search (MNMS), an automated model construction framework that finds the best performing models in the search space for multiple tasks simultaneously. The authors present a multi-task neural model search framework that has been pre-trained on previous searches, thus speeding up the search for new tasks."
Properly training CNNs with dustbin class increase their robustness to adversarial attacks and their capacity to deal with out-distribution samples. This work proposes adding an additional label for detecting OOD samples and adversarial examples in CNN models. The paper proposes an additional class that incorporates natural out-distribution images and interpolated images for adversarial and out-distribution samples in CNNs,An augmented CNN for black-box adversarial examples can significantly reduce the misclassification rates for both naive and robust out-distribution sets. This study presents a method for training effective CNNs that can be used to generate adversarial samples from a wide range of out-of-distributary sets.,"An augmented CNN can significantly reduce the misclassification rate for black-box adversarial examples by reducing the number of out-distribution regions. This paper proposes an augmented CNN that is more effective than a naive CNN, and proposes a method to select a representative sample from a wide range of unseen samples. The authors propose a new approach to training effective CNNs in the feature space of the image classification task.","A simple and computationally efficient augmented CNN that can significantly reduce the risk of misclassifying both adversaries and samples from a broad range of over-generalized out-distribution sets. This article introduces a method to learn a ""dustbin"" sub-manifold for the dustbin class, where they are mapped to this set.","A simple and computationally efficient solution for reducing the risk of misclassifying both adversaries and samples from a broad range of over-generalized out-distribution sets. This study introduces a method to learn a ""dustbin"" sub-manifold that can be used to train adversarial examples instead of unsupervised dustbins."
"Permutation-invariant loss function for point set prediction. Proposes a new loss for points registration (aligning two point sets) with preferable permutation invariant property. This article introduces a novel distance function between point sets, applies two other permutation distances in an end-to-end object detection task, and shows that in two dimensions all local minima of the holographic loss are global minima. Proposes permutation invariant loss functions which depend on the distance of sets.","An analytic distance function for moderately sized point sets of known cardinality that is shown to have very desirable properties, both as a loss function as well as a regularizer for machine learning applications. This article introduces a new loss function for small point sets with known cardinalities that can be used as a deep learning loss function. This work presents a new method for learning deep learning points by using a simple permutation-invariant loss function","A simple permutation-invariant loss function for moderately sized point sets of known cardinality that is shown to have very desirable properties, both as a loss function as well as a regularizer for machine learning applications. This paper proposes a new loss function which can be used for the purpose of training point sets with known cardinalities. The authors propose an analytic distance function for small point sets in order to define a meaningful distance between the underlying sets.","A permutation-invariant loss function for moderately sized point sets of known cardinality that is shown to have very desirable properties, both as a loss function and a regularizer for machine learning applications. This work presents a method for training points in the form of an analytic distance function for low-valued points and shows that it can be used to train points in a wide range of ways.","An analytic distance function for moderately sized point sets of known cardinality that is shown to have very desirable properties, both as a loss function and a regularizer for machine learning applications. This study introduces a permutation-invariant loss function for low-value points in the context of machine learning and shows that it has favorable properties."
"Genetic algorithms based approach for optimizing deep neural network policies The authors present an algorithm for training ensembles of policy networks that regularly mixes different policies in the ensemble together. This work proposes a genetic algorithm inspired policy optimization method, which mimics the mutation and the crossover operators over policy networks.","A new policy gradient algorithm for black-box policy optimization that efficiently combines two parent policies and generates offspring that takes advantage of both the parents. This work introduces a new variant of GAs which combines state-space crossover with a novel mutation operator. The authors introduce a new GAs algorithm for deep reinforcement learning, called GAs, which combines two policies into one policy and generates a hybrid policy.","A new policy gradient algorithm for black-box policy optimization that efficiently combines two parent policies and generates offspring that takes advantage of both parents. This paper proposes a novel policy gradient method for black box policy optimization, based on state-space crossover and imitation learning in the crossover step. The authors propose a new variant of GAs which combines one parent policy with an offspring policy using imitation learning. This work proposes a new approach to black-boxes policy optimization by combining two parent policy into an offspring or child policy.","A new state-space crossover operator that efficiently combines two parent policies into an offspring or child policy that tries to mimic its best parent in generating similar state visitation distributions. This article introduces a new network architecture for continuous control tasks, which combines both parent and child policies to achieve comparable or higher sample efficiency. The authors present a novel way of learning a policy that maximizes the expected sum of rewards starting from the initial state.","A new state-space crossover operator that efficiently combines two parent policies into an offspring or child policy that takes advantage of both parents. This work introduces a new policy gradient operator for continuous control tasks, where the policy is evaluated by a deep neural network with a probability distribution over the parameter space and evaluates the objective function on the candidates with the high fitness."
"We propose an easy to implement, yet effective method for neural network compression. PFA exploits the intrinsic correlation between filter responses within network layers to recommend a smaller network footprints. Proposes to prune convolutional networks by analyzing the observed correlation between the filters of a same layer as expressed by the eigenvalue spectrum of their covariance matrix. This study introduces an approach to compressing neural networks by looking at the correlation of filter responses in each layer via two strategies. This study proposes a compression method based on spectral analysis","A closed-form pruning algorithm based on spectral energy analysis for suggesting the number of filters to remove in a layer. This paper introduces a new pruning technique, called PFA-En, which uses spectral energy estimation to determine the amount of filters that should be removed at each layer. The authors present a method for optimizing the performance of structured pruning algorithms by using spectral energy analyses to determine how many filters should be eliminated.",A closed-form pruning algorithm based on spectral energy analysis for suggesting the number of filters to remove in a layer: PFA-En uses Principal Component Analysis (PCA) BID21 to allow a user to specify the proportion of the energy in the original response that should be preserved in each layer.,"A structured pruning method for reducing the number of filters to remove in a layer. This article introduces a PFA-En algorithm that uses a spectral energy analysis algorithm to estimate the number and the size of the filters in each layer. The authors present a novel pruning technique for filter selection, which is based on a linear mapping to a lower dimensional space that maximizes the variance of the data in the dataset.","A closed-form algorithm based on spectral energy analysis for suggesting the number of filters to remove in a layer. This work introduces a new set of filters that can be pruned to a lower dimensional space by using a random initialization to obtain the highest test accuracy. The authors present a method for filter selection, which is more accurate than Scratch and CIFAR-100."
This study studies the discrimination and generalization properties of GANs when the discriminator set is a restricted function class like neural networks. Balances capacities of generator and discriminator classes in GANs by guaranteeing that induced IPMs are metrics and not pseudo metrics This paper provides a mathematical analysis of the role of the size of the adversary/discriminator set in GANs,"A generalization bound for neural f -divergence in GANs with non-parametric discriminators. The authors prove that neural discriminators are discriminative when they are bounded by a bounded Lipschitz distance, and show that the discriminator set can be used to achieve strong convergence. This study studies the discriminators' discriminator-to- discriminator relationship between different parameters of a GAN.","A generalization bound for neural discriminator sets with bounded Lipschitz distance. The authors prove that the discriminator set F is even, i.e., fÉ?? F implies É??f É?? F. Intuitively speaking, minimizing (1) towards zero corresponds to matching the moments E ∂Ê [f] = E ◊´ [f ] for all discriminators f É??F.","A new discriminator set of neural distances that is bounded Lipschitz when X and  are bound to be universally approximators in the Borel probability measures. This study studies the problem of discrimination between neural networks by assuming that the discriminator sets are infinite dimensional and large enough to guarantee that d F (, ) = 0 implies  = ).","A bounded Lipschitz distance for non-decreasing homogenous activation functions, and a stronger neural distance. This paper considers the problem of discriminating against non-parametric and infinite dimensional representations of the discriminator sets. The authors show that discriminating between the two sets of discriminators is based on the fact that the discrepancies between the three sets are invariantly equal to those of the other sets."
"Building on previous work on domain generalization, we hope to produce a classifier that will generalize to previously unseen domains, even when domain identifiers are not available during training. A domain generalization approach to reveal semantic information based on a linear projection scheme from CNN and NGLCM output layers. The paper proposes an unsupervised approach to identify image features that are not meaningful for image classification tasks","A new neural network building block that is differentiable and tunable through backpropagation. This work introduces a new neural model for image recognition that is more tunable than previous models. The authors introduce a new Neural Network building block, GLCM, which can be used to extract textural information from images of training domains.","A new neural network building block that is differentiable and tunable through backpropagation. This paper proposes a new neural architecture based on GLCM, which can extract textural information from the image. The authors propose a new Neural Network building block based on gLCM and NGLCM that is more tunable than previous methods.","A new neural network building block that resembles GLCM, which has (sub)gradient everywhere, and thus are tunable through backpropagation. This work introduces a new neural networks building block for the construction of G, where all the parameters are differentiable, and therefore all the operations used in the construction have (sub-gradient).","A new neural network building block that resembles GLCM but has (sub)gradient everywhere and thus are tunable with backpropagation. This work introduces a new neural networks building block for the construction of a neural network, where all the parameters are differentiable, and thus can be projected with a projection matrix constructed by a residual maker matrix."
"Rethinking generalization requires revisiting old ideas: statistical mechanics approaches and complex learning behavior The authors suggest that statistical mechanics ideas will help to understand generalization properties of deep neural networks, and give an approach that provides strong qualitative descriptions of empirical results regarding deep neural networks and learning algorithms. A set of ideas related to theoretical understanding generalization properties of multilayer neural networks, and a qualitative analogy between behaviours in deep learning and results from quantitative statistical physics analysis of single and two-layer neural networks.","A theoretical analysis of the NN/DNN learning process. This article presents a theoretical analysis on the generalization performance of NNs and shows that it is possible to generalize to a large number of control parameters. The study presents a method for generalizing NNs to large amounts of noise in the data, showing that generalization can be achieved on a small amount of noise.","A theoretical analysis of the generalization properties of NN/DNNs, and an empirical analysis of their generalization performance. The article proposes a new approach to generalization of DNNs that focuses on improving the accuracy of the learning process. This paper proposes a method for generalizing deep neural networks (SDNs) based on a variety of factors, such as noise, data, and noise.","NNs are robust to massive amounts of noise in the data and/or can help training, while others argue that they are quite sensitive to even a modest amount of noise. This article addresses the problem of learning DNNs by explaining how convergence to flat minimizers can be used to generalize the learning process. The authors present a method for understanding NN learning using a wide range of parameters, including the specific details of the learning algorithm, and their properties.","An approach to generalization of NN/DNN learning by focusing heavily on the specific details of the model, the detailed properties of the data and their noise, and so on. This article considers the problem of convergence to flat minimizers in statistical learning, shows that convergence to sharp minima can be used to improve prediction quality by 1%)."
"This article introduces Morpho-MNIST, a collection of shape metrics and perturbations, in a step towards quantitative evaluation of representation learning. This work discusses the problem of evaluating and diagnosing the represenatations learnt using a generative model. Authors present a set of criteria to categorize MNISt digists and a set of interesting perturbations to modify MNIST dataset.","A new quantitative framework for assessing the generative direction of generative models of images. This work introduces a quantitative framework to evaluate generative representations of images, based on morphometric data. The study presents a method for evaluating generative representation of images by using morphometric analysis to determine whether a model has learned to represent specific factors of variation.","Morpho-MNIST is a quantitative framework for assessing representation learning. This paper proposes a new quantitative framework to assess the representations of generative models in image classification using morphometric analysis. The authors propose a method for evaluating generative model representations based on morphometric attributes, which can be used to determine whether a model has learned to represent specific factors of variation.","A new quantitative framework for assessing representation learning in image classification. This article introduces Morpho-MNIST, a framework that aims to answer the question of what extent has my model learned to represent specific factors of variation in the data? The authors present a method for evaluating representation learning using morphometric analysis and a morpho-mNIST code base to address the problem of understanding latent variables in images.","A new quantitative framework for assessing representation learning that has well understood and easily measurable factors of variation in the data. This work introduces a new framework to evaluate representation learning by adding a morphometric analysis, enabling quantitative comparison of trained models, and identification of roles of latent variables, and characterisation of sample diversity."
"We show that modular structured models are the best in terms of systematic generalization and that their end-to-end versions don't generalize as well. This paper evaluates systemic generalization between modular neural networks and otherwise generic models via introduction of a new, spatial reasoning dataset A targeted empirical evaluation of generalization in models for visual reasoning, focused on the problem of recognizing (object, relation, object) triples in synthetic scenes featuring letters and numbers.","A new synthetic dataset for the purpose of generalization of deep neural networks. This study presents a new dataset for deep neural network generalization, called SQOOP, where models are required to learn a layout that matches the task. The authors investigate the generalization capabilities of deep-learning neural networks and show that they are capable of doing systematic generalization on an end-to-end basis.","A new synthetic dataset for generalization of neural models, called Spatial Queries On Object Pairs (SQOOP), which is designed to induce systematic generalization. The authors propose a new model for the problem of answering questions about objects in an object-following context, and show that it can be used to improve generalization performance. This paper proposes a novel model for solving questions on objects in a natural setting, called SQOOP.",A new synthetic dataset that can answer questions about all 36  35 possible objects in SQOOP. This study introduces a new dataset to address the problem of instruction-following problems for seq2seq models by adding a modularity and structure to their design to make them structurally resemble the kind of rules they are supposed to learn.,"A synthetic dataset for learning a generalization task that learns rules on how to compose words and fail spectacularly when asked to interpret ""jump"", ""run twice"" and ""walk twice"". This work introduces a new dataset called Spatial Queries On Object Pairs (SQOOP), in which a model has to perform spatial relational reasoning about pairs of randomly scattered letters and digits in the image."
"We propose a self-monitoring agent for the Vision-and-Language Navigation task. A method for vision+language navigation which tracks progress on the instruction using a progress monitor and a visual-textual co-grounding module, and performs well on standard benchmarks. This study describes a model for vision-and-language navigation with a panoramic visual attention and an auxillary progress monitoring loss, giving state-of-the-art results.","A novel LSTM based on textually grounded instructions that can be used to track progress towards the goal. The authors present a novel approach for tracking the progress of an action selection agent by using textual grounding. This work introduces a novel method for measuring the completeness of instruction-following tasks, which uses textual grounding to measure the progress made.","This paper proposes a novel method for measuring the completeness of instruction-following tasks. The authors propose a new objective function for agents to measure how well they are doing in order to improve the state of the arts. This work proposes an attentional mechanism that is able to predict which part of the instruction is needed for action selection-textual grounding, and shows that it can be used to estimate the progress made towards the goal.","A new approach for action selection-textual grounding that can be used to estimate the completeness of instruction-following. This work introduces a new objective function for the agent to measure how well it can estimate the progress made towards the goal. The authors present an agent with the ability to identify which direction to go by relying on a grounded instruction, and show that even the attentional mechanism of the baseline does not successfully track this information through time.","A new objective function for the agent to measure how well it can estimate the completeness of instruction-following. This work introduces a new approach for action selection-textual grounding, which is used to measure the progress made towards the goal. The authors present a method for determining which direction to go by relying on a grounded instruction, and show that the attentional mechanism of the baseline does not successfully track this information through time."
"We show that ENAS with ES-optimization in RL is highly scalable, and use it to compactify neural network policies by weight sharing. The authors construct reinforcement learning policies with very few parameters by compressing a feed-forward neural network, forcing it to share weights, and using a reinforcement learning method to learn the mapping of shared weights. This article combines ideas from ENAS and ES methods for optimisation, and introduces the chromatic network architecture, which partitions weights of the RL network into tied sub-groups.","Combine ENAS and ES for learning compact representations that learn effective policies with over 92% reduction of the number of parameters. This paper combines ENAS, ES, and random partitioning to learn efficient policies for RL tasks. The authors combine ENAS with ES to train a large population of CPU workers in order to improve the performance of RL networks.","A scalable and scalable method for learning compact representations that outperforms human-designed networks. This paper proposes to combine ENAS and ES in order to improve the performance of non-structured neural networks by reducing the number of weights and biases of the network. The authors propose a novel algorithm for learning structured representations based on Toeplitz matrices, which is more efficient than standard ENAS algorithms.","A highly scalable algorithm that learns effective policies with over 92% reduction of the number of neural networks parameters. This article introduces a method for learning weight-sharing architectures that is more efficient than hardcoded ones. The authors present an approach to learning weights for RL, where weights are chosen randomly instead of being learned, but the topologies of connections are ultimately biased towards RL tasks under consideration.","A highly scalable algorithm that learns effective policies with over 92% reduction of the number of neural networks parameters. This work introduces a method for learning weight-sharing architectures that are more complex than hardcoded ones. The authors study the problem of learning weight sharing architectures in RL by using ES to improve the efficiency of the controller, and proposed a way to learn weight sharing mechanisms which can be used to measure the accuracy of the input data."
"Gaggle, an interactive visual analytic system to help users interactively navigate model space for classification and ranking tasks. A new visual analytic system which aims to enable non-expert users to interactively navigate a model space by using a demonstration-based approach. A visual analytics system that helps novice analysts navigate model space in performing classification and ranking tasks.","A user-defined model space for classification and ranking models. This article presents a novel approach to the problem of overfitting ML models with user feedback by using a combination of a learning algorithm and associated hyperparameters. The authors introduce Gaggle, a multi-modal ML system that learns to classify data from multiple datasets and then uses user feedback to select a new model.","A user-defined model space for classification and ranking models. This article proposes a novel approach to the problem of overfitting ML models with multiple hyperparameters in order to improve the user interface. The authors propose a method for improving the user experience of ML models by incorporating user interaction into the model selection process. This paper proposes a new approach to learning models that can be used for classification, ranking, and evaluation.","A new optimal model for a single model to show at each iteration is to simplify the user interface by removing a model comparison and selection step. This study introduces a new model space that can be sampled using a combination of a learning algorithm and associated hyperparameters. The article presents a method for evaluating models for the ranking task, which uses a linear dimension reduction technique to improve the user experience.",A new optimal model for a single iteration. This study introduces a new model space that can be sampled using a combination of a learning algorithm and hyperparameters. The authors present a model space for the task of classifying data objects in a linear way by removing a comparison and selection step to ensure they do not change labels in future iterations.
"We propose to generate adversarial example based on generative adversarial networks in a semi-whitebox and black-box settings. Describes AdvGAN, a conditional GAN plus adversarial loss, and evaluates AdvGAN on semi-white box and black box setting, reporting state-of-art results. This article proposes a way of generating adversarial examples that fool classification systems and wins MadryLab's mnist challenge.","An adversarial perturbation strategy for black-box attacks based on the assumption that adversaries have no prior knowledge of training data or the model itself. This paper presents a method for generating adversarial examples using a dynamic distillation technique, where the adversary assumes that the adversarial instance is close to the original one in terms of L 2.","A new black-box attack strategy for training adversarial examples that are close to the original one. This paper proposes a method for generating black-boxes attacks based on a re-ranking loss and an L 2 norm loss. The authors propose a new attack strategy, called AdvGAN, which uses a reranking loss to generate adversarial instances of the target class in order to improve the attack performance.",This article introduces a method to optimize adversarial perturbation for untargeted attacks by optimizing the distance between the prediction and the ground truth of the generated adversarials. The paper presents a new way of achieving adversarially perturbated adversaries by minimizing the distillation objective of the network distillation objectives.,A deep neural network that generates adversarial examples against an untargeted image. This work combines re-ranking loss and a L 2 norm loss to constrain the generated instance to be close to the original one in terms of L 2. The authors present a method for maximizing the distance between the prediction and the ground truth of the generated adversarials.
We introduce a novel measure of flatness at local minima of the loss surface of deep neural networks which is invariant with respect to layer-wise reparameterizations and we connect flatness to feature robustness and generalization. The authors propose a notion of feature robustness which is invariant with respect to rescaling the weight and discuss the notion's relationship to generalization. This article defines a notion of feature-robustness and combines it with epsilon representativeness of a function to describe a connection between flatness of minima and generalization in deep neural networks.,"Feature robustness is related to generalization in neural networks. This study studies the robustness of a neural network with ReLU activations, and shows that feature robustness can be related to the generalization properties of the neural network. This work considers the generalisation properties of neural networks and introduces a new measure of flatness, which is based on the fact that the loss curve of a given function is not randomly modified.","A new measure of feature robustness that considers all directions of moving away from a local minimum. This article proposes a new measure to measure the robustness of a neural network, which is based on the fact that it can be reparameterized without changing its output in such a way that flatness is changed almost arbitrarily. The paper proposes a method for measuring features of a deep neural network with respect to adversarial examples and proposes a novel measure of flatness.",A method to measure the robustness of a neural network's flatness. This article introduces a method for assessing the generalization properties of feature robustness in the context of ReLU activations. The paper considers the problem of determining the generalisation properties of the ReLU function by using a data-independent distribution over matrices A and a model that has a non-zero value on the diagonal.,"This article considers the generalization properties of feature robustness in a neural network. The authors introduce a new method to measure the flatness of a function f =  É?Ω  (e.g., an unnormalized neural network) towards local changes in the feature space. This study presents a method for evaluating the generalisation properties of features robustness from a set of distributions to a particular distribution."
"We introduce DPFRL, a framework for reinforcement learning under partial and complex observations with a fully differentiable discriminative particle filter Introduces ideas for training DLR agents with latent state variables, modeled as a belief distribution, so they can handle partially observed environments. This paper introduces a principled method for POMDP RL: Discriminative Particle Filter Reinforcement Learning that allows for reasoning with partial observations over multiple time steps, achieving state-of-the-art on benchmarks.","A discriminative observation model that learns to explicitly track a latent belief, while circumventing the difficulty of generative observation modeling. This article introduces a new deep learning method for deep learning that learns a latent knowledge representation from particle observations. The study presents a deep learning approach to deep learning by using a discriminatively parameterized observation function to learn a latent information representation.","Discriminative Particle Filter Reinforcement Learning (DPFRL), a POMDP RL method that learns to explicitly track a latent belief, while circumventing the difficulty of generative observation modeling. This study proposes a new method for discriminating latent belief representations in order to improve decision making from particle filters.","This article introduces the Discriminative Particle Filter Reinforcement Learning (DPFRL), a method that learns to explicitly track a latent belief while circumventing the difficulty of generative observation modeling. This work introduces a new method for learning observation features that are relevant to decision making from particle beliefs, and shows that DPFRL outperforms GRU in most cases because of its explicit structure for belief tracking.","This work introduces a new method for learning to explicitly track a latent belief, while circumventing the difficulty of generative observation modeling. The authors present a method for re-learning observation features that are irrelevant for belief tracking and decision making by using a discriminative Particle Filter Reinforcement Learning framework. This study presents a novel method for understanding beliefs in RL with partial observations, which is more flexible than a generative model."
"We prove randomly initialized (stochastic) gradient descent learns a convolutional filter in polynomial time. Studies the problem of learning a single convolutional filter using SGD and shows that under certain conditions, SGD learns a single convolutional filter. This work extends the Gaussian distribution assumption to a more general angular smoothness assumption, which covers a wider family of input distributions","This article studies the dynamics of gradient descent and stochastic gradient descent in deep neural networks. This study studies the learning dynamics of deep neural network and shows that gradient descent with random initialization leads to faster convergence than gradient descent. The study presents a method for learning the weights of a neural network using a Gaussian distribution, which leads to higher convergence rates.","A method for learning the weights of a neural network using stochastic gradient descent. This article proposes a method to learn the weight of a filter in polynomial time and shows that it is possible to train a model with a smoother input distribution than a vanilla one-layer model. The paper proposes a new approach to learning a deep neural network by learning a Gaussian distribution, which leads to faster convergence.",A neural network that can be optimized under stochastic gradient descent with random initialization. This work introduces a neural network optimization algorithm to learn the Gaussian distribution by using specialized analytic properties of the filter. The authors present a novel algorithm for optimizing neural networks and show that a smoother input distribution leads to faster convergence.,"A neural network optimization algorithm that can recover the filter in polynomial time. This work introduces a new method for optimizing neural networks with stochastic gradient descent to improve the performance of the filter. The authors study the problem of learning Filter Filters, and show that a smoother input distribution leads to faster convergence and a more efficient filter."
"We introduce a notion of conservatively-extrapolated value functions, which provably lead to policies that can self-correct to stay close to the demonstration states, and learn them with a novel negative sampling technique. An algorithm called value iteration with negative sampling to address the covariate shift problem in imitation learning.","A novel reinforcement learning algorithm that learns a value function that extrapolates to unseen states more conservatively, as an approach to attack the optimistic extrapolation problem. This work introduces a new model of reinforcement learning based on values functions that extrapolate from unseen states to unseen ones. The study presents a reinforcement learning method for reinforcement learning that learns values functions with conservative extrapolation and achieves near-optimal performance.","A novel reinforcement learning algorithm that learns a value function that extrapolates to unseen states more conservatively, as an approach to attack the optimistic extrapolation problem (Fujimoto et al., 2018a). This paper proposes a reinforcement learning method that learns values functions with conservative extrapolation in order to induce policies that stay close to demonstration states.",An algorithm that learns a value function that extrapolates to unseen states and achieves near-optimal performance. This work introduces an approach to attack the optimistic extrapolation problem by learning a values function that is guaranteed to induce policies that stay close to the demonstration states.,An algorithm that learns a value function that extrapolates to unseen states and achieves near-optimal performance. This work presents a method for attacking the optimistic extrapolation problem by learning a values function that is guaranteed to induce policies that stay close to the demonstration states.
"We investigate the merits of employing neural networks in the match prediction problem where one seeks to estimate the likelihood of a group of M items preferred over another, based on partial group comparison data. This work proposes a deep neural network solution to the set ranking problem and designs a architecture for this task inspired by previous manually designed algorithms. This article provides a technique to solve the match prediction problem using a deep learning architecture.","A novel neural network architecture for match prediction that can be easily adapted for a variety of real-world online game datasets. This work introduces a new neural network framework for the match prediction problem, based on a BTL model. The authors introduce two new neural networks, MM-sum and MM-prod, to address the problem of cross entropy loss in match prediction.","A novel algorithm for match prediction that can be easily adapted to real-world online game datasets. This paper proposes a new neural network architecture based on the BTL model, which can be applied to match prediction tasks. The authors propose an extension of BTL by incorporating two modules R and P into the existing model to achieve maximum likelihood.","A new model for rank aggregation tasks that can be extended to achieve satisfactory performance on a variety of real-world datasets. This work introduces a new model called RTL, which can be used to predict the likelihood of a group of M items preferred over another. The authors present a novel algorithm for ranking aggregations and show that a single layer neural network can fit some variants of the BTL model and improve prediction accuracy.","Using a single layer neural network to improve prediction accuracy on real-world online game datasets. This work introduces a BTL model that can be applied to rank aggregation tasks, and shows that it is adaptable for other tasks. The authors present a new model for match prediction in the context of a group of M items chosen by a collection of n items selected from a given dataset."
"We investigate ReLU networks in the Fourier domain and demonstrate peculiar behaviour. Fourier analysis of ReLU network, finding that they are biased towards learning low frequency This article has theoretical and empirical contributions on topic of Fourier coefficients of neural networks","This study studies the spectral bias of deep neural networks in the context of random parameter perturbations. This study investigates the problem of learning a deep neural network with low frequencies, and shows that it is more robust to random parameters than deep neural nets with high frequencies. The study presents a method for learning deep neural architectures with low-frequency components that can be used to train models with low frequency.","This study studies the spectral bias of deep neural networks, and shows that it is not just in the process of learning, but also in the parameterization of the model itself: in fact we show that the lower frequencies of trained networks are more robust with respect to random parameter perturbations. This paper proposes a new method for learning deep neural network architectures by studying the spectral biases of deep-learning models.","A method for learning neural networks that is biased towards expressing a subset of low frequency solutions. This article introduces a bias in neural networks, which manifests itself in the process of learning, but also in the parameterization of the model itself. The authors considers the problem of learning neural network models and show that the lower frequencies of trained neural networks are more robust with respect to random parameter perturbations.","A neural network that is biased towards expressing a subset of such solutions, namely those that are low frequency. This study presents a neural network bias that manifests itself in the process of learning, but also in the parameterization of the model itself. The authors show that the lower frequencies of trained neural networks are more robust with respect to random parameter perturbations."
"We refine the over-approximation results from incomplete verifiers using MILP solvers to prove more robustness properties than state-of-the-art. Introduces a verifier that obtains improvement on precision of incomplete verifiers and scalability of the complete verifiers using over-parameterization, mixed integer linear programming and linear programming relaxation. A mixed strategy to obtain better precision on robustness verifications of feed-forward neural networks with piecewise linear activation functions, achieving better precision than incomplete verifiers and more scalability than complete verifiers.","A combination of state-of-the-art overapproximation techniques used by incomplete methods for neural network robustness. This work presents a method to certify neural networks robustness in the context of adversarial examples. The authors present a method for certifying neural networks that is asymptotically complete as non-complete methods, and show that it is possible to verify robustness properties.","A new method for verifying neural network robustness that combines state-of-the-art overapproximation techniques with MILP solvers. This paper proposes a novel approach to verify neural networks robustness by combining state of the art non-ILP methods with deep Zonotope transformers. The authors propose a new approach to verifying neural networks' robustness properties, which is based on a combination of deep Zono and abstract interpretation.","A novel heuristic verifier for neural network robustness. This work introduces a method to combine overapproximation with inexact MILP formulations of the network, which are then solved to achieve more precise results for neuron bounds. The authors present a novel verifier that uses a combination of incomplete methods, including LP relaxations, and affine transformations.","A novel verifier for deep neural network robustness, combining overapproximation with an inexact MILP formulation. This work introduces a method for solving deep neural networks without adversarial examples by using a combination of state-of-the-art techniques and a novel heuristic that points to neural networks whose approximated bounds should be refined."
Using Wasserstein-GANs to generate realistic neural activity and to detect the most relevant features present in neural population patterns. A method for simulating spike trains from populations of neurons which match empirical data using a semi-convolutional GAN. The study proposes to use GANs for synthesizing realistic neural activity patterns,Spike-GAN is able to learn the structure of packets generated by a neural network. This study presents a novel neural network architecture that learns to encode information about a given set of stimuli in a spatio-temporal manner. The authors investigate the applicability of Spike-GAN to deep neural networks and show that it can be used to detect the most relevant aspects of a given stimulus.,"Spike-GAN is able to detect the most relevant aspects of a given set of stimuli. This paper proposes a novel neural network that learns to encode information about a given subset of neurons in response to a given stimulus. The authors propose a new neural network, Spike-GAN, which can be used to learn the most important aspects of each neuron's response to an incoming packet.",A method to model neural activity patterns in response to a given set of stimuli using supervised learning techniques. This study introduces a novel way to model the activity patterns generated by GANs by comparing them to those obtained with a maximum entropy model and showing that Spike-GAN is able to effectively mimic their underlying distribution.,"A new neural network that can be used to model a set of stimuli using supervised learning techniques. This study investigates the application of deep learning methods to real datasets and shows that Spike-GAN is not only memorizing but also mimicking their underlying distribution. The authors present a novel method for modeling neural activity in response to a given set of stimulations, and show that it is able to emulate the current distribution of the generated samples."
This work describe a 3D authoring tool for providing AR in assembly lines of industry 4.0 The article addresses how AR authoring tools support training of assembly line systems and proposes an approach An AR guidance system for industrial assembly lines that allows for on-site authoring of AR content. Presents a system that allows factory workers to be trained more efficiently using augmented reality system.,A novel 3D authoring tool that allows users to create 3D scenes of workstations by placing 3D objects on the assembly line. This article presents a novel 3-D authorization tool that enables users to make 3D 3D models of the workstation. The authors present a novel method for authoring 3D images of the assembly lines of an industrial machine.,"A novel authoring tool that enables users to create 3D scenes of workstations by placing 3D objects representing the workstation. The authors propose a novel authorizing tool for assembly line operators, which is based on an AR-based operator training system. This article presents a novel method for authoring 3D images of industrial components and tasks using a mobile AR platform.","A novel authoring tool designed to allow users to create 3D representations of the assembly line, and to place anchors and markers for the AR guidance elements. This article introduces a new authoring method that can be used to generate 3D models of industrial components and workstations. The authors present a novel authorizing tool called WAAT, which allows users to use an operator training system to create a visual representation of the entire assembly line.","A new authoring tool designed to allow users to create a 3D representation of the assembly line, and to place anchors and markers for the AR guidance elements. This article introduces a new Authoring Tool that can be used to create 3D models of industrial components and workstations. The article presents a method for creating 3D modeling objects using an operator training system, which allows users to use their own information on the instructions of the machine learning process."
Learning Priors for Adversarial Autoencoders Proposes a simple extension of adversarial auto-encoders for conditional image generation. Focuses on adversarial autoencoders and introduces a code generator network to transform a simple prior into one that together with the generator can better fit the data distribution,"A deep generative framework for generating images with a simple prior that is best suited for explaining the data distribution. This work introduces a new approach to generating images by replacing the manually-specified prior with a fully connected code generator. The authors introduce a new model of generative models, AAE, which uses a variational learning technique to transform the manually selected prior into a better representation of the data.",A deep generative model that replaces the manually-specified prior with a learned prior by training the code generator to generate images that are better suited for explaining the data. This paper proposes a novel approach to generating images from latent variables in order to minimize adversarial loss in the data space. The authors propose a new method for generating images that is more suitable for understanding the data distribution of a given class.,This paper introduces a new method for learning a prior over latent variables to minimize adversarial loss in data space. The article presents a method for defining a latent variable distribution in the deep generative model by learning the decoder to generate images with a distribution that matches the empirical distribution of real images in the training data. The authors introduce a variational learning technique to maximize the mutual information between the variable s and the generated image.,"A deep generative model that can be learned from the code generator to minimize adversarial loss in data space. This work introduces a neural network for generating images with a latent distribution that is capable of learning from the decoder. The authors present a variational learning method to maximize the mutual information I(s) between the variable and the generated image, and show that it is possible to learn a prior over the latent variables during training."
learn hierarchal sub-policies through end-to-end training over a distribution of tasks The authors consider the problem of learning a useful set of É??sub policiesÉ?? that can be shared between tasks so as to jump start learning on new tasks drawn from the task distribution. This study proposes a novel method for inducing temporal hierarchical structure in a specialized multi-task setting.,A method for fast learning in complex physics environments with long time horizons. This work presents a method to iteratively learn sub-policies that allow agents to achieve maximum reward over sparse-reward tasks. The authors present a method for learning sub-policy structures that can be used to speed up the learning process on complex physics tasks. This study presents an approach to fast learning of complex physics problems using a policy gradient update.,"A method for fast learning in complex physics environments with long time horizons. The authors propose a method to iteratively learn sub-policies that allow agents to achieve maximum reward over sparse-reward tasks. This work proposes a method for faster learning in complicated physics environments where the agent is given a set of sub-policy gradients, and then learns a new policy gradient update to maximize reward.","A method for sparse-reward learning that is efficient enough to learn in complex physics environments with long time horizons, and robust enough to transfer sub-policies towards otherwise unsolvable tasks. This article introduces a novel metalearning method to learn quickly over a large number of gradient updates in the RL setting-a regime.","A new master policy that is optimized for sparse-reward tasks. This work introduces a new model of sub-policies that can be used to train agents in complex physics environments with long time horizons. The authors show that the master policy is efficient enough to learn in a large number of gradient updates, and that it is robust enough to transfer them towards otherwise unsolvable non-solvable tasks."
"Represent each entity as a probability distribution over contexts embedded in a ground space. Proposes to construct word embeddings from a histogram over context words, instead of as point vectors, which allows for measuring distances between two words in terms of optimal transport between the histograms through a method that augments representation of an entity from standard ""point in a vector space"" to a histogram with bins located at some points in that vector space.","A new metric for word entailment between entities and contexts. This work introduces a new metric to measure the distance between words between entities, which can be used to improve the efficiency of existing point-wise embedding methods. The study presents a method for measuring distance between two words in NLP, and shows that it is more efficient than point-based methods.","A new metric for word entailment in NLP. This paper proposes a method for estimating the distance between two words that is more efficient than point-wise embedding methods. The study presents a method to estimate the distance of words between two entities, which can be used as a proxy for how much information is available on a given document.","A point-wise embedding method for word entailment, which can be used to measure any kind of distance between words. This article presents a method for learning representations that are able to effectively capture such inherent uncertainty and polysemy. The authors show that distributional estimations capture more of this information compared to points-wise embedded vectors alone, but has largely been ignored in the past.","A method for optimal transport between documents and contexts that can capture such inherent uncertainty and polysemy. This work explores the problem of co-occurrence information required to build the distributions as a first step of point-wise embedding methods, but has been ignored in the past. The authors present a method for determining the distance between documents by defining a suitable underlying cost on the movement of contexts."
"precision highway; a generalized concept of high-precision information flow for sub 4-bit quantization Investigates the problem of neural network quantization by employing an end-to-end precision highway to reduce the accumulated quantization error and enable ultra-low precision in deep neural networks. This work studies methods to improve the performance of quantized neural networks This paper proposes to keep a high activation/gradient flow in two kinds of networks structures, ResNet and LSTM.","A novel network-level method for quantization of high-precision information flow. This work introduces a new method for training convolutional neural networks, called precision highway, which can be applied to both pre-activation and post-activation neural networks. The study presents a novel approach to quantization in the context of deep neural networks where the activation tensor is directly connected to the residual path.","High-precision quantization with no accuracy loss and 2.45 % top-1 accuracy loss in ResNet-50 This article proposes a novel method for quantization of deep neural networks, called precision highway, which can be applied to both pre-activation and post-activation convolutional neural networks. The paper proposes a new approach to quantization that is more efficient than existing methods.","A network-level approach to quantization, called precision highway, which can be applied to both pre-activation convolutional and recurrent neural networks. This work introduces a novel quantization method for high-precision information flow by proposing a weight-binarized AlexNet that gives the same accuracy as a fully precision one.","A network-level approach to quantization, called precision highway, for high-precision information flow. This work introduces a novel quantization method that can be applied to the pre-activation convolutional and recurrent neural networks. The authors present a method for quantization using weight/activation quantization with no accuracy loss and an analysis of the energy and memory overhead of the network."
"Many graph classification data sets have duplicates, thus raising questions about generalization abilities and fair comparison of the models. The authors discuss isomorphism bias in graph datasets, the overfitting effect in learning networks whenever graph isomorphism features are incorporated within the model, theoretically analogous to data leakage effects.","A method for graph classification based on isomorphic graphs in training data sets. This study presents a new method for learning to classify graphs in the training data set, which is based on graph isomorphism bias. The authors introduce a new algorithm for graph isomorphic graph classification, called WL algorithm, which can be used to improve the generalization ability of the models.","A method for graph classification based on isomorphic graphs in the training data set. This paper proposes a novel approach to graph classification by introducing a new class of graphs that are isomorphic to existing data sets. The authors propose a new classification algorithm which can be used to improve the generalization ability of the models, and provide an empirical benchmark to evaluate the accuracy of the methods.","A graph classification problem with isomorphic graphs can be interpreted as a classification problem with weighted loss. This article presents a method for graph classification that uses WL algorithm to generalize to ""harder"" instances than in the original test sets. The authors address the problem of classifying graphs in data sets using a combination of individualization and individualization-refinement paradigms, showing a drop of accuracy by up to 15%.","A graph classification algorithm for isomorphic graphs that has repeating instances which cause the problem of a bias in the training data set. This work presents a graph classification problem with mismatched target labels that are different from the target label, and shows that it is not expressive enough to map the structure of the graphs to the target labels correctly. The authors present a method to classify graphs using a single number that uniquely identifies an individual graph."
"We utilize the alternating minimization principle to provide an effective novel technique to train deep autoencoders. Alternating minimization framework for training autoencoder and encoder-decoder networks The authors explore an alternating optimization approach for training Auto Encoders, treating each layer as a generalized linear model, and suggest using the stochastic normalized GD as the minimization algorithm in each phase.","An alternating minimization strategy for quasi-convex optimization. This article introduces a new method for training autoencoders with sigmoidal activation functions, which provides an efficient implementation of DANTE. This work presents a novel approach to quasi-Convex problem where the layers are trained as a set of generalized linear activation functions. The authors introduce a new variant of the SNGD that combines the sigmoid activation functions with the generalized ReLU activation functions","DANTE is an alternating minimization strategy for quasi-convex optimization. This paper proposes a new approach to quasi-convolutional neural networks by combining two different autoencoder activation functions. The article presents a novel method for training autoencoders with sigmoidal activation functions, which improves the performance of semi-convictional neural nets.","A novel method for training neural networks with sigmoid activation functions. This work introduces a new algorithm to train autoencoders by using alternating minimization and showing how DANTE can be applied to multi-layer neural networks. The paper presents a method for learning deep networks with multiple hidden layers, which uses a generalized gradient descent technique to perform quasi-convex optimization.","A method for training neural networks with sigmoid activation functions that can be applied to quasi-convex optimization problems. This work introduces alternating minimization strategy, DANTE, which can be used to train multi-layer networks with multiple hidden layers. The authors present a method to train autoencoders and show how to use the generalized ReLU function to train deep neural networks without further finetuning/cross-validation."
"We propose an algorithmic framework to schedule constellations of small spacecraft with 3-DOF re-orientation capabilities, networked with inter-sat links. This article proposes a communication module to optimize the schedule of communication for the problem of spacecraft constellations, and compares the algorithm in distributed and centralized settings.","Combine physical models of orbital mechanics (OM), attitude control systems (ACS), and inter-satellite links (ISL) and optimizes the schedule for any satellite in a constellation to observe a known set of ground regions with rapidly changing parameters and observation requirements. This work presents an approach to optimizing the scheduler for each satellite in the constellation.","A novel algorithmic framework that combines physical models of orbital mechanics (OM), attitude control systems (ACS) and inter-satellite links (ISL) to optimise the schedule for any satellite in a given constellation. This paper proposes an approach to optimizing the scheduler for each satellite in the network, with the goal of reducing latency.","A physics-based agile EO scheduler that optimizes the schedule for any satellite in a given constellation to observe a set of ground regions with rapidly changing parameters and observation requirements. This work presents a novel algorithmic framework that combines physical models of orbital mechanics (OM), attitude control systems, and inter-satellite links to improve the revisit/response for the same number of satellites Copyright  2019.","A new algorithmic scheduler that optimizes the schedule for any satellite in a given constellation to observe a known set of ground regions with rapidly changing parameters and observation requirements. This work introduces an algorithmic framework for combining satellite and subsystem characteristics with a network-wide scheduler, which is expected to run onboard every satellite from one GP to another."
"Image captioning as a conditional GAN training with novel architectures, also study two discrete GAN training methods. An improved GAN model for image captioning that proposes a context-aware LSTM captioner, introduces a stronger co-attentive discriminator with better performance, and uses SCST for GAN training.","A novel GAN framework for image captioning based on Self-critical Sequence Training (SCST) and Gumbel Straight-Through (ST) This work introduces a new GAN-based framework that outperforms other GANs in terms of training stability and the overall performance. This work presents a novel sequence-based GAN architecture that enables better language composition, more expressive captions, and more descriptive captions.",Self-critical Sequence Training (SCST) and Gumbel Straight-Through (ST) This paper proposes a novel GAN framework for image captioning based on self-critical sequence training. The authors propose a new GAN architecture that outperforms the existing Gumbels in terms of performance and generalizability. Presents a novel method for generating captions from image and caption using Self-Critical Sequence Training,"A novel GAN-based framework for image captioning that enables better language composition, more accurate compositional alignment of image and text, and light-weight efficient training of discrete sequence GANs. This work introduces a GAN framework that combines self-critical Sequence Training (SCST) and Gumbel Straight-Through (Gumbel ST).","A GAN-based framework for image captioning that enables better language composition, more accurate compositional alignment of image and text, and light-weight efficient training of discrete sequence GANs. This work studies the viability of self-critical Sequence Training (SCST) and Gumbel Straight-Through (Gumbel ST)."
A two-stage approach consisting of sentence selection followed by span selection can be made more robust to adversarial attacks in comparison to a single-stage model trained on full context. This work investigates an existing model and finds that a two-stage trained QA method is not more robust to adversarial attacks compared to other methods.,"A two-stage approach for question-answering with adversarial training. This paper presents a novel approach for QA that combines sentence selection and context selection to improve the robustness of both models. This work introduces a new approach to QA in which sentence selection is combined with context selection, allowing for more robust robustness to adversarial attacks.","A two-stage approach for question answering that is more robust to adversarial attacks than single-stage approaches. This paper proposes a new approach for QA which combines sentence selection and context selection in order to improve the robustness of QA models. The authors propose a novel method for improving QA by combining sentence selection, context selection, and sentence selection with adversarial training.","A promising two-stage approach for QA which decomposes the task into two stages: select relevant sentences from the passage; and select a span among those sentences. This work introduces a new approach for question-answering (QA), where an adversary can fool the model into selecting the wrong span in the passage. The study presents a novel way to improve adversarial robustness in both the context selection and span selection.",A new approach for two-stage QA that decomposes the task into two stages: select relevant sentences from the passage; and select a span among those sentences. This work presents a novel way to make adversarial models more robust to adversarially attacks. The authors present a method for learning a fixed-length question representation that is then used to score potential spans in the context selection process.
"We use a GAN discriminator to perform an approximate rejection sampling scheme on the output of the GAN generator. Proposes a rejection sampling algorithm for sampling from the GAN generator. This study proposed a post-processing rejection sampling scheme for GANs, named Discriminator Rejection Sampling, to help filter É??goodÉ?? samples from GANsÉ?? generator.","A new rejection sampling method for GANs that can be used to correct errors in the GAN distribution. This paper introduces a new method for solving the problem of discriminator rejection sampling, which is based on the assumption that the discriminator is biased towards a given distribution. The work presents a new rejection sample method for generating samples that are biased toward a particular class of classes.","Discriminator Rejection Sampling (DRS) is an adjustment of the discriminator to approximately correct errors in the GAN generator distribution. This paper proposes a new rejection sampling method for GANs that addresses the problem of disentangled samples, and shows that it can be used to improve the accuracy of the algorithm. The article proposes a method for discriminating GAN generators by using a discriminator instead of a random sample generator.","Using a rejection sampling scheme to approximately correct errors in the GAN generator distribution. This article introduces a method for generating samples from pre-trained generators, and shows that under quite strict assumptions, this scheme allows us to recover the data distribution exactly. This work presents a novel rejection sampling algorithm for GANs using a discriminator to approximate the true data distribution of the generator.","A method to correct errors in the GAN generator distribution. This work introduces a new rejection sampling scheme using the discriminator to completely minimize its own loss yields DISPLAYFORM. The authors present a method for resolving the problem of reject sampling and show that under quite strict assumptions, this scheme allows us to recover the data distribution exactly."
We show how to get good representations from the point of view of Simiarity Search. Studies the impact of changing the image classification part on top of the DNN on the ability to index the descriptors with a LSH or a kd-tree algorithm. Proposes to use softmax cross-entropy loss to learn a network that tries to reduce the angles between inputs and the corresponding class vectors in a supervised framework using.,"An approximate nearest neighbor search algorithm for hyperplane neural networks. This article studies the problem of finding the correct distance between a query and its nearest neighbor in a dataset of size n. The study presents a method to find the nearest neighbor of a hyperplane NNS algorithm, based on the cosine similarity theorem.","An approximate nearest neighbor search algorithm for hyperplane neural networks. This article proposes a method for solving the cosine similarity NNS problem, where the distance between the query and its nearest neighbor is the angular distance É?ˇ(q, p) DISPLAYFORM0 2.1 THEORETICAL ANALYSIS Different NNS algorithms rely on different properties on the data in order to enable faster similarity search. The authors propose an approximate distance search algorithm based on the angle between the querying vector and the nearest neighbor.","A method for determining the angle between query and database points to determine the nearest neighbor. This work studies the cosine similarity NNS problem in hyperplane LSH BID3 using an angle of  with the closest vector, and compares the two ANN implementations as a function of the angle of the query and the closest neighbor search. The paper presents a method to estimate the distance between query time and query time to find the correct neighbor.",A new dataset of n = 10 6 random unit vectors and plant queries at a given angle  from a randomly selected subset of database points. The authors study the cosine similarity problem in hyperplane LSH BID3 and show that the probability of finding the closest vector is at least 99.33%.
Adversarial learning methods encourage NLI models to ignore dataset-specific biases and help models transfer across datasets. The paper proposes an adversarial setup to mitigate annotation artifacts in natural language inference data This work presents a method for removing bias of a textual entailment model through an adversarial training objective.,"An adversarial architecture for NLI models that does not require direct supervision in the form of a domain label. This work introduces a new classifier architecture that can be trained on NLI datasets without requiring direct supervision. The authors introduce two new adversarial architectures, a baseline NLI architecture and an adversarial hypothesis-only architecture.","An adversarial architecture for NLI models that does not contain hidden biases in the training corpus. This paper proposes two adversarial architectures that enable a model to generalize well on NLI datasets despite the high presence of annotation artifacts. The authors propose an adversarial approach to NLI training by adding a bias-only classifier to each target dataset, and then removing the bias from the latent representation.",A domain-adversarial training framework for NLI models that performs well on other NLI datasets regardless of what annotation artifacts exist in the training corpus's hypotheses. This work introduces two architectures that enable a model to perform well on non-trivial datasets without possibly learning the relationship between the two texts.,"A domain-adversarial training framework for neural networks that can perform well on other NLI datasets regardless of what annotation artifacts exist in the training corpus' hypotheses. This work presents two architectures that enable a model to perform well against hidden biases, while in fact they are still hidden in the representation. The authors present an adversarial loss function that reduces the risk of false impressions of success."
"Object instance recognition with adversarial autoencoders was performed with a novel 'mental image' target that is canonical representation of the input image. The paper proposes a method to learn features for object recognition that is invariant to various transformations of the object, most notably object pose. This paper investigated the task of few shot recognition via a generated É??mental imageÉ?ù as intermediate representation given the input image.",MIDCGAN is a novel autoencoder that learns features that are useful for image generation. This work introduces a new model of autoencoders for the problem of generating images that are sharper and closer to the target than a regular autoencatcher. The authors introduce a new method for generating images from mental images that can be used for general classification tasks such as image-to-image translation.,"MIDCGAN is an autoencoder that learns features that are useful for generative reasoning. This paper proposes a novel approach to generating representations of mental images that can be used for classification tasks. The authors propose a novel autoencoders based on the idea of using mental images as a representation of objects, and propose a new method to generate representations of objects in order to use them for classification purposes.","A mental image DCGAN that learns features that are useful for recognizing entire classes of objects. This article introduces a new way to learn the mental image and adversarial loss in a multimodal autoencoder, where the discriminator can tell a real target sample quickly and the real component of the opponent. The authors present a mental image generation approach with a dual-mode learning approach","A new mental image DCGAN that learns features that are useful for recognizing entire classes of objects. This work introduces a new approach to learning mental images from the perspective of an object generation model and a discriminator-like representation of the object in the form of a bottleneck feature vector, of length n. The authors describe a novel way of learning mental image recognition by learning a range of classification features from the input to the target distribution."
"Question answering models that model the joint distribution of questions and answers can learn more than discriminative models This paper proposes a generative approach to textual and visual QA, where a joint distribution over the question and answer space given the context is learned, which captures more complex relationships. This paper introduces a generative model for question answering and proposes to model p(q,a|c), factorized as p(a|c) * p(q|a,c). The authors proposes a generative QA model, which optimizes jointly the distribution of questions and answering given a document/context.","A generative QA model that learns to answer questions independently of the answer and document. This work introduces a generative model for answering questions using question-to-context attention. The study presents a novel QA framework for answering complex questions in a multi-sentence setting, where the question is answered independently from the document and the document.","A generative QA model for answering questions independently of the answer and document This paper proposes a novel method for answering question-to-question questions in CLEVR. The authors propose a generative approach to answering questions by using a self-attention mechanism to select the correct word for each question. The article proposes a new way of answering questions on CLEVR, which is based on an attention mechanism that allows the model to learn more information about the question.","CLEVR is a fully connected layer applied to the concatenation of word embeddings and the hidden states of each layer of the language model. This work studies the problem of over-fitting to discriminative loss functions, which saturate when simple correlations allow the question to be answered confidently, leaving no incentive for further learning on the example.","A discriminative language model that can identify the only producer, and ignore the rest of the question. This work introduces a discriminative loss function which saturates when simple correlations allow the question to be answered confidently, leaving no incentive for further learning on the example. The authors address the problem of discriminative word embedding by using a hidden state of each layer of a language model with a trainable vector of size d."
"We learn deep networks of hard-threshold units by setting hidden-unit targets using combinatorial optimization and weights by convex optimization, resulting in improved performance on ImageNet. The study explains and generalizes approaches for learning neural nets with hard activation. This article examines the problem of optimizing deep networks of hard-threshold units. The study discusses the problem of optimizing neural networks with hard threshold and proposes a novel solution to it with a collection of heuristics/approximations.","A recursive mini-batch algorithm for learning deep neural networks with hard-threshold activations. This work introduces a recursive minibatch algorithm to learn deep neural network activations that includes the popular straight-through estimator as a special case. This paper presents a recursive semi-batch method for learning neural networks that includes a deep gradient descent problem, and shows that it improves classification accuracy in a number of settings, including AlexNet.",A recursive mini-batch algorithm for learning deep neural networks with hard-threshold activations. This paper proposes a new algorithm to learn deep neural network architectures with non-differentiable activations in order to minimize loss. The authors propose an algorithm for improving the accuracy of deep neural net classification by using gradient descent as a general optimization problem.,"A discrete optimization problem for hard-threshold hidden units in order to minimize loss. This work presents a mini-batch algorithm for learning deep neural networks that includes the popular but poorly justified straight-through estimator as a special case. The authors address the problem of learning deep deep networks with gradient descent, and show that it improves classification accuracy in a number of settings, including for AlexNet and ResNet-18 on ImageNet.","A mini-batch algorithm for learning deep hard-threshold networks that includes the popular but poorly justified straight-through estimator as a special case. The authors address the problem of learning deep neural networks with hidden units in order to minimize loss, and show that it improves classification accuracy in a number of settings, including for AlexNet and ResNet-18 on ImageNet."
"pix2scene: a deep generative based approach for implicitly modelling the geometrical properties of a 3D scene from images Explores explaining scenes with surfels in a neural recognition model, and demonstrate results on image reconstruction, synthesis, and mental shape rotation. Authors introduce a method to create a 3D scene model given a 2D image and a camera pose using a self-superfised model",A novel method of unsupervised learning of 3D structure from a single view of a scene. This work introduces a novel method for learning 3D structural properties of objects in a scene by using a variational encoder network. The study presents a novel approach to learn 3D representations of objects that can be viewed from a wide range of locations.,"A method of unsupervised learning of 3D structure from a single view of a given scene. This paper proposes a novel approach to learn 3D structural properties of objects in a scene using a variational encoder network. The authors propose a novel method for learning 3D structures based on a low-dimensional latent variable, which can be used to train models that can infer the structure of a scene.","A method of unsupervised learning of the 3D structure from a single 2D image. This work introduces a method to infer the structural properties of a 3D scene using a latent variable (or vector) into a viewpoint-dependent representation of surface elements that constitute the visible part of the scene. The authors present a new model for 3D rendering, which uses a gradient-based renderer and a surfel-based rendering pipeline.","A method of unsupervised learning of the 3D structure in a 3D scene using a latent variable. This work studies the structural properties of a 2D scene and shows that only a small fraction of the entities are perceivable from the camera. The authors present a method to learn a surfel-based representation of the visible part of the scene by learning a viewpoint-dependent representation of surface elements, similar to surfels BID24"
"We show how to use deep RL to construct agents that can solve social dilemmas beyond matrix games. Learning to play two-player general-sum games with state with imperfect information Specifies a trigger strategy (CCC) and corresponding algorithm, demonstrating convergence to efficient outcomes in social dilemmas without need for agents to observe each other's actions.",A new reward-ergodic strategy for cooperative and selfish agents. This article introduces a new policy gradient approach for cooperative/selfish agents in Markov games. This study presents a new reward gradient approach to cooperative/socially motivated agents in the Prisoner's Dilemma (POMG) where the agent learns to cooperate with the other agent. The authors present a novel policy gradient method for cooperating with other agents in a Markov game,"A new policy gradient approach for cooperative and selfish agents in Markov games. This paper proposes a new policy-based approach to cooperate in the Prisoner's Dilemma by learning cooperative policies and switching between them as needed (Lerer & Peysakhovich, 2017), or as an outcome of an end-to-end procedure (Foerster et al., 2017c). The authors propose a novel policy gradient technique for cooperative/selfish agents in POMGs where the goal is to avoid defection.","A method for learning cooperative and selfish policies that improves the behavior of both agents. This article introduces a new policy-ergodic approach to exchangeability in the prisoner's Dilemma, which can be used as a co-operation problem. The authors address the problem of exchangeability between agents by using a pair of policies, one for each agent, and a starting state with a low rate of payoff.","A method for learning cooperative and selfish policies that improves game-to-game performance. The authors address the problem of defection in the Prisoner's Dilemma by introducing a new policy gradient technique to improve the rate of payoff between agents. This article introduces a novel approach to learn cooperative policies, which can be used to train agents with a different level of co-operation and a higher rate of return on their own."
We learn a fast neural solver for PDEs that has convergence guarantees. Develops a method to accelerate the finite difference method in solving PDEs and proposes a revised framework for fixed point iteration after discretization. The authors propose a linear method for speeding up PDE solvers.,"A new iterative solver that converges faster than the hand designed solver. This article introduces a new iteratively solver for deep linear convolutional networks, which can be easily obtained on different geometries and boundary conditions. The study presents a new Iterative Solver for a class of problems where the fixed point of the function is the same as that of the previous iteration.",A new iterative solver for discretized PDE problems that converges to the correct solution in a single iteration. This paper proposes a method for learning an iterative linear solver that is faster than hand-designed ones BID20 BID12. The authors propose a new Iterative Solver for Discretized Processes (DPEs) where the objective is to solve the problem of discretization by solving the problem with only fixed points.,"A new linear convolutional network with a fixed point and fast convergence on the class of problems of interest. This work introduces a new iterator for discretized PDE problems, where the function b is clear from the underlying physical problem. The paper presents a method to learn a linear convex operator that can be used to solve discretized problems by learning a solution governed by the same A.",A new linear convolutional network that can be used to solve a class of PDE problems governed by the same A. This work introduces a new iterator for discretized PDE problem solving with a fixed point and fast convergence on the class of problems of interest. The authors address the problem of learning an iterative solver that is able to approximate T (I) from a single point of view.
"Propose a novel method by integrating SG-MCMC sampling, group sparse prior and network pruning to learn Sparse Structured Ensemble (SSE) with improved performance and significantly reduced cost than traditional methods. The authors propose a procedure to generate an ensemble of sparse structured models A new framework for training ensemble neural networks that uses SG-MCMC methods within deep learning, and then increases computational efficiency by group sparsity+pruning. This work explores the use of FNN and LSTMs to make bayesian model averaging more computationally feasible and improve average model performance.","A Bayesian model averaging method for LSTMs that outperforms SGD and other Bayesian inference frameworks. This work presents a Bayesian method for learning LSTM models using stochastic gradient descent (SGLD). The authors present a method to learn a Bayes-based model averaging algorithm, which can be used to improve the performance of existing Bayesian models.","A Bayesian model averaging method that can improve the performance of neural networks in real-world tasks. This paper proposes a method to learn Bayesian models using stochastic gradient descent (SGLD). The authors propose a method for learning Bayesian ensembles from SGD, which is based on a Bayesian inference framework. The article proposes an approach to training Bayesian generative models with SGLD by reducing the posterior sampling and improving the accuracy of the ensemble.","A Bayesian model averaging is more accurate in prediction and robust to over-fitting than point estimates of parameters. This study presents a Bayes-based method for posterior sampling, which uses a SGLD learning rate to learn from the posterior. The paper considers the problem of posterior sampling with a large number of models, and suggests a way to improve performance by using a random pruned network instead of random connection pruning.","A Bayesian inference framework that averaging more models than other traditional methods of learning ensembles can improve performance. This study studies the problem of posterior sampling in LSTM with an emphasis on discretization error, and shows that SGLD does not have a Metropolis-Hastings correction step. The authors present a method for evaluating posterior sampling as a result of a lack of regularization in the case of DNNs."
"We propose and apply a meta-learning methodology based on Weak Supervision, for combining Semi-Supervised and Ensemble Learning on the task of Biomedical Relationship Extraction. A semi-supervised method for relation classification, which trains multiple base learners using a small labeled dataset and applies some of them to annotate unlabeled examples for semi-supervised learning. This paper addresses the problem of generating training data for biological relation extraction, and uses predictions from data labeled by weak classifiers as additional training data for a meta learning algorithm. This paper proposes a combination of semi-supervised learning and ensemble learning for information extraction, with experiments conducted on a biomedical relation extraction task","An ensemble learning method for improving generalization of deep neural networks on large datasets. This work introduces a new approach to Deep Neural Networks, called Majority Voting, which is an ensemble learning technique that uses a simple bi-directional Long-Short Term Memory network and a large dataset. The study presents a new method for learning a diverse set of data points in a supervised learning setting.","An ensemble learning method for improving the generalization of deep neural networks. This paper proposes a new approach to Deep Neural Networks, which can be adapted and generalized to most supervised learning tasks; (b) demonstrating the effectiveness and usability of this methodology in a small-scale controlled experiment; and (c) investigating the effect of various denoising methods on the overall system behavior and performance. This article proposes a method for learning from unlabeled data points that is more accurate than existing models.","Using an ensemble learning methodology to improve the generalization of relation extraction in a small-scale controlled experiment. This work introduces a new method for supervised learning, which can be used on large-scale (or web-scale) datasets. The authors present a detailed approach to denoising relationships with neural networks, and show that it is useful for training data from different sources.","This study introduces a new ensemble learning methodology for relation extraction, which can be adapted and generalized to large-scale (or web-scale) datasets. The authors present a method for ensemble learning with deep neural networks that uses an unlabeled data point to generate a label or abstain from voting. This work explores the problem of ensemble learning in a small-scale controlled environment by using a multi-modal network"
"we propose a regularizer that improves the classification performance of neural networks the authors propose to train a model from a point of maximizing mutual information between the predictions and the true outputs, with a regularization term that minimizes irrelevant information while learning. Proposes to decompose the parameters into an invertible feature map F and a linear transformation w in the last layer to maximize mutual information I(Y, \hat{T}) while constraining irrelevant information","Information Bottleneck (IB) problem is a binary supervised classification problem where the mutual information between signal X and feature T is treated as irrelevant information for classification. This article presents a binary-supervised classification problem based on the notion of mutual information in deep neural networks. The authors present a binary algorithm for classification of binary neural networks, which can be decomposed into two stages: maximization over mutual information and minimization.","Information Bottleneck (IB) problem is a deep neural network optimization problem where the mutual information between signal X and feature Y is treated as irrelevant information for classification. The article proposes an information bottleneck problem, where mutual information is treated with respect to each other in order to avoid overfitting. This paper proposes a new approach to binary supervised classification based on mutual information that can be decomposed into two stages: maximization and minimization","A novel information optimization problem for supervised classification:Maximize I(Y; Y) and prevent over-fitting in the learning process. This article introduces a novel algorithm to optimize neural networks, which can be decomposed into two stages: Transformation stage of the unstructured signal under the deep invertible (invertible) feature map F to become linearly separable.","A novel information optimization problem for the discrete prediction random variable Y in deep neural network. This work introduces a new algorithm to predict the mutual information between signal X and feature T, which can be decomposed into two stages: Transformation stage, transformation stage, and classification stage. The authors present a novel algorithm for the classification of deep neural networks that is robust against invertible features of Y and prevents over-fitting in the learning process."
"Presents new architecture which leverages information globalization power of u-nets in a deeper networks and performs well across tasks without any bells and whistles. A network architecture for semantic image segmentation, based on composing a stack of basic U-Net architectures, that reduces the number of parameters and improves results. This proposes a stacked U-Net architecture for image segmentation.","A deep net-based classification network that globalizes information while preserving resolution. This work introduces stacked u-nets, which iteratively combine features from different resolution scales while maintaining resolution. The work presents a new architecture for image classification that combines the information globalization power of u-nets with semantic segmentation and object detection tasks.","This work proposes stacked u-nets, which iteratively combine features from different resolution scales while maintaining resolution. This paper proposes stacked U-nets to globalize information by decreasing resolution; features are pooled and down-sampled into a single output. This study proposes stacking u-nets for image segmentation and object detection tasks, with the goal of reducing the number of parameters in the network.","stacked u-nets, which iteratively combine features from different resolution scales while maintaining resolution, are capable of handling the complexity of natural images. This article introduces a stack of auxiliary blocks to globalize information while preserving resolution for image segmentation and object detection tasks. The authors study the problem of globalizing information in a deep network by using a small number of parameters that can be used to address semantic segmentation tasks.",A deep-net architecture capable of handling the complexity of natural images that leverages information globalization power of u-nets in a deeper net-work architecture. This study presents a deep network for image segmentation and object detection tasks that requires global information about all pixels in an image. The authors present a wide range of net- work architectures that combine features from different resolution scales to achieve higher resolution on semantic segmentation tasks.
"We introduce a smoothness regularization for convolutional kernels of CNN that can help improve adversarial robustness and lead to perceptually-aligned gradients This article proposes a new regularization scheme that encourages convolutional kernels to be smoother, arguing that reducing neural network reliance on high-frequency components helps robustness against adversarial examples. The authors propose a method for learning smoother convolutional kernels, specifically, a regularizer penalizing large changes between consecutive pixels of the kernel with the intuition of penalizing the use of high-frequency input components.","A smooth regularization of deep neural networks to improve the robustness of models. This work presents a novel method for training deep neural network models that is more robust to adversarial perturbations than vanilla training loss. The authors present a novel algorithm for training neural networks with low-frequency components that can be used to improve their robustness. This study introduces a new approach to training neural network architectures with low frequency components, and shows that regularization can improve robustness significantly.","Regularization of neural networks to improve the robustness of models. This work proposes a novel regularization method for training neural networks with low-frequency components, which improves the accuracy of the model. The authors propose a new regularization algorithm for neural networks that is more sensitive to high-frequency component of an image than normal ones. This paper proposes a new algorithm for training deep neural networks in order to improve their robustness.","Using a smooth kernel to filter out the low-frequency components of an image and improve models' robustness. This work studies the robustness of neural networks by regularizing the CNN to be most sensitive to the low (or high) component of images. The authors use a variation of logit pairing loss, which penalizes the KL divergence over softmax as the distance metric.","Using a smooth kernel to filter out the low-frequency components of an image and improve the robustness of models. This work introduces a new definition of the high-frequency component of a neural network by using a variation of logit pairing loss, which penalizes the KL divergence over softmax as a distance metric."
"We use meta-gradients to attack the training procedure of deep neural networks for graphs. Studies the problem of learning a better poisoned graph parameters that can maximize the loss of a graph neural network. An algorithm to alter graph structure by adding/deleting edges so as to degrade the global performance of node classification, and the idea to use meta-learning to solve the bilevel optimization problem.","A new meta-gradient approach for node classification that is more efficient to compute than adversarial examples. This article presents a meta gradient approach for the problem of node classification, which is an instance of semi-supervised classification where the attacker has full knowledge about the graph structure and all node attributes. The authors present a new meta gradient formulation for the purpose of learning nodes from unlabeled data, which can be used to train deep learning models.","A meta-gradient approach for node classification, which is an instance of semi-supervised classification: given a single (attributed) network and a subset of nodes whose class labels are known (e.g., the topic of a work in a citation graph), the goal is to infer the classes of the unlabeled nodes. This paper proposes a meta gradient formulation that can be used to train deep learning models without access to the class labels.","A meta-learning approach for node classification, which is based on the meta-gradient principle of meta learning. This study introduces a meta learning method to infer the classes of the unlabeled nodes and shows that under restrictive attack settings, without access to the target classifier, our attacks can render it near-useless for use in production (i.e., on test data).","A meta-learning approach for non-targeted node classification, which is based on a meta-gradient that learns to avoid poisoning attackers. This work introduces a new meta gradient method for the detection of attacks in a multi-task learning setting, and shows that the meta gradient achieves similar results to the bi-level formulation in Eq. The authors show that meta learning is more efficient than meta learning."
We evaluate learning heteroscedastic noise models within different Differentiable Bayes Filters Proposes to learn heteroscedastic noise models from data by optimizing the prediction likelihood end-toend through differentiable Bayesian Filters and two different versions of the Unscented Kalman Filter Revisits Bayes filters and evaluates the benefit of training the observation and process noise models while keeping all other models fixed This work presents a method to learn and use state and observation dependent noise in traditional Bayesian filtering algorithms. The approach consists of constructing a neural network model which takes as input the raw observation data and produces a compact representation and an associated diagonal covariance.,A method to learn heteroscedastic noise models from data by optimizing the prediction likelihood end-to-end through differentiable Bayesian Filters. This work introduces a method to train a model that learns to predict the likelihood of an observation given a particle in a graph-construction context. The authors present a method for learning a heterogeneous Bayesian filter based on observation noise.,"A method to learn heteroscedastic noise models from data by optimizing the prediction likelihood end-to-end through differentiable Bayesian Filters. This paper proposes a method to train Bayesian filters based on the observation noise, which improves the accuracy of the model. The authors propose a method for training Bayesian filter models that can be used to predict the likelihood of an observation given a particle in a graph-construction context.",A method to learn heterostochastic process noise models from data by optimizing the prediction likelihood end-to-end through differentiable Bayesian Filters. This work introduces a method for learning heteroscedastic filtering from data using an unscented transform to predict the mean and covariance of the state at the next timestep.,A method to learn heterostochastic noise models from data by optimizing the prediction likelihood end-to-end through differentiable Bayesian Filters. This work presents a method for learning heteroscedastic process noise models by learning the observation noise from data and using it as a filtering method. The authors present a way to learn a heterosceptic process noise model that predicts higher uncertainty for the position and heading of the car.
"We propose a method for learning latent dependency structure in variational autoencoders. Uses a matrix of binary random variables to capture dependencies between latent variables in a hierarchical deep generative model. This article presents a VAE approach in which a dependency structure on the latent variable is learned during training. The authors propose to augment the latent space of a VAE with an auto-regressive structure, to improve the expressiveness of both the inference network and the latent prior",A method for learning the dependency structure between latent variables in deep latent variable models. This work introduces a framework for learning a dependency structure of a variational autoencoder in the latent variable space of a deep generative model. The study presents a framework to learn the dependency structures of a latent variable model in deep neural networks by using a Bayesian network and an inference framework.,A method for learning the dependency structure between latent variables in deep latent variable models. This paper proposes a general modeling and inference framework that combines the complementary strengths of deep generative models and probabilistic graphical models. The authors propose a method to learn the dependencies between latent variable structures in deep variational autoencoder baselines.,"A method for learning the dependency structure between latent variables in deep generative models. The authors present a variational autoencoder framework for learning latent variable space in a Bayesian network with a learned, flexible dependency structure. This work introduces a new model that learns the dependency structure of a Latent Variable Structured Variable Scale (VAE) using a sampling procedure to generate expectations over latent variable structures.","A method for learning the dependency structure between latent variables in deep generative models. This work introduces a variational autoencoder framework that learns the depend structure of a latent variable model and combines it with a learned, flexible dependency structure. The authors present a method to learn a dependency structure in a Bayesian network using a sampling procedure to achieve higher expectations over latent variable structures."
We examine the relationship between probability density values and image content in non-invertible GANs. The authors try to estimate the probability distribution of the image with the help of GAN and develop a proper approximation to the PDFs in the latent space.,"A new GAN based on probability density that predicts the densities of images given their latent representation. This work introduces a new method for predicting the density of images in the MNIST dataset, which is based on a regression analysis of the probability density of the latent representation of the image. The authors introduce a new model of GANs, called GAN-based DNNs, which can predict the predicted density of an image given its latent representation","Improving the accuracy of image density estimation with GANs. This work proposes a new method for estimating the probability density of an image given its latent representation. The authors propose a new DNN-based model that is more accurate in predicting the density of images given their latent representation, and shows that it is easier to estimate the density than the prior model. This paper proposes a deep neural network (GAN) based on the assumption that 1s are likely to be real.","A method to extract the probability density of an image given its latent representation. This article introduces a method for estimating densities in MNIST images, which uses the discriminator to produce samples that are likely to be real and low values to fake points. The authors study the problem of calculating density in GANs by comparing histograms of predicted distributions in the train and test datasets.","A method to extract the probability density value of an image given its latent representation. This work introduces a method for estimating densities of image distributions by using a discriminator to produce samples that are likely to be real and low values to fake points. The authors present a way to estimate density in images of high density, and show that it is possible to use a GAN to generate samples from the discriminator classifying them as real."
A simple fast method for extracting visual features from convolutional neural networks Proposes a fast way to learn convolutional features that later can be used with any classifier by using reduced numbers of training epocs and specific schedule delays of learning rate Use a learning rate decay scheme that is fixed relative to the number of epochs used in training and extract the penultimate layer output as features to train a conventional classifier.,A method to speed up the training of convolutional neural networks with a fast learning rate. This article presents a method to train convolutionally neural networks faster by introducing a new step decay schedule that is a function of the total number of epochs predicted to train the model. The authors present a method for learning convolutionality features fast by introducing an exponential and fast decay of the learning rate of the network.,"A method to speed up the training of convolutional neural networks using exponential and fast decay of the learning rate. This paper proposes a method to train convolutionally neural networks in a fast manner with fewer data augmentation than classical methods. The authors propose a method for learning features fast, which is based on exponential/fast decay of each layer's learning rate during the training phase.",A new approach to learning feature fast is to design a step decay schedule that is a function of the total number of epochs predicted to train the model. This study presents a method to learn feature fast in a neural network by using supervised Convolutional Neural Networks (CNN) to extract high-quality image features.,A new approach to learning feature fast is to design a step decay schedule that is based on the total number of epochs predicted to train the model. This work introduces a method to learn feature fast by using supervised Convolutional Neural Networks (CNNs) to extract high-quality image features Fast. The authors address the problem of building feature fast models with exponential and fast decay of the learning rate.
"Decompose the task of learning a generative model into learning disentangled latent factors for subsets of the data and then learning the joint over those latent factors. Locally Disentangled Factors for hierarchical latent variable generative model, which can be seen as a hierarchical variant of Adversarially Learned Inference The paper investigates the potential of hierarchical latent variable models for generating images and image sequences and proposes to train several ALI models stacked on top of each other to create a hierarchical representation of the data. The work aims to learn the hierarchies for training GAN in a hierarchical optimization schedule directly instead of being designed by a human",An unsupervised method for learning hierarchical latent variables with a resolution-based hierarchy. This article presents a novel method for training deep generative models with a hierarchical latent variable in each layer of the graph. This work introduces a new method for disentangled latent variables in the graph that combines resolution and gradients. The authors present a novel approach for learning hierarchies in a hierarchical way by using a resolution based hierarchy.,"Locally Disentangled Factors (LDF) is an unsupervised method for training deep generative models. This paper proposes a novel method for learning hierarchical latent variables in the context of video and text, which can be used to train deep neural networks. The article proposes a new approach to learn hierarchical latent factors in video that combines resolution-based hierarchies with gradient-based methods.","A method for unsupervised learning of hierarchical latent variables with a requisite but general prior to facilitate disentangled learning dynamics in each level. This work introduces a new approach to unsupervised models, which uses a resolution-based hierarchy framework and the inference framework. The paper presents a method to decouple level-wise training objectives which significantly accelerates the training process.",A method to learn hierarchical latent variables with a requisite but general prior to disentangled learning. This study presents a method for unsupervised modeling models of high-dimensional observed variables and shows that it is possible to achieve decoupled training of complicated generative models. This work introduces a new approach to the disentanglement of hierarchy models by using a resolution hierarchial framework.
"Inspired by prior work on Sliced-Wasserstein Autoencoders (SWAE) and kernel smoothing we construct a new generative model É?? Cramer-Wold AutoEncoder (CWAE). This work proposes a WAE variant based on a new statistical distance between the encoded data distribution and the latent prior distribution Introduces a variation on the Wasserstein AudoEncoders which is a novel regularized auto-encoder architecture that proposes a specific choice of the divergence penalty This work proposes the Cramer-Wold autoencoder, which uses the Cramer-Wold distance between two distributions based on the Cramer-Wold Theorem.","Cramer-Wold distance from standard multivariate normal density is a generalization of AutoEncoder based generative models. This work presents a method for computing the distance between two distributions from the standard normal density in the latent space. The authors provide a method to compute the distance of a sample from the normal density of a Gaussian prior, and show that it is faster than other autoencoders.","Cramer-Wold distance from standard multivariate normal density is a generalization of AutoEncoder based generative models. This article proposes a new method for computing the distance between two distributions in a latent space, using the Cramer Wold distance theorem. The authors propose a new metric to compute the distance of a sample from the standard normal density. A new metric for generating samples from both distributions that can be used to generate autoencoders with high accuracy.","This article introduces a method for estimating the distance between two distributions and the distance of a sample from the standard normal density. The paper presents a novel method to compute distance between different distributions by using a close analytic formula, which can be used to approximate the divergence measure in WAE-MMD. This work explores the problem of decomposition on a distribution with a closed-form obtained from a characteristic kernel",A method for estimating distance between two distributions to one dimensional calculation. This work introduces a method for measuring distance between samples and the distance of a sample from the standard normal density. The authors investigate the problem of divergence measurement in the absence of an analytic formula that would enable the computation of the distance between different distributions by using the Cramer-Wold Theorem BID3 and Radon Transform BID4.
"Learn to rank learning curves in order to stop unpromising training jobs early. Novelty: use of pairwise ranking loss to directly model the probability of improving and transfer learning across data sets to reduce required training data. The article proposes a method to rank learning curves of neural networks that can model learning curves across different datasets, achieving higher speed-ups on image classification tasks.","A method to compare the learning curve of a new configuration to the one of the currently best configuration. This article presents a method for comparing the learning curves of different configurations of a neural architecture using meta-knowledge. The authors present a method to evaluate the likelihood of improvement of a model based on its final learning curve. This paper presents a new method for evaluating the performance of neural architectures, which is based on a combination of partial and partial learning curves",A method to evaluate the likelihood of improvement of a model by comparing the learning curve of a new configuration to the one of the currently best configuration. This article presents a method for evaluating the probability of improvement in neural architecture search using a meta-knowledge ranking algorithm. The paper proposes a method to compare the learning curves of two different models to determine whether the current model outperforms the previous model.,A method to determine the likelihood of no improvement is to compare the learning curve of a new configuration to the one of the currently best configurations. This article introduces a meta-knowledge method that models the probability that the model currently being investigated surpasses the best solution so far.,"A method to determine the likelihood of no improvement is to compare the learning curve of a new configuration to the one of the currently best configurations. This work introduces a ranking model that models the probability that the current best solution surpasses the best solution so far. The authors use meta-knowledge to explicitly denote the entire learning curve, y 1 and y max."
"Empirically shows that larger models train in fewer training steps, because all factors in weight space traversal improve. This work shows that wider RNNs improve convergence speed when applied to NLP problems, and by extension the effect of increasing the widths in deep neural networks on the convergence of optimization This paper characterizes the impact of over-parametrization in the number of iterations it takes an algorithm to converge, and presents further empirical observations on the effects of over-parametrization in neural network training.","Convergence rate is a function of direct distance from initialization point to final point, and the improvement comes from each factor: The distance from initialized weights to converged weights shrinks with a power-law-like relationship, and gradient vectors become more aligned with each other during traversal.","Convergence curve is a linear relationship between the number of steps to convergence and the distance from initialization point to final point. This study studies the effect of training set size on convergence rate in LMs, showing that it has an inverse relationship to gradient updates. The authors propose a new learning curve for LMs where the average step size grows with a power-law-like relationship, and gradient vectors become more aligned with each other during traversal.","A convergence curve characterized by direct distance from initialization point to final point, the average step size and the average angle between gradient vectors and the path that connects current weights to final wights. This study presents a convergence curve that can be characterized into a powerlaw region within which the number of gradient updates to convergence has a reciprocal relationship to model size and linear relationship to its dataset size.","A convergence curve characterized by direct distance from initialization point to final point, the average step size grows with a power-law-like relationship, and the average angle between gradient vectors becomes more aligned with each other during traversal. This study presents a convergence rate model that can be characterized into a grid region within which the number of gradient updates to convergence has a reciprocal relationship to model size and linear relationship to dataset size."
"Generalized Graph Embedding Models A generalized knowledge graph embedding approach which learns the embeddings based on three different simultaneous objectives, and performs on par or even outperforms existing state-of-the art approaches. Tackles the task of learning embeddings of multi-relational graphs using a neural network Proposes a new method, GEN, to compute embeddings of multirelationship graphs, particularly that so-called E-Cells and R-Cells can answer queries of the form (h,r,?),(?r,t), and (h,?,t)","A new embedding learning framework for modeling knowledge graphs. This article presents a new embeddings framework for representing knowledge graphs that is more representative and informative than previous approaches. The study presents a deep learning framework based on the embedding dictionary of Knowledge Graphs, which can be used to model different types of knowledge graphs in a wide range of tasks.","A deep learning framework for modeling knowledge graphs that is unsupervised. The authors propose a new embedding learning framework, DeepWalk, based on the Knowledge Graph Learning Framework (GEN). This paper proposes a deep learning approach to model knowledge graphs by using a neural network architecture with a hidden layer of information which can be used to represent different types of knowledge graphs.","A new embedding learning framework for modeling author connections on social networks that is more robust to global underfitting and local over-fitting. This work introduces a new embedded learning framework, which can be used to solve link prediction problems. The authors present a model for neural network embeddation that uses a hidden layer of the embedded dictionary in order to answer query.","The proposed embedding learning framework for modeling author connections on social networks is completely unsupervised, which is distinctly different from previous works. This study considers the problem of embeddering neural networks using a hidden layer of the embedded dictionary and shows that it outperforms when given 50% of the data in a wide variety of artificial intelligence tasks. The authors present a model with a non-supervised label, which can be used to solve link prediction problems."
"Mean Replacement is an efficient method to improve the loss after pruning and Taylor approximation based scoring functions works better with absolute values. Proposes a simple improvement to methods for unit pruning using ""mean replacement"" This work presents a mean-replacement pruning strategy and utilizes the absolute-valued Taylor expansion as the scoring function for the pruning",A new pruning method for neural networks that identifies a stable set of prunable units early in the training process. This paper presents a method for pruning neural networks with a fixed number of units at each layer. The authors present a method to prune neural networks without mean propagation and show that the pruning penalty is relatively low during the training phase.,"A new pruning method for neural networks that achieves a stable set of prunable units during the training process. This paper proposes a novel pruning strategy for neural network architectures, proposing a new scoring function to improve the pruning penalty on neural networks. The authors propose an approach to pruning neural networks by using mean replacement instead of mean replacement in order to avoid pruning too early.","A new pruning method to prune a predefined fraction of its units using the chosen criterion, and measure the pruning penalty by comparing the losses measured before and after pruning. This work introduces a new scoring function for all scoring functions and shows that the best performing scoring functions are somewhat consistent over the course of training, implying that the dead parts of the network appear during the stages of training.","A pruning method to prune a predefined fraction of its units using a chosen criterion and measure the pruning penalty. This work introduces a pruning strategy for prunable networks, where the best performing scoring functions can be used to reduce bias propagation in training. The authors present a new pruning strategy that measures the loss as a function with activations and a first order approximation of the absolute change in the loss."
"We introduce a system called GamePad to explore the application of machine learning methods to theorem proving in the Coq proof assistant. This work describes a system for applying machine learning to interactive theorem proving, focuses on tasks of tactic prediction and position evaluation, and shows that a neural model outperforms an SVM on both tasks. Proposes that machine learning techniques be used to help build proof in the theorem prover Coq.","A deep learning algorithm for theorem proving in the Coq proof assistant. This work introduces a deep learning system called GamePad that can be used to explore the application of machine learning methods to theorem proving. This article introduces a new method for proof-of-the-art theorem proving based on Coq, which combines deep learning with machine learning to solve the problem of proving a theorem in a supervised manner.",A deep learning method for proving a proof in the Coq proof assistant. This paper introduces a system called GamePad that can be used to explore the application of machine learning methods to theorem proving and proposes a new method for doing so. The paper presents a method for solving the problem of proof-of-the-art problems in Coq by using a deep learning algorithm to generate proof states from the current state.,"This article introduces a new system for theorem proving in the Coq proof assistant. The paper presents a method for the application of the coq proof script to the task of premise selection, which can be used on tasks useful for the automate prediction task. The authors present a way to learn proof state by implementing a patch to Coq that uses a Coq Ltac interpreter to log the intermediate proof states.","This paper introduces a new gamepad system for theorem proving in the Coq proof assistant. The authors present a method to learn proof states in a coq proof script, and show that it can be used to develop a pre-proved proof script. This work presents a framework for the application of machine learning to the orem provers on tasks useful for the task of premise selection which operates with little to no supervision."
"We propose a self-ensemble framework to train more robust deep learning models under noisy labeled datasets. This article proposed ""self-ensemble label filtering"" for learning with noisy labels where the label noise is instance-independent, which yield more accurate identification of inconsistent predictions. This study proposes an algorithm for learning from data with noisy labels which alternates between updating the model and removing samples that look like they have noisy labels.","Self-ensemble filtering is a principled method against learning under noisy labels. This paper introduces a semi-supervised approach to learning from noisy labels in deep neural networks by leveraging ensemble predictions of the network's output to improve the filtering process. This work introduces a new method for learning from noise-free labeled data, called Self-Ensemble Learning, which combines ensemble predictions with a self-aware filtering strategy.","Self-ensemble filtering and model ensembles is a principled method against learning under noisy labels. This paper proposes a semi-supervised approach to learning from noisy labels in DNNs by leveraging ensemble of predictions of the single network's output over different training epochs. The authors propose a new method for learning from potentially correct samples even with an extreme level of noise in the labels (e.g., 80% noise ratio) and leads to improved performance as the label sets become less noisy. This work proposes a framework for self-efficient filtering, i.e., using ensemble of prediction of the individual networks' output to improve the filtering process.","A method for self-ensemble learning under noisy labels. This work introduces a method to learn from noisy labels by using a model ensemble to improve the performance of DNNs. The authors present a framework for non-expert learning on noisy labels that uses a moving-average of model snapshots to filter out the noisy labels, and show that SELF consistently outperforms the existing methods on asymmetric and symmetric noise at all noise levels.","A method for self-ensemble filtering and semi-supervised model ensembles that learns from noisy labeled data. This work introduces a method to improve the performance on noisy labels by reducing the noise ratio of noisy labels. The authors present a new filtering framework for learning from noisy labels using a non-expert dataset and a multi-task approach to filter out noisy labels, resulting in a more robust and robust manner."
"An algorithm for training neural networks efficiently on temporally redundant data. The work describes a neural coding scheme for spike based learning in deep neural networks This paper presents a method for spike based learning that aims at reducing the needed computation during learning and testing when classifying temporal redundant data. This paper applies a predictive coding version of the Sigma-Delta encoding scheme to reduce a computational load on a deep learning network, combining the three components in a way not seen previously.","A deep neural network with spiking gradients that performs about as well as a traditional deep network trained with backpropagation. This work introduces a new neural network encoding scheme, called ""spiking"", which is used to train neural networks with a spiking gradient. The authors present a method for training a neural network using spiking and an adaptive scale of quantization to match the magnitude of the input.","A neural network encoding scheme for temporal data that is more efficient than a traditional deep neural network. This paper proposes a neural network encoder and decoder based on a spiking mechanism, and shows that it performs about as well as a standard deep network trained with backpropagation, despite only communicating discrete values between layers. The authors propose a new algorithm for decoding temporal data in the context of neural networks where the input/output term dominates, we can say that the relative cost of computing†ß? t vs z t is: DISPLAYFORM5 2.5 A Neural Network encoder-decoder scheme for predicting the magnitude of an incoming signal.","This work presents a new algorithm for adaptive layer quantization on all layers of a neural network. This article introduces a method for adaptively tuning the gradients on each layer of the neural network to match the running average of the magnitude of the data. The authors present a novel algorithm for encoding layers of neural networks that can be trained with backpropagation, despite only communicating discrete values between layers.","This work presents a method for adaptively tuning layers of neural network activations, which can be implemented on every layer of a neural network. The authors introduce a new algorithm to improve the performance of neural networks on Temporal MNIST by implementing a ""sparse"" and ""event-based"" quantization scheme. This study presents an algorithm for encoding gradient activations on each layer of the neural network"
A trick on adversarial samples so that the mis-classified labels are imperceptible in the label space to human observers A method for constructing adversarial attacks that are less detectable by humans without cost in image space by changing the target class to be similar to the original class of the image.,"Identifying a target label for adversarial samples in the label space is not at the expense of huge loss in the image space. This article introduces a new attack method that can be used to identify the target label of an adversarial sample. The study presents a method for identifying the target labels of a classifier in the feature space, and then using it to generate adversarial data.",A method for generating adversarial samples that are imperceptible to human observers. This paper proposes a novel attack method which can be used to generate adversarial data in the label space without any loss in the image space. The article proposes an attack method that is more effective than adversarial attacks by making the target label less recognizable to humans.,"An attack that makes adversarial samples less recognizable in the label space by human observers. This work introduces a method for generating adversarials to be mis-classified as the target label, and shows improvement in the attack rate is not at the expense of loss in the image space. The paper presents a new attack method that can attack a classifier with ""similar"" label to the input image's ground truth.","In the image space, adversarial samples generated by our method are less recognizable by human observers than other attacks. This work introduces a method for attacking an input image to be misclassified in the label space and shows that it is not at the expense of the loss in the attack rate or attack rate. The authors present a new attack method for generating adversarials generated by using a probability model, then move the input to the target label."
"We propose AD-VAT, where the tracker and the target object, viewed as two learnable agents, are opponents and can mutually enhance during training. This article aims to address the visual active tracking problem with a training mechanism in which the tracker and target serve as mutual opponents This study presents a simple multi-agent Deep RL task where a moving tracker tries to follow a moving target. Proposes a novel reward function - ""partial zero sum"", which only encourages the tracker-target competition when they are close and penalizes whey they are too far.","A novel Adversarial Reinforcement Learning method for the Asymmetric Dueling task, i.e., a novel Dueling mechanism for ASD-VAT. This work introduces a novel adversarial reinforcement learning method that learns to control the movement of the target in a dueling/competitive manner. The authors introduce a new adversarial learning method for ASDF-Vat, which is based on a combination of RL and RL.","Adversarial Reinforcement Learning for Asymmetric Dueling The authors propose a novel adversarial reinforcement learning method for VAT task, i.e., asymmetric dueling. This work proposes an adversarial training method for the VAT task in which both agents are trained to compete with each other on tasks that are always at the appropriate difficulty.","A novel reversarial reinforcement learning method for VAT task, i.e., the Asymmetric Dueling mechanism (AD-VAT). This article introduces a new approach to training agents using adversarial neural networks in order to predict the trackerÉ??s reward as an auxiliary task. The study presents a method for training agents that is more likely to compete with a target with the appropriate difficulty level when both agents are stronger simultaneously.","A novel re-enforcement learning method for multi-agent training. This work introduces a neural network to train agents using adversarial training in a dueling/competitive manner. The authors present a new tracker that learns to predict their reward as an auxiliary task, and show that the tracker is more likely to compete with a target with the appropriate difficulty level when both agents are stronger simultaneously."
"Human behavioral judgments are used to obtain sparse and interpretable representations of objects that generalize to other tasks This study describes a large-scale experiment on human object/sematic representations and a model of such representations. This study develops a new representation system for object representations from training on data collected from odd-one-out human judgements of images. A new approach to learn a sparse, positive, interpretable semantic space that maximizes human similarity judgements by training to specifically maximize the prediction of human similarity judgements.","A probabilistic model of the decision in a given trial based on similarity between the embedding vectors of the three concepts presented. The authors present a model for understanding the reasoning behind a decision made by a group of concepts, and show that the decision can be explained as a function of similarity between two concepts.","A probabilistic model for understanding semantic distinctions in a given context. This paper presents a probabilistically-based approach to understanding semantic differences between three concepts, and proposes a method for analyzing the similarity between the three concepts in order to determine whether the two concepts are related or not. The authors propose an approach to learning semantic distinctions between concepts by considering the similarity of each conceptÉ??s embedding vectors.","A probabilistic model for a given trial with non-negativity and sparsity penalty. This study presents a novel method for estimating the differences between concept senses by using a random initialization parameter to obtain sparse embeddings. The authors present a model for two concepts that can be used to model phenomena such as judgments of typicality or similarity between concepts, or reaction times in various semantic tasks.","Using sparse representations to model phenomena such as judgments of typicality or similarity between concepts, or reaction times in various semantic tasks. This work introduces a method for estimating vectors for each of the different concept senses (synsets) of a concept sense, and a novel way to model situations where the decision is close to being deterministic."
"We train generative adversarial networks in a progressive fashion, enabling us to generate high-resolution images with high quality. Introduces progressive growing and a simple parameter-free minibatch summary statistic feature for use in GAN training to enable synthesis of high-resolution images.","A novel GAN formulation that preserves variation in the training data distribution. This work introduces a novel method for preserving variation in GANs, which is based on the idea that the generator and discriminator can be used to generate images at high resolution. The authors present a novel GAL formulation that allows for the generation of images at low resolution, and shows that the generated images are more stable than the original model.","A novel generative model for generating images at high resolution. This work proposes a novel formulation of GANs where the generator and discriminator can be used to generate images that show variation in different directions. The authors propose a novel method for generating generative models at high resolutions, which is based on using a minibatch-based approach to generate generative data.","A GAN formulation that does not explicitly require the entire training data distribution to be represented by the resulting generative model. This article introduces a method for measuring the degree of preserved variation in GANs, which can be used to measure the distance between the training distribution and the generated distribution. The authors present a GAN formula that uses weight initialization instead of a trivial N (0, 1) initialization and then explicitly scale the weights at runtime.","A GAN formulation that does not explicitly require the entire training data distribution to be represented by the result of the resulting generative model. This work introduces a GAN formula that can be used to measure the distance between the training distribution and the generated distribution, and provides a better quality version of the CELEBA dataset. The authors address the problem of mode collapse in GANs, and show that it is possible to do so over a dozen minibatches."
"A fast second-order solver for deep learning that works on ImageNet-scale problems with no hyper-parameter tuning Choosing direction by using a single step of gradient descent ""towards Newton step"" from an original estimate, and then taking this direction instead of original gradient A new approximate second-order optimization method with low computational cost that replaces the computation of the Hessian matrix with a single gradient step and a warm start strategy.","A Hessian-free method for non-convex deep neural network optimisation. The authors introduce a Hessian matrix for the first-order optimization of deep neural networks, and show that it can outperform first order methods on large datasets. This work introduces a hybrid gradient descent method for deep neural nets, which achieves high convergence rates on multi-parameter optimization.","A Hessian-free method for deep neural optimisation that avoids the inner CG loop. This paper proposes a hybrid SGD algorithm with a Hessian matrix and a stochastic gradient descent step. The authors propose a hybrid approach to deep network optimisation, based on the Hessian decomposition of the first order solvers in order to reduce the number of iterations.","A method for non-convex deep network optimisation, which is useful against first order solvers. This article introduces a new Hessian-free method that can be used to improve second-order neural networks without the inner CG loop. The authors present a method for multi-task deep neural networks with no hyper-parameter tuning and show strong results on several large-scale problems.","A new method for non-convex deep network optimisation, which can be used to improve second-order optimisation. This work introduces a new algorithm that uses the Hessian loop to solve non-consequence deep neural networks with no hyper-parameter tuning. The authors present a method for multi-task deep learning, using a surrogate matrix and a recursive gradient descent step in order to avoid saddle-points"
Models of source code that combine global and structural features learn more powerful representations of programs. A new method to model the source code for the bug repairing task using a sandwich model like [RNN GNN RNN] which significantly improves localization and repair accuracy.,"A new family of Graph Neural Networks for code that efficiently combine longer distance information with semantic structural information. This work introduces a new family to graph-based neural networks for code, which is based on a sequence-based embedding of code into a graph representation. The study presents a new generation of graph neural networks (GGNNs) for code translation and repair tasks, which combines the message passing information of sequence models with the semantic structure of the code.","A new family of Graph Neural Networks for code that efficiently combine longer-distance information with semantic structural information. This paper proposes two new families of models for code based on a graph-based embedding of programs, and proposes to combine longer distance information between programs in order to improve the performance of GGNNs. The authors propose a new generation of program graphs for code where the message passing is carried out via a sequence-like embedding layer.","A graph-based embedding of programs to predict the most likely variable at each variable-use location and generate a repair prediction using an enumerative approach. This work introduces a graph neural network architecture that integrates message passing with the semantic structural information available to the GGNN. The paper presents two new models that efficiently combine longerdistance information, such as the sequence model can represent, with the number of message passes.","A graph-based model for code that uses message-passing to represent relations in code, which makes them de facto local due to the high cost of iteration. This work introduces a new family of models that efficiently combine longerdistance information, such as the sequence model can represent, with the semantic structural information available to the GGNN."
"A novel differentiable neural architecture search framework for mixed quantization of ConvNets. The authors introduce a new method for neural architecture search which selects the precision quantization of weights at each neural network layer, and use it in the context of network compression. The study presents a new approach in network quantization by quantizing different layers with different bit-widths and introduces a new differentiable neural architecture search framework.","A combinatorial optimization problem that solves the mixed precision quantization problem with stochastic super nets. This work introduces a new architecture search framework, which is based on the idea of stochastically decomposing neural nets into a super net. The authors introduce a new algorithm called DNAS, which can be used to find the optimal architecture for a given neural net.","Neural architecture search for mixed precision quantization This paper proposes a combinatorial optimization approach to solve the mixed precision data quantization problem by constructing a stochastic super net that minimizes the expected loss of the target network. The authors propose a method for solving the mixed-precision quantization problems in neural nets by building a super net whose macro architecture (number of layers, filter size of each layer, etc.) is the same as the target model.","This paper introduces a new framework for quantization of neural nets, which uses the DNAS framework to solve the mixed precision quantization problem. The authors study the stochastic super net as a method for quantizing macro architectures of neural networks by constructing a super net whose macro architecture (number of layers, filter size of each layer, etc.) is the same as the target network.","Using the DNAS framework to solve the mixed precision quantization problem by constructing a super net whose macro architecture (number of layers, filter size of each layer, etc.) is the same as the target network. This work introduces a new model for quantization of neural nets with a stochastic super net that represents the architecture space A. The authors present a novel method for quantizing the loss function of a neural network"
"We propose an novel learning method for deep sound recognition named BC learning. Authors defined a new learning task that requires a DNN to predict mixing ratio between sounds from two different classes to increase discriminitive power of the final learned network. Proposes a method to improve the performance of a generic learning method by generating ""in between class"" training samples and presents the basic intuition and necessity of the proposed technique.","BC learning is a simple and powerful method that improves various sound recognition methods and elicits the true value of large-scale networks. This study studies the effect of BC learning on sound recognition in a wide range of settings, and shows that BC learning improves the performance of many sound recognition models.","BC learning improves the performance on various sound recognition networks, datasets, and data augmentation schemes. The authors propose a new method for improving sound recognition using BC learning. This paper proposes to use BC learning to enhance the feature distribution of sound recognition models by increasing the number of training epochs in the feature space.","A model that learns to mix the mixed sounds of dog bark and rain with a certain ratio is proportional to the original feature distribution of class A and B. This work studies the performance of sound recognition networks on datasets and data augmentation schemes in which BC learning proves to be always beneficial. The study presents a method for improving the performance on various sound recognition network, datasets, and data-augmentation schemes.","A new model for sound recognition and data augmentation in the feature space, and a regularization of the positional relationship between the feature distributions of the classes. This work introduces a new model to learn mixed sounds of dog bark and rain when the mixing ratio is within the range of 0.45 -0.8. The study presents a novel model for learning mixed sounds from two different parts of the features of the class."
"Motivated by theories of language and communication, we introduce community-based autoencoders, in which multiple encoders and decoders collectively learn structured and reusable representations. The authors tackle the problem of representation learning, aim to build reusable and structured represenation, argue co-adaptation between encoder and decoder in traditional AE yields poor representation, and introduce community based auto-encoders. The article presents a community based autoencoder framework to address co-adaptation of encoders and decoders and aims at constructing better representations.","A new framework for representation learning that is easier to learn than traditional autoencoders and decoders. This work introduces a new approach to the representation learning problem in which the encoder and decoder are trained to encode information in a systematic way. The authors introduce a new framework of autoencoder-encoder-decoder training, where each encoder is randomly sampled to learn a representation of the input.","A simple representation learning framework for community-based autoencoders and decoders. This paper proposes a new approach to the representation learning problem, proposing a method to train autoencoder and decoder in a systematic way. The authors propose an approach to representation learning that is based on co-adaptation between two encoders and a decoder to encode information in the representation. This work proposes a method for improving the accuracy of autoencilers by using community-encoded representations as a model.",A framework for autoencoders that can be used to train a community-based encoder and decoder. This article introduces a framework for learning representations that are more easily extracted and re-used for supervised learning and reinforcement learning. The authors study the problem of co-adaptation between a pair of encoders and a non-decoder classifier,"A framework for learning representations that are more easily extracted and re-used for a different task, such as supervised learning or reinforcement learning. This work introduces a framework for autoencoders (CbAEs), in which the encoder and decoder can learn to reconstruct information from the input. The authors study the problem of co-adaptation between a pair of encoders and a latent vector model."
"This study presents a new deep learning architecture for addressing the problem of supervised learning with sparse and irregularly sampled multivariate time series. Proposes a framework for making predictions on sparse, irregularly sampled time-series data using an interpolation module that models the missing values in using smooth interpolation, non-smooth interpolation, and intensity. Solves the problem of supervised learning with sparse and irregularly sampled multivariate time series using a semi-parametric interpolation network followed by a prediction network.","A novel interpolation network for multivariate time series that captures the global structure of time series. This work introduces a new deep learning framework for multi-time series interpolation, which is able to capture information about time series in a multi-timescale manner. The authors introduce a new interpolation method for multivariable time series, which uses a deep learning model to capture data from multiple dimensions of a multivariate dataset.","A novel interpolation network for multivariate time series. This paper proposes a deep learning framework that captures the global structure of time series during the interpolation stage. The authors propose an interpolation method to capture information about time series in a multivariate way, which is more suitable for classification and regression tasks. This work proposes a new model for multi-timescale time series that uses forward or linear interpolation to capture data from multiple dimensions of the input data.","A deep learning model for multivariate time series that can be shared across multiple dimensions during the interpolation stage, while any standard deep-learning model can be used for the prediction network. This work introduces a deep learning architecture for multi-time series prediction which uses a semi-parametric intensity function representation to isolate information about short duration events from broader trends.","A deep learning model for multivariate time series that can be used to isolate information about short duration events from broader trends. This work presents an interpolation network architecture that explicitly leverages a separate information channel related to patterns of medical event point processes. The authors present a deep learning framework for multi-time series prediction and class classification tasks with sparse and irregularly sampled time series, and a new representation of the input time series."
"We propose 3D shape programs, a structured, compositional shape representation. Our model learns to infer and execute shape programs to explain 3D shapes. An approach to infer shape programs given 3D models, with architecture consisting of a recurrent network that encodes a 3D shape and outputs instructions, and a second module that renders the program to 3D. This study introduces a high-level semantic description for 3D shapes, given by the ShapeProgram.","An end-to-end neural program synthesizer for 3D image reconstruction. This work introduces a domain-specific language for image reconstruction, which combines a neural program synthesis and a neural executor. The work presents a domain specific language for 3d image reconstruction that combines a deep learning framework with a neural network to generate programs from raw images.","An end-to-end neural program synthesizer for 3D image reconstruction. This paper introduces a domain-specific language for image to image reconstructions, which can be used to generate programs from raw images. The article proposes a domain specific language for the reconstruction of 3D objects by using an LSTM and a neural program executor to execute programs.","A purely end-to-end neural network synthesizer for 3D graphics. This article introduces a novel way to infer 3D shapes from raw, unannotated shapes, and shows how it can be used to reconstruct parts of objects. The authors present a method for modeling 3D images using a domain-specific language, which uses a specific language to learn more about the structure of objects and their properties.","A purely end-to-end neural network synthesizer for 3D graphics. This work introduces a new way of learning to infer 3D shapes from raw, unannotated shapes, and then execute them directly from an RGB image. The authors present a method for modeling 3D images using a domain-specific language, which can be used to reconstruct parts of a table top and a square layer that is more accurate and physically plausible."
"We define a flexible DSL for RNN architecture generation that allows RNNs of varying size and complexity and propose a ranking function that represents RNNs as recursive neural networks, simulating their performance to decide on the most promising architectures. Introduces a new method to generate RNNs architectures using a domain-specific language for two types of generators (random and RL-based) together with a ranking function and evaluator. This work casts the search of good RNN Cell architectures as a black-box optimization problem where examples are represented as an operator tree and scored based on learnt functions or generated by a RL agent. This work investigates meta-learning strategy for automated architecture search in the context of RNN by using a DSL that specifies RNN recurrent operations.","A deep reinforcement learning architecture search framework based on the OpenNMT framework. This article presents a deep learning framework for RNNs with an extension DSL to the LSTM encoder and decoder. The authors present a deep RL framework for learning deep neural networks using open-end DSLs, which is designed to be used to train deep RL architectures.","A deep learning framework for RNNs that can be used to train a wide variety of architectures. This article proposes a deep learning architecture based on OpenNMT, which uses an open-source LSTM encoder and extend DSL. The authors propose a new approach to training deep learning architectures by adding a hidden and extended DSL to the computation graph. A deep learning algorithm for building deep learning RNN architectures using open-world LSTMs","This article introduces a new algorithm for RNN architectures that uses a hidden state h t and an extension of the DSL to code. This study presents a novel method for generating RNNs by using a LSTM-encoder-decoder, which can be used to generate a dataset of candidate architectures. The authors present a technique for constructing RNN with a unique vector representation in the output node","This study introduces a novel RNN architecture that uses a hidden state h t and an extension of the DSL to code by traversing the tree from the source nodes towards the final node. The authors present a new architecture definition for RNNs, which can be used to estimate the next batch of candidate architectures using a search-based optimization algorithm."
"Deep and narrow neural networks will converge to erroneous mean or median states of the target function depending on the loss with high probability. This paper studies failure modes of deep and narrow networks, focusing on as small as possible models for which the undesired behavior occurs. This paper shows that the training of deep ReLU neural networks will converge to a constant classifier with high probability over random initialization if hidden layer widths are too small.",An approximate non-linear activation function for neural networks that can be approximated by a small 3-layer feed-forward NN. This article presents a method for approximating the nonlinear activation functions of neural networks in terms of the width of the input and output of the neural network. The authors show that a simple nonlinear activator function can be approximate by a 2-layer neural network with widths larger than the input dimension.,"NNs can be approximated by a small 3-layer feed-forward NN, but not by any 2-layer network with the same accuracy irrespective of the activation function. The authors show that ReLU (ReLU) is an approximate neural network that has no difference in the width between the input and output dimensions. This paper proposes a method for learning ReLU based on nonlinear activation functions and shows that it is possible to learn ReLU from ReLU.","A simple approximately radial activation function can be approximated by a small 3-layer feed-forward NN, but it cannot be approximated by any 2-layer network with the same accuracy irrespective of the activation functions. This work presents a novel approxiation theory of a class of (possibly discontinuous) piecewise C  functions for ReLU NNs, showing that no more than O( 2(d","A simple approximately radial activation function can be approximated by a small 3-layer feed-forward NN, but it is impossible to approximate by any 2-layer network with the same accuracy, unless its width is exponential in the dimension. The authors study approximation theory of a class of (possibly discontinuous) piecewise C  functions for ReLU NNs and show that no more than O( 2(d1)/"
