{
  "_from_model_config": true,
  "begin_suppress_tokens": [
    170
  ],
  "bos_token_id": 0,
  "decoder_start_token_id": 2,
  "diversity_penalty": 0.7,
  "early_stopping": true,
  "eos_token_id": 2,
  "forced_bos_token_id": 0,
  "forced_eos_token_id": 2,
  "length_penalty": 2.0,
  "max_length": 150,
  "min_length": 60,
  "no_repeat_ngram_size": 3,
  "num_beam_groups": 4,
  "num_beams": 4,
  "pad_token_id": 1,
  "repetition_penalty": 1.3,
  "suppress_tokens": [
    1698,
    32687
  ],
  "transformers_version": "4.35.2"
}
