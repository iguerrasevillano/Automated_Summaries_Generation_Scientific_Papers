{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iguerrasevillano/TFM/blob/main/Extractive_summaries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEZEiEhlnp8j"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DCyyzSCaF2VU",
        "outputId": "9b17b4ff-c394-498e-aebd-38ca7b2d0b64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow)\n",
            "  Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.16,>=2.15.0 (from tensorflow)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow)\n",
            "  Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.4)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, keras, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 0.4.6\n",
            "    Uninstalling google-auth-oauthlib-0.4.6:\n",
            "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.0\n",
            "    Uninstalling tensorboard-2.12.0:\n",
            "      Successfully uninstalled tensorboard-2.12.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "Successfully installed google-auth-oauthlib-1.2.0 keras-2.15.0 tensorboard-2.15.1 tensorflow-2.15.0.post1 tensorflow-estimator-2.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "x7-Ua4kJJ-I_",
        "outputId": "dd7ecb94-bfd7-4571-d612-e959dda34b06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Keras\n",
        "import tensorflow as tf\n",
        "\n",
        "# NLTK\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.cluster.util import cosine_distance\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Graph\n",
        "import networkx as nx\n",
        "import re\n",
        "\n",
        "# Time\n",
        "import time\n",
        "\n",
        "# AST\n",
        "import ast\n",
        "\n",
        "# Current directory\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvW3zjlq_ukX",
        "outputId": "93ee8495-87ff-4cc1-e39f-e2520af24f4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZxAvwv5nyhE"
      },
      "source": [
        "### Load and clean raw data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlyJWKdLJ_JN",
        "outputId": "56c565e5-b37b-408a-9add-bd8739765872"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# Connect w/ Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gr_wV5WgL3ao"
      },
      "outputs": [],
      "source": [
        "BASE_PATH = \"/content/drive/MyDrive/VIU/TFM/Desarrollo/Data/\"\n",
        "\n",
        "documents = os.listdir(BASE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rOo2flUzaIGG"
      },
      "outputs": [],
      "source": [
        "# AUXILIAR FUNCTIONS\n",
        "\n",
        "def load_data(data):\n",
        "\n",
        "  jsonl_file_path = BASE_PATH + 'TLDR/' + data + '.jsonl'\n",
        "\n",
        "  # Read the JSON Lines file into a list of dictionaries\n",
        "  data_list = []\n",
        "  with open(jsonl_file_path, 'r') as jsonl_file:\n",
        "      for line in jsonl_file:\n",
        "          data_dict = json.loads(line)\n",
        "          data_list.append(data_dict)\n",
        "\n",
        "  return data_list\n",
        "\n",
        "\n",
        "\n",
        "# Join all the sentences of target\n",
        "def join_words(df, column):\n",
        "  df[column] = df[column].apply(lambda x : ' '.join(x))\n",
        "  return df\n",
        "\n",
        "\n",
        "# Count number of words of target\n",
        "def count_words(df, column):\n",
        "  return df[column].apply(lambda x : len(x.split()))\n",
        "\n",
        "\n",
        "\n",
        "def similarity(sentence1, sentence2, stopwords=None):\n",
        "  if stopwords is None:\n",
        "    stopwords = []\n",
        "  sentence1 = [w.lower() for w in sentence1]\n",
        "  sentence2 = [w.lower() for w in sentence2]\n",
        "\n",
        "  all_words = list(set(sentence1 + sentence2))\n",
        "\n",
        "  vector1 = [0] * len(all_words)\n",
        "  vector2 = [0] * len(all_words)\n",
        "\n",
        "  #build the vector for the first sentence\n",
        "  for word in sentence1:\n",
        "    if not word in stopwords:\n",
        "      vector1[all_words.index(word)]+=1\n",
        "\n",
        "  #build the vector for the second sentence\n",
        "  for word in sentence2:\n",
        "    if not word in stopwords:\n",
        "      vector2[all_words.index(word)]+=1\n",
        "\n",
        "  norm_vector1 = np.sqrt(np.dot(vector1, vector1))\n",
        "  norm_vector2 = np.sqrt(np.dot(vector2, vector2))\n",
        "\n",
        "  if norm_vector1 == 0 or norm_vector2 == 0:\n",
        "    return 0\n",
        "\n",
        "  return 1-cosine_distance(vector1, vector2)\n",
        "\n",
        "\n",
        "\n",
        "def similarity_matrix(sentences, stop_words):\n",
        "  similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
        "\n",
        "  for idx1 in range(len(sentences)):\n",
        "    for idx2 in range(len(sentences)):\n",
        "      if idx1 != idx2:\n",
        "        similarity_matrix[idx1][idx2] = similarity(sentences[idx1], sentences[idx2], stop_words)\n",
        "\n",
        "  return similarity_matrix\n",
        "\n",
        "\n",
        "\n",
        "def generate_extractive_summary(sentences, top_n, stop_words):\n",
        "\n",
        "  summarize_text = []\n",
        "\n",
        "  # Step1: generate similarity matrix\n",
        "  sentence_similarity_matrix = similarity_matrix(sentences, stop_words)\n",
        "\n",
        "  # Step2: Rank sentences in similarity matrix\n",
        "  sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_matrix)\n",
        "  scores = nx.pagerank(sentence_similarity_graph)\n",
        "\n",
        "  # Step3: sort the rank and place top sentences\n",
        "  ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
        "\n",
        "  # Step4: get the top n number of sentences based on rank\n",
        "  for i in range(top_n):\n",
        "    if len(ranked_sentences) > i:\n",
        "      summarize_text.append(ranked_sentences[i][1])\n",
        "    else:\n",
        "      break\n",
        "\n",
        "  # Step5: reorder the sentences as in the original text\n",
        "  real_indexes = []\n",
        "  for sentence in summarize_text:\n",
        "    if sentence in sentences:\n",
        "      real_indexes.append(sentences.index(sentence))\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "  sorted_real_indexes = sorted(real_indexes)\n",
        "\n",
        "  ordered_summarized_text = []\n",
        "  for i in sorted_real_indexes:\n",
        "    ordered_summarized_text.append(sentences[i])\n",
        "\n",
        "  # Step6 : output the summarized version\n",
        "  return ' '.join(ordered_summarized_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "1I5H39lnQW9o",
        "outputId": "f1e53705-6ecb-43f9-af0f-9dd1041db76e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                              source  \\\n",
              "0  [Due to the success of deep learning to solvin...   \n",
              "1  [The backpropagation (BP) algorithm is often t...   \n",
              "2  [We introduce the 2-simplicial Transformer, an...   \n",
              "3  [We present Tensor-Train RNN (TT-RNN), a novel...   \n",
              "4  [Recent efforts on combining deep models with ...   \n",
              "\n",
              "                                       source_labels  \\\n",
              "0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                                        rouge_scores    paper_id  \\\n",
              "0  [0.3018867874688502, 0.37209301838831804, 0.60...   SysEexbRb   \n",
              "1  [0.0, 0.0, 0.13043477920604923, 0.142857139229...  SygvZ209F7   \n",
              "2  [0.33333332839506175, 0.8888888839111112, 0.11...  rkecJ6VFvr   \n",
              "3  [0.06666666222222252, 0.06451612466181092, 0.0...   HJJ0w--0W   \n",
              "4  [0.2777777727932099, 0.5714285666581633, 0.095...   HyH9lbZAW   \n",
              "\n",
              "                                              target title  \n",
              "0  [We provide necessary and sufficient analytica...   NaN  \n",
              "1  [Biologically plausible learning algorithms, p...   NaN  \n",
              "2  [We introduce the 2-simplicial Transformer and...   NaN  \n",
              "3  [Accurate forecasting over very long time hori...   NaN  \n",
              "4  [We propose a variational message-passing algo...   NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-863837a7-2509-4209-a818-334a05160261\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>source_labels</th>\n",
              "      <th>rouge_scores</th>\n",
              "      <th>paper_id</th>\n",
              "      <th>target</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Due to the success of deep learning to solvin...</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.3018867874688502, 0.37209301838831804, 0.60...</td>\n",
              "      <td>SysEexbRb</td>\n",
              "      <td>[We provide necessary and sufficient analytica...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[The backpropagation (BP) algorithm is often t...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.13043477920604923, 0.142857139229...</td>\n",
              "      <td>SygvZ209F7</td>\n",
              "      <td>[Biologically plausible learning algorithms, p...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[We introduce the 2-simplicial Transformer, an...</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.33333332839506175, 0.8888888839111112, 0.11...</td>\n",
              "      <td>rkecJ6VFvr</td>\n",
              "      <td>[We introduce the 2-simplicial Transformer and...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[We present Tensor-Train RNN (TT-RNN), a novel...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.06666666222222252, 0.06451612466181092, 0.0...</td>\n",
              "      <td>HJJ0w--0W</td>\n",
              "      <td>[Accurate forecasting over very long time hori...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Recent efforts on combining deep models with ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.2777777727932099, 0.5714285666581633, 0.095...</td>\n",
              "      <td>HyH9lbZAW</td>\n",
              "      <td>[We propose a variational message-passing algo...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-863837a7-2509-4209-a818-334a05160261')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-863837a7-2509-4209-a818-334a05160261 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-863837a7-2509-4209-a818-334a05160261');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d9ce3dd5-cfe1-4352-93ec-13371995cfbe\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d9ce3dd5-cfe1-4352-93ec-13371995cfbe')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d9ce3dd5-cfe1-4352-93ec-13371995cfbe button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Due to the success of deep learning to solving a variety of challenging machine learning tasks, there is a rising interest in understanding loss functions for training neural networks from a theoretical aspect.', 'Particularly, the properties of critical points and the landscape around them are of importance to determine the convergence performance of optimization algorithms.', 'In this paper, we provide a necessary and sufficient characterization of the analytical forms for the critical points (as well as global minimizers) of the square loss functions for linear neural networks.', 'We show that the analytical forms of the critical points characterize the values of the corresponding loss functions as well as the necessary and sufficient conditions to achieve global minimum.', 'Furthermore, we exploit the analytical forms of the critical points to characterize the landscape properties for the loss functions of linear neural networks and shallow ReLU networks.', 'One particular conclusion is that: While the loss function of linear networks has no spurious local minimum, the loss function of one-hidden-layer nonlinear networks with ReLU activation function does have local minimum that is not global minimum.', 'In the past decade, deep neural networks BID8 have become a popular tool that has successfully solved many challenging tasks in a variety of areas such as machine learning, artificial intelligence, computer vision, and natural language processing, etc.', 'As the understandings of deep neural networks from different aspects are mostly based on empirical studies, there is a rising need and interest to develop understandings of neural networks from theoretical aspects such as generalization error, representation power, and landscape (also referred to as geometry) properties, etc.', 'In particular, the landscape properties of loss functions (that are typically nonconex for neural networks) play a central role to determine the iteration path and convergence performance of optimization algorithms.', 'One major landscape property is the nature of critical points, which can possibly be global minima, local minima, saddle points.', 'There have been intensive efforts in the past into understanding such an issue for various neural networks.', 'For example, it has been shown that every local minimum of the loss function is also a global minimum for shallow linear networks under the autoencoder setting and invertibility assumptions BID1 and for deep linear networks BID11 ; BID14 ; Yun et al. (2017) respectively under different assumptions.', 'The conditions on the equivalence between local minimum or critical point and global minimum has also been established for various nonlinear neural networks Yu & Chen (1995) ; BID9 ; BID15 ; BID17 ; BID6 under respective assumptions.', 'However, most previous studies did not provide characterization of analytical forms for critical points of loss functions for neural networks with only very few exceptions.', 'In BID1 , the authors provided an analytical form for the critical points of the square loss function of shallow linear networks under certain conditions.', 'Such an analytical form further helps to establish the landscape properties around the critical points.', 'Further in BID13 , the authors characterized certain sufficient form of critical points for the square loss function of matrix factorization problems and deep linear networks.', 'The focus of this paper is on characterizing the sufficient and necessary forms of critical points for broader scenarios, i.e., shallow and deep linear networks with no assumptions on data matrices and network dimensions, and shallow ReLU networks over certain parameter space.', 'In particular, such analytical forms of critical points capture the corresponding loss function values and the necessary and sufficient conditions to achieve global minimum.', 'This further enables us to establish new landscape properties around these critical points for the loss function of these networks under general settings, and provides alternative (yet simpler and more intuitive) proofs for existing understanding of the landscape properties.', 'OUR CONTRIBUTION 1) For the square loss function of linear networks with one hidden layer, we provide a full (necessary and sufficient) characterization of the analytical forms for its critical points and global minimizers.', 'These results generalize the characterization in BID1 to arbitrary network parameter dimensions and any data matrices.', 'Such a generalization further enables us to establish the landscape property, i.e., every local minimum is also a global minimum and all other critical points are saddle points, under no assumptions on parameter dimensions and data matrices.', 'From a technical standpoint, we exploit the analytical forms of critical points to provide a new proof for characterizing the landscape around the critical points under full relaxation of assumptions, where the corresponding approaches in BID1 are not applicable.', 'As a special case of linear networks, the matrix factorization problem satisfies all these landscape properties.2) For the square loss function of deep linear networks, we establish a full (necessary and sufficient) characterization of the analytical forms for its critical points and global minimizers.', 'Such characterizations are new and have not been established in the existing art.', 'Furthermore, such analytical form divides the set of non-global-minimum critical points into different categories.', 'We identify the directions along which the loss function value decreases for two categories of the critical points, for which our result directly implies the equivalence between the local minimum and the global minimum.', 'For these cases, our proof generalizes the result in BID11 under no assumptions on the network parameter dimensions and data matrices.3) For the square loss function of one-hidden-layer nonlinear neural networks with ReLU activation function, we provide a full characterization of both the existence and the analytical forms of the critical points in certain types of regions in the parameter space.', 'Particularly, in the case where there is one hidden unit, our results fully characterize the existence and the analytical forms of the critical points in the entire parameter space.', 'Such characterization were not provided in previous work on nonlinear neural networks.', 'Moreover, we apply our results to a concrete example to demonstrate that both local minimum that is not a global minimum and local maximum do exist in such a case.', 'Analytical forms of critical points: Characterizing the analytical form of critical points for loss functions of neural networks dates back to BID1 , where the authors provided an analytical form of the critical points for the square loss function of linear networks with one hidden layer.', 'In BID13 , the authors provided a sufficient condition of critical points of a generic function, i.e., the fixed point of invariant groups.', 'They then characterized certain sufficient forms of critical points for the square loss function of matrix factorization problems and deep linear networks, whereas our results provide sufficient and necessary forms of critical points for deep linear networks via a different approach.', 'Properties of critical points: BID1 ; BID0 studied the linear autoencoder with one hidden layer and showed the equivalence between the local minimum and the global minimum.', 'Moreover, BID2 generalized these results to the complex-valued autoencoder setting.', 'The deep linear networks were studied by some recent work BID11 ; BID14 Yun et al. (2018) , in which the equivalence between the local minimum and the global minimum was established respectively under different assumptions.', 'Particularly, Yun et al. (2017) established a necessary and sufficient condition for a critical point of the deep linear network to be a global minimum.', 'A similar result was established in BID7 for deep linear networks under the setting that the widths of intermediate layers are larger than those of the input and output layers.', 'The effect of regularization on the critical points for a two-layer linear network was studied in Taghvaei et al. (2017) .For nonlinear neural networks, Yu & Chen (1995) studied a nonlinear neural network with one hidden layer and sigmoid activation function, and showed that every local minimum is also a global minimum provided that the number of input units equals the number of data samples.', 'BID9 considered a class of multi-layer nonlinear networks with a pyramidal structure, and showed that all critical points of full column rank achieve the zero loss when the sample size is less than the input dimension.', 'These results were further generalized to a larger class of nonlinear networks in BID15 , in which they also showed that critical points with non-degenerate Hessian are global minimum.', 'BID3 b) connected the loss surface of deep nonlinear networks with the Hamiltonian of the spin-glass model under certain assumptions and characterized the distribution of the local minimum.', 'BID11 further eliminated some of the assumptions in BID3 , and established the equivalence between the local minimum and the global minimum by reducing the loss function of the deep nonlinear network to that of the deep linear network.', 'BID17 showed that a two-layer nonlinear network has no bad differentiable local minimum.', 'BID6 studied a one-hidden-layer nonlinear neural network with the parameters restricted in a set of directions of lines, and showed that most local minima are global minima.', 'Tian (2017) considered a two-layer ReLU network with Gaussian input data, and showed that critical points in certain region are non-isolated and characterized the critical-point-free regions.', 'Geometric curvature BID10 established the gradient dominance condition of deep linear residual networks, and Zhou & Liang (2017) further established the gradient dominance condition and regularity condition around the global minimizers for deep linear, deep linear residual and shallow nonlinear networks.', 'BID12 studied the property of the Hessian matrix for deep linear residual networks.', 'The local strong convexity property was established in BID16 for overparameterized nonlinear networks with one hidden layer and quadratic activation functions, and was established in Zhong et al. (2017) for a class of nonlinear networks with one hidden layer and Gaussian input data.', 'Zhong et al. (2017) further established the local linear convergence of gradient descent method with tensor initialization.', 'BID18 studied a one-hidden-layer nonlinear network with a single output, and showed that the volume of sub-optimal differentiable local minima is exponentially vanishing in comparison with the volume of global minima.', 'BID5 investigated the saddle points in deep neural networks using the results from statistical physics and random matrix theory.', 'Notation: The pseudoinverse, column space and null space of a matrix M are denoted by M † , col(M ) and ker(M ), respectively.', 'For any index sets I, J ⊂ N, M I,J denotes the submatrix of M formed by the entries with the row indices in I and the column indices in J. For positive integers i ≤ j, we define i : j = {i, i + 1, . . . , j − 1, j}. The projection operator onto a linear subspace V is denoted by P V .', 'In this section, we study linear neural networks with one hidden layer.', 'Suppose we have an input data matrix X ∈ R d0×m and a corresponding output data matrix Y ∈ R d2×m , where there are in total m data samples.', 'We are interested in learning a model that maps from X to Y via a linear network with one hidden layer.', 'Specifically, we denote the weight parameters between the output layer and the hidden layer of the network as A 2 ∈ R d2×d1 , and denote the weight parameters between the hidden layer and the input layer of the network as A 1 ∈ R d1×d0 .', 'We are interested in the square loss function of this linear network, which is given by DISPLAYFORM0 Note that in a special case where X = I, L reduces to a loss function for the matrix factorization problem, to which all our results apply.', 'The loss function L has been studied in BID1 under the assumptions that d 2 = d 0 ≥ d 1 and the matrices XX , Y X (XX ) −1 XY are invertible.', 'In our study, no assumption is made on either the parameter dimensions or the invertibility of the data matrices.', 'Such full generalization of the results in BID1 turns out to be critical for our study of nonlinear shallow neural networks in Section 4.We further define Σ := Y X † XY and denote its full singular value decomposition as U ΛU .', 'Suppose that Σ has r distinct positive singular values σ 1 > · · · > σ r > 0 with multiplicities m 1 , . . .', ', m r , respectively, and hasm zero singular values.', 'Recall that DISPLAYFORM1 Our first result provides a full characterization of all critical points of L. Theorem 1 (Characterization of critical points).', 'All critical points of L are necessarily and sufficiently characterized by a matrix L 1 ∈ R d1×d0 , a block matrix V ∈ R d2×d1 and an invertible matrix C ∈ R d1×d1 via DISPLAYFORM2 (2) DISPLAYFORM3 , where both V i ∈ R mi×pi and V ∈ Rm ×p consist of orthonormal columns with the number of columns DISPLAYFORM4 Theorem 1 characterizes the necessary and sufficient forms for all critical points of L. Intuitively, the matrix C captures the invariance of the product A 2 A 1 under an invertible transform, and L 1 captures the degree of freedom of the solution set for linear systems.', 'In general, the set of critical points is uncountable and cannot be fully listed out.', 'However, the analytical forms in eqs. (1) and (2) do allow one to construct some critical points of L by specifying choices of L 1 , V , C that fulfill the condition in eq. (3).', 'For example, choosing L 1 = 0 guarantees eq. (3), in which case eqs. (1) and (2) yield a critical point (C −1 V U Y X † , U V C) for any invertible matrix C and any block matrix V that takes the form specified in Theorem 1.', 'For nonzero L 1 , one can fix a proper V and solve the linear equation on C in eq. (3).', 'If a solution exists, we then obtain the form of a corresponding critical point.', 'We further note that the analytical structures of the critical points are more important, which have direct implications on the global optimality conditions and landscape properties as we show in the remaining part of the section.', 'Remark 1.', 'We note that the block pattern parameters {p i } r i=1 andp denote the number of columns of {V i } r i=1 and V , respectively, and their sum equals the rank of A 2 , i.e., DISPLAYFORM5 The parameters p i , i = 1, . . .', ', r,p of V contain all useful information of the critical points that determine the function value of L as presented in the following proposition.', 'DISPLAYFORM6 Proposition 1 evaluates the function value L at a critical point using the parameters {p i } r i=1 .', 'To explain further, recall that the data matrix Σ has each singular value σ i with multiplicity m i .', 'For each i, the critical point captures p i out of m i singular values σ i .', 'Hence, for a σ i with larger value (i.e., a smaller index i), it is desirable that a critical point captures a larger number p i of them.', 'In this way, the critical point captures more important principle components of the data so that the value of the loss function is further reduced as suggested by Proposition 1.', 'In summary, the parameters {p i } r i=1 characterize how well the learned model fits the data in terms of the value of the loss function.', 'Moreover, the parameters {p i } r i=1 also determine a full characterization of the global minimizers as given below.', 'Proposition 2 (Characterization of global minimizers).', 'A critical point (A 1 , A 2 ) of L is a global minimizer if and only if it falls into the following two cases.', 'DISPLAYFORM7 The analytical form of any global minimizer can be obtained from Theorem 1 with further specification to the above two cases.', 'Proposition 2 establishes the neccessary and sufficient conditions for any critical point to be a global minimizer.', 'If the data matrix Σ has a large number of nonzero singular values, i.e., the first case, one needs to exhaust the representation budget (i.e., rank) of A 2 and capture as many large singular values as the rank allows to achieve the global minimum; Otherwise, A 2 of a global minimizer can be non-full rank and still captures all nonzero singular values.', 'Note that A 2 must be full rank in the case 1, and so is A 1 if we further adopt the assumptions on the network size and data matrices in BID1 .', 'Furthermore, the parameters {p i } r i=1 naturally divide all non-global-minimum critical points (A 1 , A 2 ) of L into the following two categories.• (Non-optimal order): The matrix V specified in Theorem 1 satisfies that there exists 1 ≤ i < j ≤ r such that p i < m i and p j > 0.• (Optimal order): rank(A 2 ) < min{d 2 , d 1 } and the matrix V specified in Theorem 1 satisfies that DISPLAYFORM8 To understand the above two categories, note that a critical point of L with non-optimal order captures a smaller singular value σ j (since p j > 0) while skipping a larger singular value σ i with a lower index i < j (since p i < m i ), and hence cannot be a global minimizer.', 'On the other hand, although a critical point of L with optimal order captures the singular values in the optimal (i.e., decreasing) order, it does not fully utilize the representation budget of A 2 (because A 2 is non-full rank) to further capture nonzero singular values and reduce the function value, and hence cannot be a global minimizer either.', 'Next, we show that these two types of non-global-minimum critical points have different landscape properties around them.', 'Throughout, a matrix M is called the perturbation of M if it lies in an arbitrarily small neighborhood of M .Proposition 3 (Landscape around critical points).', 'The critical points of L have the following landscape properties.1.', 'A non-optimal-order critical point (A 1 , A 2 ) has a perturbation ( A 1 , A 2 ) with rank( A 2 ) = rank(A 2 ), which achieves a lower function value; 2.', 'An optimal-order critical point (A 1 , A 2 ) has a perturbation ( A 1 , A 2 ) with rank( A 2 ) = rank(A 2 ) + 1, which achieves a lower function value; 3.', 'Any point in X := {(A 1 , A 2 ) : A 2 A 1 X = 0} has a perturbation (A 1 , A 2 ), which achieves a higher function value;As a consequence, items 1 and 2 imply that any non-global-minimum critical point has a descent direction, and hence cannot be a local minimizer.', 'Thus, any local minimizer must be a global minimizer.', 'Item 3 implies that any point has an ascent direction whenever the output is nonzero.', 'Hence, there does not exist any local/global maximizer in X .', 'Furthermore, item 3 together with items 1 and 2 implies that any non-global-minimum critical point in X has both descent and ascent directions, and hence must be a saddle point.', 'We summarize these facts in the following theorem.', 'Theorem 2 (Landscape of L).', 'The loss function L satisfies: 1) every local minimum is also a global minimum; 2) every non-global-minimum critical point in X is a saddle point.', 'We note that the saddle points in Theorem 2 can be non-strict when the data matrices are singular.', 'As an illustrative example, consider the following loss function of a shallow linear network L(a 2 , a 1 ) = 1 2 (a 2 a 1 x − y) 2 , where a 1 , a 2 , x and y are all scalars.', 'Consider the case y = 0.', 'Then, the Hessian at the saddle point a 1 = 0, a 2 = 1 is [x 2 , 0; 0, 0], which does not have any negative eigenvalue.', 'From a technical point of view, the proof of item 1 of Proposition 3 applies that in BID0 and generalizes it to the setting where Σ can have repeated singular values and may not be invertible.', 'To further understand the perturbation scheme from a high level perspective, note that non-optimalorder critical points capture a smaller singular value σ j instead of a larger one σ i with i < j. Thus, one naturally perturbs the singular vector corresponding to σ j along the direction of the singular vector corresponding to σ i .', 'Such a perturbation scheme preserves the rank of A 2 and reduces the value of the loss function.', 'More importantly, the proof of item 2 of Proposition 3 introduces a new technique.', 'As a comparison, BID1 proves a similar result as item 2 using the strict convexity of the function, which requires the parameter dimensions to satisfy d 2 = d 0 ≥ d 1 and the data matrices to be invertible.', 'In contrast, our proof completely removes these restrictions by introducing a new perturbation direction and exploiting the analytical forms of critical points in eqs. (1) and (2) and the condition in eq. (3).', 'The accomplishment of the proof further requires careful choices of perturbation parameters as well as judicious manipulations of matrices.', 'We refer the reader to the supplemental materials for more details.', 'As a high level understanding, since optimal-order critical points capture the singular values in an optimal (i.e., decreasing) order, the previous perturbation scheme for non-optimal-order critical points does not apply.', 'Instead, we increase the rank of A 2 by one in a way that the perturbed matrix captures the next singular value beyond the ones that have already been captured so that the value of the loss function can be further reduced.', 'In this section, we study deep linear networks with ≥ 2 layers.', 'We denote the weight parameters between the layers as A k ∈ R d k ×d k−1 for k = 1, . . .', ', , respectively.', 'The input and output data are denoted by X ∈ R d0×m , Y ∈ R d ×m , respectively.', 'We are interested in the square loss function of deep linear networks, which is given by DISPLAYFORM0 , respectively, andm(k) zero singular values.', 'Our first result provides a full characterization of all critical points of L D , where we denote DISPLAYFORM1 Theorem 3 (Characterization of critical points).', 'All critical points of L D are necessarily and sufficiently characterized by matrices DISPLAYFORM2 . .', ', A can be individually expressed out recursively via the following two equations: DISPLAYFORM3 DISPLAYFORM4 Note that the forms of the individual parameters A 1 , . . .', ', A can be obtained as follows by recursively applying eqs. (4) and (5).', 'First, eq. (5) with k = 0 yields the form of A ( ,2) .', 'Then, eq. (4) with k = 0 and the form of A ( ,2) yield the form of A 1 .', 'Next, eq. (5) with k = 1 yields the form of A ( ,3) , and then, eq. (4) with k = 1 and the forms of A ( ,3) , A 1 further yield the form of A 2 .', 'Inductively, one obtains the expressions of all individual parameter matrices.', 'Furthermore, the first condition in eq. FORMULA13 is a consistency condition that guarantees that the analytical form for the entire product of parameter matrices factorizes into the forms of individual parameter matrices.', 'Similarly to shallow linear networks, while the set of critical points here is also uncountable, Theorem 3 suggests ways to obtain some critical points.', 'For example, if we set L k = 0 for all k (i.e., eq. (6) is satisfied), we can obtain the form of critical points for any invertible C k and proper V k with the structure specified in Theorem 3.', 'For nonzero L k , eq. (6) needs to be verified for given C k and V k to determine a critical point.', 'Similarly to shallow linear networks, the parameters {p i (0)} r (0) i=1 ,p(0) determine the value of the loss function at the critical points and further specify the analytical form for the global minimizers, as we present in the following two propositions.', 'DISPLAYFORM5 DISPLAYFORM6 In particular, A ( ,2) can be non-full rank with rank(A ( ,2) ) = DISPLAYFORM7 The analytical form of any global minimizer can be obtained from Theorem 3 with further specification to the above two cases.', 'In particular for case 1, if we further adopt the invertibility assumptions on data matrices as in BID1 and assume that all parameter matrices are square, then all global minima must correspond to full rank parameter matrices.', 'We next exploit the analytical forms of the critical points to further understand the landscape of the loss function L D .', 'It has been shown in BID11 that every local minimum of L D is also a global minimum, under certain conditions on the parameter dimensions and the invertibility of the data matrices.', 'Here, our characterization of the analytical forms for the critical points allow us to understand such a result from an alternative viewpoint.', 'The proofs for certain cases (that we discuss below) are simpler and more intuitive, and no assumption is made on the data matrices and dimensions of the network.', 'Similarly to shallow linear networks, we want to understand the local landscape around the critical points.', 'However, due to the effect of depth, the critical points of L D are more complicated than those of L. Among them, we identify the following subsets of the non-global-minimum critical DISPLAYFORM8 • (Deep-non-optimal order): There exist 0 ≤ k ≤ − 2 such that the matrix V k specified in Theorem 3 satisfies that there exist 1 ≤ i < j ≤ r(k) such that p i (k) < m i (k) and p j (k) > 0.• (Deep-optimal order): (A , A −1 ) is not a global minimizer of L D with A ( −2,1) being fixed, rank(A ) < min{d , d −1 }, and the matrix V −2 specified in Theorem 3 satisfies that DISPLAYFORM9 The following result summarizes the landscape of L D around the above two types of critical points.', 'The loss function L D has the following landscape properties.', 'deep-non-optimal-order critical point (A 1 , . . . , A ) has a perturbation (A 1 , . . .', ', A k+1 , . . .', ', A ) with rank( A ) = rank(A ), which achieves a lower function value.', '2.', 'A deep-optimal-order critical point (A 1 , . . . , A ) has a perturbation (A 1 , . . .', ', A −1 , A ) with rank( A ) = rank(A ) + 1, which achieves a lower function value.', '3.', 'Any point in X D := {(A 1 , . . .', ', A ) : A ( ,1) X = 0} has a perturbation (A 1 , . . .', ', A ) that achieves a higher function value.', 'Consequently, 1) every local minimum of L D is also a global minimum for the above two types of critical points; and 2) every critical point of these two types in X D is a saddle point.', 'Theorem 4 implies that the landscape of L D for deep linear networks is similar to that of L for shallow linear networks, i.e., the pattern of the parameters {p i (k)} r(k) i=1 implies different descent directions of the function value around the critical points.', 'Our approach does not handle the remaining set of non-global minimizers, i.e., there exists q ≤ −1 such that (A , . . .', ', A q ) is a global minimum point of L D with A (q−1,1) being fixed, and A ( ,q) is of optimal order.', 'It is unclear how to perturb the intermediate weight parameters using their analytical forms for deep networks , and we leave this as an open problem for the future work.', 'In this section, we study nonlinear neural networks with one hidden layer.', 'In particular, we consider nonlinear networks with ReLU activation function σ : R → R that is defined as σ(x) := max{x, 0}. Our study focuses on the set of differentiable critical points.', 'The weight parameters between the layers are denoted by A 2 ∈ R d2×d1 , A 1 ∈ R d1×d0 , respectively, and the input and output data are denoted by X ∈ R d0×m , Y ∈ R d2×m , respectively.', 'We are interested in the square loss function which is given by DISPLAYFORM0 where σ acts on A 1 X entrywise.', 'Existing studies on nonlinear networks characterized the sufficient conditions for critical points being global minimum BID9 Since the activation function σ is piecewise linear, the entire parameter space can be partitioned into disjoint cones.', 'In particular, we consider the set of cones K I×J where I ⊂ {1, . . .', ', d 1 }, J ⊂ {1, . . .', ', m} that satisfy DISPLAYFORM1 where \"≥\" and \"<\" represent entrywise comparisons.', 'Within K I×J , the term σ(A 1 X) activates only the entries σ(A 1 X) I:J , and the corresponding loss function L N is equivalent to DISPLAYFORM2 Hence, within K I×J , L N reduces to the loss of a shallow linear network with parameters ((A 2 ) :,I , (A 1 ) I,: ) and input & output data pair (X :,J , Y :,J ).', 'Note that our results on shallow linear networks in Section 2 are applicable to all parameter dimensions and data matrices.', 'Thus, Theorem 1 fully characterizes the forms of critical points of L N in K I×J .', 'Moreover, the existence of such critical points can be analytically examined by substituting their forms into eq. (8).', 'In summary, we obtain the following result, where we denote Σ J := Y :,J X † :,J X :,J Y :,J with the full singular value decomposition U J Λ J U J , and suppose that Σ J has r(J) distinct positive singular values σ 1 (J) > · · · > σ r(J) (J) with multiplicities m 1 , . . .', ', m r(J) , respectively, andm(J) zero singular values.', 'Proposition 6 (Characterization of critical points).', 'All critical points of L N in K I×J for any I ⊂ {1, . . .', ', d 1 }, J ⊂ {1, . . .', ', m} are necessarily and sufficiently characterized by an L 1 ∈ R |I|×d0 , a block matrix V ∈ R d2×|I| and an invertible matrix C ∈ R |I|×|I| such that DISPLAYFORM3 DISPLAYFORM4 ×p consist of orthonormal columns with p i ≤ m i for i = 1, . . .', ', r(J),p ≤m such that DISPLAYFORM5 Moreover, a critical point in K I×J exists if and only if there exists such C, V , L 1 that DISPLAYFORM6 Other entries of A 1 X < 0.To further illustrate, we consider a special case where the nonlinear network has one unit in the hidden layer, i.e., d 1 = 1, in which case A 1 and A 2 are row and column vectors, respectively.', 'Then, the entire parameter space can be partitioned into disjoint cones taking the form of K I×J , and I = {1} is the only nontrivial choice.', 'We obtain the following result from Proposition 6.Proposition 7 (Characterization of critical points).', 'Consider L N with d 1 = 1 and any J ⊂ {1, . . .', ', m}. Then, any nonzero critical point of L N within K {1}×J can be necessarily and sufficiently characterized by an 1 ∈ R 1×d0 , a block unit vector v ∈ R d2×1 and a scalar c ∈ R such that DISPLAYFORM7 Specifically, v is a unit vector that is supported on the entries corresponding to the same singular value of Σ J .', 'Moreover, a nonzero critical point in K {1}×J exists if and only if there exist such c, v, 1 that satisfy DISPLAYFORM8 DISPLAYFORM9 We note that Proposition 7 characterizes both the existence and the forms of critical points of L N over the entire parameter space for nonlinear networks with a single hidden unit.', 'The condition in eq. FORMULA24 is guaranteed because P ker(v) = 0 for v = 0.To further understand Proposition 7, suppose that there exists a critical point in K {1}×J with v being supported on the entries that correspond to the i-th singular value of Σ J .', 'Then, Proposition 1 implies that DISPLAYFORM10 In particular, the critical point achieves the local minimum DISPLAYFORM11 .', 'This is because in this case the critical point is full rank with an optimal order, and hence corresponds to the global minimum of the linear network in eq. (9).', 'Since the singular values of Σ J may vary with the choice of J, L N may achieve different local minima in different cones.', 'Thus, local minimum that is not global minimum can exist for L N .', 'The following proposition concludes this fact by considering a concrete example.', 'Proposition 8.', 'For one-hidden-layer nonlinear neural networks with ReLU activation function, there exists local minimum that is not global minimum, and there also exists local maximum.', 'FORMULA13 and FORMULA19 hold if c −1 (v) 1,: ≥ 0, ( 1 ) 1,: < 0.', 'Similarly to the previous case, choosing c = 1, v = (1, 0) , 1 = (−1, 0) yields a local minimum that achieves the function value L n = 2.', 'Hence, local minimum that is not global minimum does exist.', 'Moreover, in the cone K I×J with I = {1}, J = ∅, the function L N remains to be the constant 5 2 , and all points in this cone are local minimum or local maximum.', 'Thus, the landscape of the loss function of nonlinear networks is very different from that of the loss function of linear networks.', 'In this paper, we provide full characterization of the analytical forms of the critical points for the square loss function of three types of neural networks, namely, shallow linear networks, deep linear networks, and shallow ReLU nonlinear networks.', 'We show that such analytical forms of the critical points have direct implications on the values of the corresponding loss functions, achievement of global minimum, and various landscape properties around these critical points.', 'As a consequence, the loss function for linear networks has no spurious local minimum, while such point does exist for nonlinear networks with ReLU activation.', 'In the future, it is interesting to further explore nonlinear neural networks.', 'In particular, we wish to characterize the analytical form of critical points for deep nonlinear networks and over the full parameter space.', 'Such results will further facilitate the understanding of the landscape properties around these critical points.', 'Notations: For any matrix M , denote vec(M ) as the column vector formed by stacking its columns.', 'Denote the Kronecker product as \"⊗\".', 'Then, the following useful relationships hold for any dimension compatible matrices M , U , V , W : DISPLAYFORM0 DISPLAYFORM1 DISPLAYFORM2 DISPLAYFORM3 Recall that a point DISPLAYFORM4 DISPLAYFORM5 We first prove eqs. (1) and (2) .', 'DISPLAYFORM6 Next, we derive the form of A 2 .', 'Recall the full singular value decomposition Σ = U ΛU , where Λ is a diagonal matrix with distinct singular values σ 1 > . . .', '> σ r > 0 and multiplicities m 1 , . . .', ', m r , respectively.', 'We also assume that there arem number of zero singular values in Λ. Using the fact that P col(A2) = U P col(U A2) U , the last equality in eq. (26) reduces to DISPLAYFORM7 By the multiplicity pattern of the singular values in Λ, P col(U A2) must be block diagonal.', 'Specifically, we can write P col(U A2) = diag( P 1 , . . .', ', P r , P), where P i ∈ R mi×mi and P ∈ Rm ×m .Also, since P col(U A2) is a projection, P 1 , . . . , P r , P must all be projections.', 'Note that P col(U A2) has rank rank(A 2 ), and suppose that P 1 , . . .', ', P r , P have ranks p 1 , . . .', ', p r ,p, respectively.', 'Then, we must have p i ≤ m i for i = 1, . . .', ', r,p ≤m and r i=1 p i +p = rank(A 2 ).', 'Also, note that each projection can be expressed as P i = V i V i with V i ∈ R mi×pi , V ∈ Rm ×p consisting of orthonormal columns.', 'Hence, we can write P col(U A2) = V V where V = diag(V 1 , . . .', ', V r , V ).', 'We then conclude that P col(A2) = U P col(U A2) U = U V V U .', 'Thus, A 2 has the same column space as U V , and there must exist an invertible matrix DISPLAYFORM8 Then, plugging A † 2 = C −1 V U into eq. (25) yields the desired form of A 1 .We now prove eq. (3).', 'Note that the above proof is based on the equations DISPLAYFORM9 Hence, the forms of A 1 , A 2 in eqs. (1) and (2) need to further satisfy ∇ A2 L = 0.', 'By eq. FORMULA19 and the form of A 2 , we obtain that DISPLAYFORM10 This expression, together with the form of A 1 in eq. (1), implies that DISPLAYFORM11 where (i) uses the fact that X † XX = X , (ii) uses the fact that the block pattern of V is compatible with the multiplicity pattern of the singular values in Λ, and hence V V ΛV = ΛV .', 'On the other hand, we also obtain that DISPLAYFORM12 Thus, to satisfy ∇ A2 L = 0 in eq. FORMULA12 , we require that DISPLAYFORM13 which is equivalent to DISPLAYFORM14 Lastly, note that (I − U V (U V ) ) = P col(U V ) ⊥ , and (I − V V ) = P ker(V ) , which concludes the proof.', 'By expansion we obtain that L = DISPLAYFORM0 .', 'Consider any (A 1 , A 2 ) that satisfies eq. FORMULA4 , we have shown that such a point also satisfies eq. (27), which further yields that DISPLAYFORM1 where (i) follows from the fact that Tr( P col(A2) Σ P col(A2) ) = Tr( P col(A2) Σ), and (ii) uses the fact that P col(A2) = U P col(U A2) U .', 'In particular, a critical point (A 1 , A 2 ) satisfies eq. (28).', 'Moreover, using the form of the critical point A 2 = U V C, eq. FORMULA20 further becomes DISPLAYFORM2 where (i) is due to P col(V C) = P col(V ) = V V , and (ii) utilizes the block pattern of V and the multiplicity pattern of Λ that are specified in Theorem 1.', '(1): Consider a critical point (A 1 , A 2 ) with the forms given by Theorem 1.', 'By choosing L 1 = 0, the condition in eq. FORMULA4 is guaranteed.', 'Then, we can specify a critical point with any V that satisfies the block pattern specified in Theorem 1, i.e., we can choose any p i , i = 1, . . .', ', r,p such that p i ≤ m i for i = 1, . . .', ', r,p ≤m and DISPLAYFORM0 m i , the global minimum value is achieved by a full rank A 2 with rank(A 2 ) = min{d 2 , d 1 } and DISPLAYFORM1 That is, the singular values are selected in a decreasing order to minimize the function value.(2): If (A 2 , A 1 ) is a global minimizer and min{d y , d} > r i=1 m i , the global minimum can be achieved by choosing p i = m i for all i = 1, . . .', ', r andp ≥ 0.', 'In particular, we do not need a full rank A 2 to achieve the global minimum.', 'For example, we can choose rank(A 2 ) = r i=1 m i < min{d y , d} with p i = m i for all i = 1, . . .', ', r andp = 0.', 'We first prove item 1.', 'Consider a non-optimal-order critical point (A 1 , A 2 ).', 'By Theorem 1, we can write A 2 = U V C where V = [diag(V 1 , . . .', ', V r , V ), 0] and V i , i = 1, . . .', ', r, V consist of orthonormal columns.', 'Define the orthonormal block diagonal matrix Since (A 1 , A 2 ) is a non-optimal-order critical point, there exists 1 ≤ i < j ≤ r such that p i < m i and p j > 0.', 'Then, consider the following perturbation of U S for some > 0.', 'DISPLAYFORM0 DISPLAYFORM1 with which we further define the perturbation matrix A 2 = M S V C. Also, let the perturbation matrix A 1 be generated by eq. (1) with U ← M and V ← S V .', 'Note that with this construction, ( A 1 , A 2 ) satisfies eq. (25), which further implies eq. (27) for ( A 1 , A 2 ), i.e., A 2 A 1 X = P col( A2) Y X † X. Thus, eq. (28) holds for the point ( A 1 , A 2 ), and we obtain that DISPLAYFORM2 where the last equality uses the fact that S ΛS = Λ, as can be observed from the block pattern of S and the multiplicity pattern of Λ. Also, by the construction of M and the form of S V , a careful calculation shows that only the i, j-th diagonal elements of P col(S U M S V ) have changed, i.e., DISPLAYFORM3 As the index i, j correspond to the singular values σ i , σ j , respectively, and σ i > σ j , one obtain that DISPLAYFORM4 Thus, the construction of the point ( A 2 , A 1 ) achieves a lower function value for any > 0.', 'Letting → 0 and noticing that M is a perturbation of U S, the point ( A 2 , A 1 ) can be in an arbitrary neighborhood of (A 2 , A 1 ).', 'Lastly, note that rank( A 2 ) = rank(A 2 ).', 'This completes the proof of item 1.Next, we prove item 2.', 'Consider an optimal-order critical point (A 1 , A 2 ).', 'Then, A 2 must be non-full rank, since otherwise a full rank A 2 with optimal order corresponds to a global minimizer by Proposition 2.', 'Since there exists some k ≤ r such that 0] .', 'Using this expression, eq. (1) yields that DISPLAYFORM5 DISPLAYFORM6 We now specify our perturbation scheme.', 'Recalling the orthonormal matrix S defined in eq. (29).', 'Then, we consider the following matrices for some 1 , 2 > 0 DISPLAYFORM7 For this purpose, we need to utilize the condition of critical points in eq. (3), which can be equivalently expressed as DISPLAYFORM8 (ii) ⇔ (CL 1 ) (rank(A2)+1):d1,: XY (I − U S :,1:(q−1) (U S :,1:(q−1) ) ) = 0where (i) follows by taking the transpose and then simplifying, and (ii) uses the fact that V = SS V = S :,1:(q−1) in the case of optimal-order critical point.', 'Calculating the function value at ( A 1 , A 2 ), we obtain that DISPLAYFORM9 .', 'We next simplify the above three trace terms using eq. (31).', 'For the first trace term, observe that DISPLAYFORM10 2 Tr(S :,q ΛS :,q ) where (i) follows from eq. (31) as S :,q is orthogonal to the columns of S :,1:(q−1) .', 'For the second trace term, we obtain that DISPLAYFORM11 = 2Tr( 2 U S :,q (CL 1 ) (rank(A2)+1),: XY U V diag (U V diag ) ) + 2Tr( 1 2 U S :,q S :,q ΛSS V diag (U V diag ) ) (i) = 2Tr( 2 U S :,q (CL 1 ) (rank(A2)+1),: XY U V diag (U V diag ) ) + 2Tr( 1 2 σ k U S :,q e q S V diag (U V diag ) )(ii) = 2Tr( 2 U S :,q (CL 1 ) (rank(A2)+1),: XY U V diag (U V diag ) ), where (i) follows from S :,q ΛS = σ k e q , and (ii) follows from e q S V diag = 0.', 'For the third trace term, we obtain that 2Tr(P Y ) = 2Tr( 2 U S :,q (CL 1 ) (rank(A2)+1),: XY ) + 2Tr( 1 2 U S :,q (U S :,q ) Σ) = 2Tr( 2 U S :,q (CL 1 ) (rank(A2)+1),: XY ) + 2Tr( 1 2 S :,q ΛS :,q ).Combining the expressions for the three trace terms above, we conclude that Consider a critical point (A 1 , . . .', ', A ) so that eq. FORMULA4', 'Observe that the product matrix A ( ,2) is equivalent to the class of matrices B 2 ∈ R min{d ,...,d2}×d1 .Consider a critical point (B 2 , A 1 ) of the shallow linear network L :=', 'The proof is similar to that for shallow linear networks.', 'Consider a deep-non-optimal-order critical point (A 1 , . . .', ', A ), and define the orthonormal block matrix S k using the blocks of V k in a similar way as eq. (29).', 'Then, A (l,k+2) takes the form A (l,k+2) = U k S k S k V k C k .', 'Since A (l,k+2) is of non-optimal order, there exists i < j < r(k) such that p i (k) < m i (k) and p j (k) > 0.', 'Thus, we perturb the j-th column of U k S k to be , and denote the resulting matrix as M k .Then, we perturb A to be A = M k (U k S k ) A so that A A ( −1,k+2) = M k S k V k C k .', 'Moreover, we generate A k+1 by eq. (4) with U k ← M k , V k ← S k V k .', 'Note that such construction satisfies eq. (32), and hence also satisfies eq. (34), which further yields that DISPLAYFORM0 With the above equation, the function value at this perturbed point is evaluated as DISPLAYFORM1 Then, a careful calculation shows that only the i, j-th diagonal elements of DISPLAYFORM2 have changed, and are Now consider a deep-optimal-order critical point (A 1 , . . .', ', A ).', 'Note that with A ( −2,1) fixed to be a constant, the deep linear network reduces to a shallow linear network with parameters (A , A −1 ).', 'Since (A , A −1 ) is not a non-global minimum critical point of this shallow linear network and A is of optimal-order, we can apply the perturbation scheme in the proof of Proposition 3 to identify a perturbation ( A , A −1 ) with rank( A ) = rank(A ) + 1 that achieves a lower function value.', 'Consider any point in X D .', 'Since A ( ,1) X = 0, we can scale the nonzero row, say, the i-th row (A ) i,: A ( −1,1) X properly in the same way as that in the proof of Proposition 3 to increase the function value.', 'Lastly, item 1 and item 2 imply that every local minimum is a global minimum for these two types of critical points.', 'Moreover, combining items 1,2 and 3, we conclude that every critical point of these two types in X D is a saddle point.']\n"
          ]
        }
      ],
      "source": [
        "data_list = load_data('train')\n",
        "data_list.extend(load_data('dev'))\n",
        "data_list.extend(load_data('test'))\n",
        "\n",
        "# Convert the list of dictionaries to a Pandas DataFrame\n",
        "data = pd.DataFrame(data_list)\n",
        "\n",
        "# Display the DataFrame\n",
        "display(data.head())\n",
        "print(data['source'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvhhDOSFsRsb",
        "outputId": "bd3b1022-55b3-4a97-e144-840714cbcad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    3229.000000\n",
            "mean       34.522453\n",
            "std        24.459065\n",
            "min         3.000000\n",
            "25%        16.000000\n",
            "50%        24.000000\n",
            "75%        51.000000\n",
            "max       149.000000\n",
            "Name: number_words_target, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Drop columns\n",
        "no_need_columns = ['source_labels', 'rouge_scores']\n",
        "data = data.drop(columns=no_need_columns)\n",
        "\n",
        "data = join_words(data, 'target')\n",
        "\n",
        "data['number_words_target'] = count_words(data, 'target')\n",
        "\n",
        "print(data['number_words_target'].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6NHG1aFfaqf",
        "outputId": "dad72427-19e3-4086-8d28-5dd610165c40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    1312.000000\n",
              "mean       58.935213\n",
              "std        20.402388\n",
              "min        30.000000\n",
              "25%        41.000000\n",
              "50%        58.000000\n",
              "75%        73.000000\n",
              "max       149.000000\n",
              "Name: number_words_target, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Summaries with less than 25 words are eliminated from the data\n",
        "clean_data = data[data['number_words_target']>=30]\n",
        "clean_data = clean_data.reset_index(drop=True)\n",
        "\n",
        "clean_data['number_words_target'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "not6hOj1hg6W",
        "outputId": "fdf3e645-68df-4bb1-9f52-1db5f71081b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              source    paper_id  \\\n",
              "0  [Due to the success of deep learning to solvin...   SysEexbRb   \n",
              "1  [Generative Adversarial Networks (GANs) have a...   ryj38zWRb   \n",
              "2  [Dialogue systems require a great deal of diff...  BJepraEFPr   \n",
              "3  [Backdoor attacks aim to manipulate a subset o...  rkgyS0VFvr   \n",
              "4  [The integration of a  Knowledge Base (KB) int...  SJl7tREFvr   \n",
              "\n",
              "                                              target title  \\\n",
              "0  We provide necessary and sufficient analytical...   NaN   \n",
              "1  Are GANs successful because of adversarial tra...   NaN   \n",
              "2  In this paper, we propose to learn a dialogue ...   NaN   \n",
              "3  We proposed a novel distributed backdoor attac...   NaN   \n",
              "4  Conventional memory networks generate many red...   NaN   \n",
              "\n",
              "   number_words_target  extractive_summary  \n",
              "0                   38                 NaN  \n",
              "1                   36                 NaN  \n",
              "2                   30                 NaN  \n",
              "3                   35                 NaN  \n",
              "4                   32                 NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f11bce5-d764-4fc7-9dab-84bf4ad76e98\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>paper_id</th>\n",
              "      <th>target</th>\n",
              "      <th>title</th>\n",
              "      <th>number_words_target</th>\n",
              "      <th>extractive_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Due to the success of deep learning to solvin...</td>\n",
              "      <td>SysEexbRb</td>\n",
              "      <td>We provide necessary and sufficient analytical...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>38</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Generative Adversarial Networks (GANs) have a...</td>\n",
              "      <td>ryj38zWRb</td>\n",
              "      <td>Are GANs successful because of adversarial tra...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Dialogue systems require a great deal of diff...</td>\n",
              "      <td>BJepraEFPr</td>\n",
              "      <td>In this paper, we propose to learn a dialogue ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Backdoor attacks aim to manipulate a subset o...</td>\n",
              "      <td>rkgyS0VFvr</td>\n",
              "      <td>We proposed a novel distributed backdoor attac...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>35</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[The integration of a  Knowledge Base (KB) int...</td>\n",
              "      <td>SJl7tREFvr</td>\n",
              "      <td>Conventional memory networks generate many red...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f11bce5-d764-4fc7-9dab-84bf4ad76e98')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7f11bce5-d764-4fc7-9dab-84bf4ad76e98 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7f11bce5-d764-4fc7-9dab-84bf4ad76e98');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-847e058e-45ff-4deb-94be-e865e96e209b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-847e058e-45ff-4deb-94be-e865e96e209b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-847e058e-45ff-4deb-94be-e865e96e209b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "clean_data['extractive_summary'] = np.nan\n",
        "clean_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RESET DATA\n",
        "import ast\n",
        "\n",
        "clean_data = pd.read_csv(BASE_PATH+'extractive_summaries+good.csv')\n",
        "\n",
        "# Assuming 'df' is your DataFrame and 'list_column' is the column with lists\n",
        "# For example, if your DataFrame looks like this:\n",
        "# df = pd.DataFrame({'list_column': [[1, 2, 3], [4, 5], [6, 7, 8]]})\n",
        "\n",
        "# Define a function to safely convert strings to lists\n",
        "def convert_to_list(cell):\n",
        "    try:\n",
        "        return ast.literal_eval(cell)\n",
        "    except (SyntaxError, ValueError):\n",
        "        return cell\n",
        "\n",
        "# Apply the function to the column with lists\n",
        "clean_data['source'] = clean_data['source'].apply(convert_to_list)\n",
        "\n",
        "# Now, 'list_column' contains lists\n",
        "# Access the first list in the first row, for example\n",
        "first_list = clean_data.at[0, 'source']\n",
        "print(first_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANz2vmVcnzLv",
        "outputId": "b338da58-af83-455a-cdc9-74f0dc574c43"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Due to the success of deep learning to solving a variety of challenging machine learning tasks, there is a rising interest in understanding loss functions for training neural networks from a theoretical aspect.', 'Particularly, the properties of critical points and the landscape around them are of importance to determine the convergence performance of optimization algorithms.', 'In this paper, we provide a necessary and sufficient characterization of the analytical forms for the critical points (as well as global minimizers) of the square loss functions for linear neural networks.', 'We show that the analytical forms of the critical points characterize the values of the corresponding loss functions as well as the necessary and sufficient conditions to achieve global minimum.', 'Furthermore, we exploit the analytical forms of the critical points to characterize the landscape properties for the loss functions of linear neural networks and shallow ReLU networks.', 'One particular conclusion is that: While the loss function of linear networks has no spurious local minimum, the loss function of one-hidden-layer nonlinear networks with ReLU activation function does have local minimum that is not global minimum.', 'In the past decade, deep neural networks BID8 have become a popular tool that has successfully solved many challenging tasks in a variety of areas such as machine learning, artificial intelligence, computer vision, and natural language processing, etc.', 'As the understandings of deep neural networks from different aspects are mostly based on empirical studies, there is a rising need and interest to develop understandings of neural networks from theoretical aspects such as generalization error, representation power, and landscape (also referred to as geometry) properties, etc.', 'In particular, the landscape properties of loss functions (that are typically nonconex for neural networks) play a central role to determine the iteration path and convergence performance of optimization algorithms.', 'One major landscape property is the nature of critical points, which can possibly be global minima, local minima, saddle points.', 'There have been intensive efforts in the past into understanding such an issue for various neural networks.', 'For example, it has been shown that every local minimum of the loss function is also a global minimum for shallow linear networks under the autoencoder setting and invertibility assumptions BID1 and for deep linear networks BID11 ; BID14 ; Yun et al. (2017) respectively under different assumptions.', 'The conditions on the equivalence between local minimum or critical point and global minimum has also been established for various nonlinear neural networks Yu & Chen (1995) ; BID9 ; BID15 ; BID17 ; BID6 under respective assumptions.', 'However, most previous studies did not provide characterization of analytical forms for critical points of loss functions for neural networks with only very few exceptions.', 'In BID1 , the authors provided an analytical form for the critical points of the square loss function of shallow linear networks under certain conditions.', 'Such an analytical form further helps to establish the landscape properties around the critical points.', 'Further in BID13 , the authors characterized certain sufficient form of critical points for the square loss function of matrix factorization problems and deep linear networks.', 'The focus of this paper is on characterizing the sufficient and necessary forms of critical points for broader scenarios, i.e., shallow and deep linear networks with no assumptions on data matrices and network dimensions, and shallow ReLU networks over certain parameter space.', 'In particular, such analytical forms of critical points capture the corresponding loss function values and the necessary and sufficient conditions to achieve global minimum.', 'This further enables us to establish new landscape properties around these critical points for the loss function of these networks under general settings, and provides alternative (yet simpler and more intuitive) proofs for existing understanding of the landscape properties.', 'OUR CONTRIBUTION 1) For the square loss function of linear networks with one hidden layer, we provide a full (necessary and sufficient) characterization of the analytical forms for its critical points and global minimizers.', 'These results generalize the characterization in BID1 to arbitrary network parameter dimensions and any data matrices.', 'Such a generalization further enables us to establish the landscape property, i.e., every local minimum is also a global minimum and all other critical points are saddle points, under no assumptions on parameter dimensions and data matrices.', 'From a technical standpoint, we exploit the analytical forms of critical points to provide a new proof for characterizing the landscape around the critical points under full relaxation of assumptions, where the corresponding approaches in BID1 are not applicable.', 'As a special case of linear networks, the matrix factorization problem satisfies all these landscape properties.2) For the square loss function of deep linear networks, we establish a full (necessary and sufficient) characterization of the analytical forms for its critical points and global minimizers.', 'Such characterizations are new and have not been established in the existing art.', 'Furthermore, such analytical form divides the set of non-global-minimum critical points into different categories.', 'We identify the directions along which the loss function value decreases for two categories of the critical points, for which our result directly implies the equivalence between the local minimum and the global minimum.', 'For these cases, our proof generalizes the result in BID11 under no assumptions on the network parameter dimensions and data matrices.3) For the square loss function of one-hidden-layer nonlinear neural networks with ReLU activation function, we provide a full characterization of both the existence and the analytical forms of the critical points in certain types of regions in the parameter space.', 'Particularly, in the case where there is one hidden unit, our results fully characterize the existence and the analytical forms of the critical points in the entire parameter space.', 'Such characterization were not provided in previous work on nonlinear neural networks.', 'Moreover, we apply our results to a concrete example to demonstrate that both local minimum that is not a global minimum and local maximum do exist in such a case.', 'Analytical forms of critical points: Characterizing the analytical form of critical points for loss functions of neural networks dates back to BID1 , where the authors provided an analytical form of the critical points for the square loss function of linear networks with one hidden layer.', 'In BID13 , the authors provided a sufficient condition of critical points of a generic function, i.e., the fixed point of invariant groups.', 'They then characterized certain sufficient forms of critical points for the square loss function of matrix factorization problems and deep linear networks, whereas our results provide sufficient and necessary forms of critical points for deep linear networks via a different approach.', 'Properties of critical points: BID1 ; BID0 studied the linear autoencoder with one hidden layer and showed the equivalence between the local minimum and the global minimum.', 'Moreover, BID2 generalized these results to the complex-valued autoencoder setting.', 'The deep linear networks were studied by some recent work BID11 ; BID14 Yun et al. (2018) , in which the equivalence between the local minimum and the global minimum was established respectively under different assumptions.', 'Particularly, Yun et al. (2017) established a necessary and sufficient condition for a critical point of the deep linear network to be a global minimum.', 'A similar result was established in BID7 for deep linear networks under the setting that the widths of intermediate layers are larger than those of the input and output layers.', 'The effect of regularization on the critical points for a two-layer linear network was studied in Taghvaei et al. (2017) .For nonlinear neural networks, Yu & Chen (1995) studied a nonlinear neural network with one hidden layer and sigmoid activation function, and showed that every local minimum is also a global minimum provided that the number of input units equals the number of data samples.', 'BID9 considered a class of multi-layer nonlinear networks with a pyramidal structure, and showed that all critical points of full column rank achieve the zero loss when the sample size is less than the input dimension.', 'These results were further generalized to a larger class of nonlinear networks in BID15 , in which they also showed that critical points with non-degenerate Hessian are global minimum.', 'BID3 b) connected the loss surface of deep nonlinear networks with the Hamiltonian of the spin-glass model under certain assumptions and characterized the distribution of the local minimum.', 'BID11 further eliminated some of the assumptions in BID3 , and established the equivalence between the local minimum and the global minimum by reducing the loss function of the deep nonlinear network to that of the deep linear network.', 'BID17 showed that a two-layer nonlinear network has no bad differentiable local minimum.', 'BID6 studied a one-hidden-layer nonlinear neural network with the parameters restricted in a set of directions of lines, and showed that most local minima are global minima.', 'Tian (2017) considered a two-layer ReLU network with Gaussian input data, and showed that critical points in certain region are non-isolated and characterized the critical-point-free regions.', 'Geometric curvature BID10 established the gradient dominance condition of deep linear residual networks, and Zhou & Liang (2017) further established the gradient dominance condition and regularity condition around the global minimizers for deep linear, deep linear residual and shallow nonlinear networks.', 'BID12 studied the property of the Hessian matrix for deep linear residual networks.', 'The local strong convexity property was established in BID16 for overparameterized nonlinear networks with one hidden layer and quadratic activation functions, and was established in Zhong et al. (2017) for a class of nonlinear networks with one hidden layer and Gaussian input data.', 'Zhong et al. (2017) further established the local linear convergence of gradient descent method with tensor initialization.', 'BID18 studied a one-hidden-layer nonlinear network with a single output, and showed that the volume of sub-optimal differentiable local minima is exponentially vanishing in comparison with the volume of global minima.', 'BID5 investigated the saddle points in deep neural networks using the results from statistical physics and random matrix theory.', 'Notation: The pseudoinverse, column space and null space of a matrix M are denoted by M † , col(M ) and ker(M ), respectively.', 'For any index sets I, J ⊂ N, M I,J denotes the submatrix of M formed by the entries with the row indices in I and the column indices in J. For positive integers i ≤ j, we define i : j = {i, i + 1, . . . , j − 1, j}. The projection operator onto a linear subspace V is denoted by P V .', 'In this section, we study linear neural networks with one hidden layer.', 'Suppose we have an input data matrix X ∈ R d0×m and a corresponding output data matrix Y ∈ R d2×m , where there are in total m data samples.', 'We are interested in learning a model that maps from X to Y via a linear network with one hidden layer.', 'Specifically, we denote the weight parameters between the output layer and the hidden layer of the network as A 2 ∈ R d2×d1 , and denote the weight parameters between the hidden layer and the input layer of the network as A 1 ∈ R d1×d0 .', 'We are interested in the square loss function of this linear network, which is given by DISPLAYFORM0 Note that in a special case where X = I, L reduces to a loss function for the matrix factorization problem, to which all our results apply.', 'The loss function L has been studied in BID1 under the assumptions that d 2 = d 0 ≥ d 1 and the matrices XX , Y X (XX ) −1 XY are invertible.', 'In our study, no assumption is made on either the parameter dimensions or the invertibility of the data matrices.', 'Such full generalization of the results in BID1 turns out to be critical for our study of nonlinear shallow neural networks in Section 4.We further define Σ := Y X † XY and denote its full singular value decomposition as U ΛU .', 'Suppose that Σ has r distinct positive singular values σ 1 > · · · > σ r > 0 with multiplicities m 1 , . . .', ', m r , respectively, and hasm zero singular values.', 'Recall that DISPLAYFORM1 Our first result provides a full characterization of all critical points of L. Theorem 1 (Characterization of critical points).', 'All critical points of L are necessarily and sufficiently characterized by a matrix L 1 ∈ R d1×d0 , a block matrix V ∈ R d2×d1 and an invertible matrix C ∈ R d1×d1 via DISPLAYFORM2 (2) DISPLAYFORM3 , where both V i ∈ R mi×pi and V ∈ Rm ×p consist of orthonormal columns with the number of columns DISPLAYFORM4 Theorem 1 characterizes the necessary and sufficient forms for all critical points of L. Intuitively, the matrix C captures the invariance of the product A 2 A 1 under an invertible transform, and L 1 captures the degree of freedom of the solution set for linear systems.', 'In general, the set of critical points is uncountable and cannot be fully listed out.', 'However, the analytical forms in eqs. (1) and (2) do allow one to construct some critical points of L by specifying choices of L 1 , V , C that fulfill the condition in eq. (3).', 'For example, choosing L 1 = 0 guarantees eq. (3), in which case eqs. (1) and (2) yield a critical point (C −1 V U Y X † , U V C) for any invertible matrix C and any block matrix V that takes the form specified in Theorem 1.', 'For nonzero L 1 , one can fix a proper V and solve the linear equation on C in eq. (3).', 'If a solution exists, we then obtain the form of a corresponding critical point.', 'We further note that the analytical structures of the critical points are more important, which have direct implications on the global optimality conditions and landscape properties as we show in the remaining part of the section.', 'Remark 1.', 'We note that the block pattern parameters {p i } r i=1 andp denote the number of columns of {V i } r i=1 and V , respectively, and their sum equals the rank of A 2 , i.e., DISPLAYFORM5 The parameters p i , i = 1, . . .', ', r,p of V contain all useful information of the critical points that determine the function value of L as presented in the following proposition.', 'DISPLAYFORM6 Proposition 1 evaluates the function value L at a critical point using the parameters {p i } r i=1 .', 'To explain further, recall that the data matrix Σ has each singular value σ i with multiplicity m i .', 'For each i, the critical point captures p i out of m i singular values σ i .', 'Hence, for a σ i with larger value (i.e., a smaller index i), it is desirable that a critical point captures a larger number p i of them.', 'In this way, the critical point captures more important principle components of the data so that the value of the loss function is further reduced as suggested by Proposition 1.', 'In summary, the parameters {p i } r i=1 characterize how well the learned model fits the data in terms of the value of the loss function.', 'Moreover, the parameters {p i } r i=1 also determine a full characterization of the global minimizers as given below.', 'Proposition 2 (Characterization of global minimizers).', 'A critical point (A 1 , A 2 ) of L is a global minimizer if and only if it falls into the following two cases.', 'DISPLAYFORM7 The analytical form of any global minimizer can be obtained from Theorem 1 with further specification to the above two cases.', 'Proposition 2 establishes the neccessary and sufficient conditions for any critical point to be a global minimizer.', 'If the data matrix Σ has a large number of nonzero singular values, i.e., the first case, one needs to exhaust the representation budget (i.e., rank) of A 2 and capture as many large singular values as the rank allows to achieve the global minimum; Otherwise, A 2 of a global minimizer can be non-full rank and still captures all nonzero singular values.', 'Note that A 2 must be full rank in the case 1, and so is A 1 if we further adopt the assumptions on the network size and data matrices in BID1 .', 'Furthermore, the parameters {p i } r i=1 naturally divide all non-global-minimum critical points (A 1 , A 2 ) of L into the following two categories.• (Non-optimal order): The matrix V specified in Theorem 1 satisfies that there exists 1 ≤ i < j ≤ r such that p i < m i and p j > 0.• (Optimal order): rank(A 2 ) < min{d 2 , d 1 } and the matrix V specified in Theorem 1 satisfies that DISPLAYFORM8 To understand the above two categories, note that a critical point of L with non-optimal order captures a smaller singular value σ j (since p j > 0) while skipping a larger singular value σ i with a lower index i < j (since p i < m i ), and hence cannot be a global minimizer.', 'On the other hand, although a critical point of L with optimal order captures the singular values in the optimal (i.e., decreasing) order, it does not fully utilize the representation budget of A 2 (because A 2 is non-full rank) to further capture nonzero singular values and reduce the function value, and hence cannot be a global minimizer either.', 'Next, we show that these two types of non-global-minimum critical points have different landscape properties around them.', 'Throughout, a matrix M is called the perturbation of M if it lies in an arbitrarily small neighborhood of M .Proposition 3 (Landscape around critical points).', 'The critical points of L have the following landscape properties.1.', 'A non-optimal-order critical point (A 1 , A 2 ) has a perturbation ( A 1 , A 2 ) with rank( A 2 ) = rank(A 2 ), which achieves a lower function value; 2.', 'An optimal-order critical point (A 1 , A 2 ) has a perturbation ( A 1 , A 2 ) with rank( A 2 ) = rank(A 2 ) + 1, which achieves a lower function value; 3.', 'Any point in X := {(A 1 , A 2 ) : A 2 A 1 X = 0} has a perturbation (A 1 , A 2 ), which achieves a higher function value;As a consequence, items 1 and 2 imply that any non-global-minimum critical point has a descent direction, and hence cannot be a local minimizer.', 'Thus, any local minimizer must be a global minimizer.', 'Item 3 implies that any point has an ascent direction whenever the output is nonzero.', 'Hence, there does not exist any local/global maximizer in X .', 'Furthermore, item 3 together with items 1 and 2 implies that any non-global-minimum critical point in X has both descent and ascent directions, and hence must be a saddle point.', 'We summarize these facts in the following theorem.', 'Theorem 2 (Landscape of L).', 'The loss function L satisfies: 1) every local minimum is also a global minimum; 2) every non-global-minimum critical point in X is a saddle point.', 'We note that the saddle points in Theorem 2 can be non-strict when the data matrices are singular.', 'As an illustrative example, consider the following loss function of a shallow linear network L(a 2 , a 1 ) = 1 2 (a 2 a 1 x − y) 2 , where a 1 , a 2 , x and y are all scalars.', 'Consider the case y = 0.', 'Then, the Hessian at the saddle point a 1 = 0, a 2 = 1 is [x 2 , 0; 0, 0], which does not have any negative eigenvalue.', 'From a technical point of view, the proof of item 1 of Proposition 3 applies that in BID0 and generalizes it to the setting where Σ can have repeated singular values and may not be invertible.', 'To further understand the perturbation scheme from a high level perspective, note that non-optimalorder critical points capture a smaller singular value σ j instead of a larger one σ i with i < j. Thus, one naturally perturbs the singular vector corresponding to σ j along the direction of the singular vector corresponding to σ i .', 'Such a perturbation scheme preserves the rank of A 2 and reduces the value of the loss function.', 'More importantly, the proof of item 2 of Proposition 3 introduces a new technique.', 'As a comparison, BID1 proves a similar result as item 2 using the strict convexity of the function, which requires the parameter dimensions to satisfy d 2 = d 0 ≥ d 1 and the data matrices to be invertible.', 'In contrast, our proof completely removes these restrictions by introducing a new perturbation direction and exploiting the analytical forms of critical points in eqs. (1) and (2) and the condition in eq. (3).', 'The accomplishment of the proof further requires careful choices of perturbation parameters as well as judicious manipulations of matrices.', 'We refer the reader to the supplemental materials for more details.', 'As a high level understanding, since optimal-order critical points capture the singular values in an optimal (i.e., decreasing) order, the previous perturbation scheme for non-optimal-order critical points does not apply.', 'Instead, we increase the rank of A 2 by one in a way that the perturbed matrix captures the next singular value beyond the ones that have already been captured so that the value of the loss function can be further reduced.', 'In this section, we study deep linear networks with ≥ 2 layers.', 'We denote the weight parameters between the layers as A k ∈ R d k ×d k−1 for k = 1, . . .', ', , respectively.', 'The input and output data are denoted by X ∈ R d0×m , Y ∈ R d ×m , respectively.', 'We are interested in the square loss function of deep linear networks, which is given by DISPLAYFORM0 , respectively, andm(k) zero singular values.', 'Our first result provides a full characterization of all critical points of L D , where we denote DISPLAYFORM1 Theorem 3 (Characterization of critical points).', 'All critical points of L D are necessarily and sufficiently characterized by matrices DISPLAYFORM2 . .', ', A can be individually expressed out recursively via the following two equations: DISPLAYFORM3 DISPLAYFORM4 Note that the forms of the individual parameters A 1 , . . .', ', A can be obtained as follows by recursively applying eqs. (4) and (5).', 'First, eq. (5) with k = 0 yields the form of A ( ,2) .', 'Then, eq. (4) with k = 0 and the form of A ( ,2) yield the form of A 1 .', 'Next, eq. (5) with k = 1 yields the form of A ( ,3) , and then, eq. (4) with k = 1 and the forms of A ( ,3) , A 1 further yield the form of A 2 .', 'Inductively, one obtains the expressions of all individual parameter matrices.', 'Furthermore, the first condition in eq. FORMULA13 is a consistency condition that guarantees that the analytical form for the entire product of parameter matrices factorizes into the forms of individual parameter matrices.', 'Similarly to shallow linear networks, while the set of critical points here is also uncountable, Theorem 3 suggests ways to obtain some critical points.', 'For example, if we set L k = 0 for all k (i.e., eq. (6) is satisfied), we can obtain the form of critical points for any invertible C k and proper V k with the structure specified in Theorem 3.', 'For nonzero L k , eq. (6) needs to be verified for given C k and V k to determine a critical point.', 'Similarly to shallow linear networks, the parameters {p i (0)} r (0) i=1 ,p(0) determine the value of the loss function at the critical points and further specify the analytical form for the global minimizers, as we present in the following two propositions.', 'DISPLAYFORM5 DISPLAYFORM6 In particular, A ( ,2) can be non-full rank with rank(A ( ,2) ) = DISPLAYFORM7 The analytical form of any global minimizer can be obtained from Theorem 3 with further specification to the above two cases.', 'In particular for case 1, if we further adopt the invertibility assumptions on data matrices as in BID1 and assume that all parameter matrices are square, then all global minima must correspond to full rank parameter matrices.', 'We next exploit the analytical forms of the critical points to further understand the landscape of the loss function L D .', 'It has been shown in BID11 that every local minimum of L D is also a global minimum, under certain conditions on the parameter dimensions and the invertibility of the data matrices.', 'Here, our characterization of the analytical forms for the critical points allow us to understand such a result from an alternative viewpoint.', 'The proofs for certain cases (that we discuss below) are simpler and more intuitive, and no assumption is made on the data matrices and dimensions of the network.', 'Similarly to shallow linear networks, we want to understand the local landscape around the critical points.', 'However, due to the effect of depth, the critical points of L D are more complicated than those of L. Among them, we identify the following subsets of the non-global-minimum critical DISPLAYFORM8 • (Deep-non-optimal order): There exist 0 ≤ k ≤ − 2 such that the matrix V k specified in Theorem 3 satisfies that there exist 1 ≤ i < j ≤ r(k) such that p i (k) < m i (k) and p j (k) > 0.• (Deep-optimal order): (A , A −1 ) is not a global minimizer of L D with A ( −2,1) being fixed, rank(A ) < min{d , d −1 }, and the matrix V −2 specified in Theorem 3 satisfies that DISPLAYFORM9 The following result summarizes the landscape of L D around the above two types of critical points.', 'The loss function L D has the following landscape properties.', 'deep-non-optimal-order critical point (A 1 , . . . , A ) has a perturbation (A 1 , . . .', ', A k+1 , . . .', ', A ) with rank( A ) = rank(A ), which achieves a lower function value.', '2.', 'A deep-optimal-order critical point (A 1 , . . . , A ) has a perturbation (A 1 , . . .', ', A −1 , A ) with rank( A ) = rank(A ) + 1, which achieves a lower function value.', '3.', 'Any point in X D := {(A 1 , . . .', ', A ) : A ( ,1) X = 0} has a perturbation (A 1 , . . .', ', A ) that achieves a higher function value.', 'Consequently, 1) every local minimum of L D is also a global minimum for the above two types of critical points; and 2) every critical point of these two types in X D is a saddle point.', 'Theorem 4 implies that the landscape of L D for deep linear networks is similar to that of L for shallow linear networks, i.e., the pattern of the parameters {p i (k)} r(k) i=1 implies different descent directions of the function value around the critical points.', 'Our approach does not handle the remaining set of non-global minimizers, i.e., there exists q ≤ −1 such that (A , . . .', ', A q ) is a global minimum point of L D with A (q−1,1) being fixed, and A ( ,q) is of optimal order.', 'It is unclear how to perturb the intermediate weight parameters using their analytical forms for deep networks , and we leave this as an open problem for the future work.', 'In this section, we study nonlinear neural networks with one hidden layer.', 'In particular, we consider nonlinear networks with ReLU activation function σ : R → R that is defined as σ(x) := max{x, 0}. Our study focuses on the set of differentiable critical points.', 'The weight parameters between the layers are denoted by A 2 ∈ R d2×d1 , A 1 ∈ R d1×d0 , respectively, and the input and output data are denoted by X ∈ R d0×m , Y ∈ R d2×m , respectively.', 'We are interested in the square loss function which is given by DISPLAYFORM0 where σ acts on A 1 X entrywise.', 'Existing studies on nonlinear networks characterized the sufficient conditions for critical points being global minimum BID9 Since the activation function σ is piecewise linear, the entire parameter space can be partitioned into disjoint cones.', 'In particular, we consider the set of cones K I×J where I ⊂ {1, . . .', ', d 1 }, J ⊂ {1, . . .', ', m} that satisfy DISPLAYFORM1 where \"≥\" and \"<\" represent entrywise comparisons.', 'Within K I×J , the term σ(A 1 X) activates only the entries σ(A 1 X) I:J , and the corresponding loss function L N is equivalent to DISPLAYFORM2 Hence, within K I×J , L N reduces to the loss of a shallow linear network with parameters ((A 2 ) :,I , (A 1 ) I,: ) and input & output data pair (X :,J , Y :,J ).', 'Note that our results on shallow linear networks in Section 2 are applicable to all parameter dimensions and data matrices.', 'Thus, Theorem 1 fully characterizes the forms of critical points of L N in K I×J .', 'Moreover, the existence of such critical points can be analytically examined by substituting their forms into eq. (8).', 'In summary, we obtain the following result, where we denote Σ J := Y :,J X † :,J X :,J Y :,J with the full singular value decomposition U J Λ J U J , and suppose that Σ J has r(J) distinct positive singular values σ 1 (J) > · · · > σ r(J) (J) with multiplicities m 1 , . . .', ', m r(J) , respectively, andm(J) zero singular values.', 'Proposition 6 (Characterization of critical points).', 'All critical points of L N in K I×J for any I ⊂ {1, . . .', ', d 1 }, J ⊂ {1, . . .', ', m} are necessarily and sufficiently characterized by an L 1 ∈ R |I|×d0 , a block matrix V ∈ R d2×|I| and an invertible matrix C ∈ R |I|×|I| such that DISPLAYFORM3 DISPLAYFORM4 ×p consist of orthonormal columns with p i ≤ m i for i = 1, . . .', ', r(J),p ≤m such that DISPLAYFORM5 Moreover, a critical point in K I×J exists if and only if there exists such C, V , L 1 that DISPLAYFORM6 Other entries of A 1 X < 0.To further illustrate, we consider a special case where the nonlinear network has one unit in the hidden layer, i.e., d 1 = 1, in which case A 1 and A 2 are row and column vectors, respectively.', 'Then, the entire parameter space can be partitioned into disjoint cones taking the form of K I×J , and I = {1} is the only nontrivial choice.', 'We obtain the following result from Proposition 6.Proposition 7 (Characterization of critical points).', 'Consider L N with d 1 = 1 and any J ⊂ {1, . . .', ', m}. Then, any nonzero critical point of L N within K {1}×J can be necessarily and sufficiently characterized by an 1 ∈ R 1×d0 , a block unit vector v ∈ R d2×1 and a scalar c ∈ R such that DISPLAYFORM7 Specifically, v is a unit vector that is supported on the entries corresponding to the same singular value of Σ J .', 'Moreover, a nonzero critical point in K {1}×J exists if and only if there exist such c, v, 1 that satisfy DISPLAYFORM8 DISPLAYFORM9 We note that Proposition 7 characterizes both the existence and the forms of critical points of L N over the entire parameter space for nonlinear networks with a single hidden unit.', 'The condition in eq. FORMULA24 is guaranteed because P ker(v) = 0 for v = 0.To further understand Proposition 7, suppose that there exists a critical point in K {1}×J with v being supported on the entries that correspond to the i-th singular value of Σ J .', 'Then, Proposition 1 implies that DISPLAYFORM10 In particular, the critical point achieves the local minimum DISPLAYFORM11 .', 'This is because in this case the critical point is full rank with an optimal order, and hence corresponds to the global minimum of the linear network in eq. (9).', 'Since the singular values of Σ J may vary with the choice of J, L N may achieve different local minima in different cones.', 'Thus, local minimum that is not global minimum can exist for L N .', 'The following proposition concludes this fact by considering a concrete example.', 'Proposition 8.', 'For one-hidden-layer nonlinear neural networks with ReLU activation function, there exists local minimum that is not global minimum, and there also exists local maximum.', 'FORMULA13 and FORMULA19 hold if c −1 (v) 1,: ≥ 0, ( 1 ) 1,: < 0.', 'Similarly to the previous case, choosing c = 1, v = (1, 0) , 1 = (−1, 0) yields a local minimum that achieves the function value L n = 2.', 'Hence, local minimum that is not global minimum does exist.', 'Moreover, in the cone K I×J with I = {1}, J = ∅, the function L N remains to be the constant 5 2 , and all points in this cone are local minimum or local maximum.', 'Thus, the landscape of the loss function of nonlinear networks is very different from that of the loss function of linear networks.', 'In this paper, we provide full characterization of the analytical forms of the critical points for the square loss function of three types of neural networks, namely, shallow linear networks, deep linear networks, and shallow ReLU nonlinear networks.', 'We show that such analytical forms of the critical points have direct implications on the values of the corresponding loss functions, achievement of global minimum, and various landscape properties around these critical points.', 'As a consequence, the loss function for linear networks has no spurious local minimum, while such point does exist for nonlinear networks with ReLU activation.', 'In the future, it is interesting to further explore nonlinear neural networks.', 'In particular, we wish to characterize the analytical form of critical points for deep nonlinear networks and over the full parameter space.', 'Such results will further facilitate the understanding of the landscape properties around these critical points.', 'Notations: For any matrix M , denote vec(M ) as the column vector formed by stacking its columns.', 'Denote the Kronecker product as \"⊗\".', 'Then, the following useful relationships hold for any dimension compatible matrices M , U , V , W : DISPLAYFORM0 DISPLAYFORM1 DISPLAYFORM2 DISPLAYFORM3 Recall that a point DISPLAYFORM4 DISPLAYFORM5 We first prove eqs. (1) and (2) .', 'DISPLAYFORM6 Next, we derive the form of A 2 .', 'Recall the full singular value decomposition Σ = U ΛU , where Λ is a diagonal matrix with distinct singular values σ 1 > . . .', '> σ r > 0 and multiplicities m 1 , . . .', ', m r , respectively.', 'We also assume that there arem number of zero singular values in Λ. Using the fact that P col(A2) = U P col(U A2) U , the last equality in eq. (26) reduces to DISPLAYFORM7 By the multiplicity pattern of the singular values in Λ, P col(U A2) must be block diagonal.', 'Specifically, we can write P col(U A2) = diag( P 1 , . . .', ', P r , P), where P i ∈ R mi×mi and P ∈ Rm ×m .Also, since P col(U A2) is a projection, P 1 , . . . , P r , P must all be projections.', 'Note that P col(U A2) has rank rank(A 2 ), and suppose that P 1 , . . .', ', P r , P have ranks p 1 , . . .', ', p r ,p, respectively.', 'Then, we must have p i ≤ m i for i = 1, . . .', ', r,p ≤m and r i=1 p i +p = rank(A 2 ).', 'Also, note that each projection can be expressed as P i = V i V i with V i ∈ R mi×pi , V ∈ Rm ×p consisting of orthonormal columns.', 'Hence, we can write P col(U A2) = V V where V = diag(V 1 , . . .', ', V r , V ).', 'We then conclude that P col(A2) = U P col(U A2) U = U V V U .', 'Thus, A 2 has the same column space as U V , and there must exist an invertible matrix DISPLAYFORM8 Then, plugging A † 2 = C −1 V U into eq. (25) yields the desired form of A 1 .We now prove eq. (3).', 'Note that the above proof is based on the equations DISPLAYFORM9 Hence, the forms of A 1 , A 2 in eqs. (1) and (2) need to further satisfy ∇ A2 L = 0.', 'By eq. FORMULA19 and the form of A 2 , we obtain that DISPLAYFORM10 This expression, together with the form of A 1 in eq. (1), implies that DISPLAYFORM11 where (i) uses the fact that X † XX = X , (ii) uses the fact that the block pattern of V is compatible with the multiplicity pattern of the singular values in Λ, and hence V V ΛV = ΛV .', 'On the other hand, we also obtain that DISPLAYFORM12 Thus, to satisfy ∇ A2 L = 0 in eq. FORMULA12 , we require that DISPLAYFORM13 which is equivalent to DISPLAYFORM14 Lastly, note that (I − U V (U V ) ) = P col(U V ) ⊥ , and (I − V V ) = P ker(V ) , which concludes the proof.', 'By expansion we obtain that L = DISPLAYFORM0 .', 'Consider any (A 1 , A 2 ) that satisfies eq. FORMULA4 , we have shown that such a point also satisfies eq. (27), which further yields that DISPLAYFORM1 where (i) follows from the fact that Tr( P col(A2) Σ P col(A2) ) = Tr( P col(A2) Σ), and (ii) uses the fact that P col(A2) = U P col(U A2) U .', 'In particular, a critical point (A 1 , A 2 ) satisfies eq. (28).', 'Moreover, using the form of the critical point A 2 = U V C, eq. FORMULA20 further becomes DISPLAYFORM2 where (i) is due to P col(V C) = P col(V ) = V V , and (ii) utilizes the block pattern of V and the multiplicity pattern of Λ that are specified in Theorem 1.', '(1): Consider a critical point (A 1 , A 2 ) with the forms given by Theorem 1.', 'By choosing L 1 = 0, the condition in eq. FORMULA4 is guaranteed.', 'Then, we can specify a critical point with any V that satisfies the block pattern specified in Theorem 1, i.e., we can choose any p i , i = 1, . . .', ', r,p such that p i ≤ m i for i = 1, . . .', ', r,p ≤m and DISPLAYFORM0 m i , the global minimum value is achieved by a full rank A 2 with rank(A 2 ) = min{d 2 , d 1 } and DISPLAYFORM1 That is, the singular values are selected in a decreasing order to minimize the function value.(2): If (A 2 , A 1 ) is a global minimizer and min{d y , d} > r i=1 m i , the global minimum can be achieved by choosing p i = m i for all i = 1, . . .', ', r andp ≥ 0.', 'In particular, we do not need a full rank A 2 to achieve the global minimum.', 'For example, we can choose rank(A 2 ) = r i=1 m i < min{d y , d} with p i = m i for all i = 1, . . .', ', r andp = 0.', 'We first prove item 1.', 'Consider a non-optimal-order critical point (A 1 , A 2 ).', 'By Theorem 1, we can write A 2 = U V C where V = [diag(V 1 , . . .', ', V r , V ), 0] and V i , i = 1, . . .', ', r, V consist of orthonormal columns.', 'Define the orthonormal block diagonal matrix Since (A 1 , A 2 ) is a non-optimal-order critical point, there exists 1 ≤ i < j ≤ r such that p i < m i and p j > 0.', 'Then, consider the following perturbation of U S for some > 0.', 'DISPLAYFORM0 DISPLAYFORM1 with which we further define the perturbation matrix A 2 = M S V C. Also, let the perturbation matrix A 1 be generated by eq. (1) with U ← M and V ← S V .', 'Note that with this construction, ( A 1 , A 2 ) satisfies eq. (25), which further implies eq. (27) for ( A 1 , A 2 ), i.e., A 2 A 1 X = P col( A2) Y X † X. Thus, eq. (28) holds for the point ( A 1 , A 2 ), and we obtain that DISPLAYFORM2 where the last equality uses the fact that S ΛS = Λ, as can be observed from the block pattern of S and the multiplicity pattern of Λ. Also, by the construction of M and the form of S V , a careful calculation shows that only the i, j-th diagonal elements of P col(S U M S V ) have changed, i.e., DISPLAYFORM3 As the index i, j correspond to the singular values σ i , σ j , respectively, and σ i > σ j , one obtain that DISPLAYFORM4 Thus, the construction of the point ( A 2 , A 1 ) achieves a lower function value for any > 0.', 'Letting → 0 and noticing that M is a perturbation of U S, the point ( A 2 , A 1 ) can be in an arbitrary neighborhood of (A 2 , A 1 ).', 'Lastly, note that rank( A 2 ) = rank(A 2 ).', 'This completes the proof of item 1.Next, we prove item 2.', 'Consider an optimal-order critical point (A 1 , A 2 ).', 'Then, A 2 must be non-full rank, since otherwise a full rank A 2 with optimal order corresponds to a global minimizer by Proposition 2.', 'Since there exists some k ≤ r such that 0] .', 'Using this expression, eq. (1) yields that DISPLAYFORM5 DISPLAYFORM6 We now specify our perturbation scheme.', 'Recalling the orthonormal matrix S defined in eq. (29).', 'Then, we consider the following matrices for some 1 , 2 > 0 DISPLAYFORM7 For this purpose, we need to utilize the condition of critical points in eq. (3), which can be equivalently expressed as DISPLAYFORM8 (ii) ⇔ (CL 1 ) (rank(A2)+1):d1,: XY (I − U S :,1:(q−1) (U S :,1:(q−1) ) ) = 0where (i) follows by taking the transpose and then simplifying, and (ii) uses the fact that V = SS V = S :,1:(q−1) in the case of optimal-order critical point.', 'Calculating the function value at ( A 1 , A 2 ), we obtain that DISPLAYFORM9 .', 'We next simplify the above three trace terms using eq. (31).', 'For the first trace term, observe that DISPLAYFORM10 2 Tr(S :,q ΛS :,q ) where (i) follows from eq. (31) as S :,q is orthogonal to the columns of S :,1:(q−1) .', 'For the second trace term, we obtain that DISPLAYFORM11 = 2Tr( 2 U S :,q (CL 1 ) (rank(A2)+1),: XY U V diag (U V diag ) ) + 2Tr( 1 2 U S :,q S :,q ΛSS V diag (U V diag ) ) (i) = 2Tr( 2 U S :,q (CL 1 ) (rank(A2)+1),: XY U V diag (U V diag ) ) + 2Tr( 1 2 σ k U S :,q e q S V diag (U V diag ) )(ii) = 2Tr( 2 U S :,q (CL 1 ) (rank(A2)+1),: XY U V diag (U V diag ) ), where (i) follows from S :,q ΛS = σ k e q , and (ii) follows from e q S V diag = 0.', 'For the third trace term, we obtain that 2Tr(P Y ) = 2Tr( 2 U S :,q (CL 1 ) (rank(A2)+1),: XY ) + 2Tr( 1 2 U S :,q (U S :,q ) Σ) = 2Tr( 2 U S :,q (CL 1 ) (rank(A2)+1),: XY ) + 2Tr( 1 2 S :,q ΛS :,q ).Combining the expressions for the three trace terms above, we conclude that Consider a critical point (A 1 , . . .', ', A ) so that eq. FORMULA4', 'Observe that the product matrix A ( ,2) is equivalent to the class of matrices B 2 ∈ R min{d ,...,d2}×d1 .Consider a critical point (B 2 , A 1 ) of the shallow linear network L :=', 'The proof is similar to that for shallow linear networks.', 'Consider a deep-non-optimal-order critical point (A 1 , . . .', ', A ), and define the orthonormal block matrix S k using the blocks of V k in a similar way as eq. (29).', 'Then, A (l,k+2) takes the form A (l,k+2) = U k S k S k V k C k .', 'Since A (l,k+2) is of non-optimal order, there exists i < j < r(k) such that p i (k) < m i (k) and p j (k) > 0.', 'Thus, we perturb the j-th column of U k S k to be , and denote the resulting matrix as M k .Then, we perturb A to be A = M k (U k S k ) A so that A A ( −1,k+2) = M k S k V k C k .', 'Moreover, we generate A k+1 by eq. (4) with U k ← M k , V k ← S k V k .', 'Note that such construction satisfies eq. (32), and hence also satisfies eq. (34), which further yields that DISPLAYFORM0 With the above equation, the function value at this perturbed point is evaluated as DISPLAYFORM1 Then, a careful calculation shows that only the i, j-th diagonal elements of DISPLAYFORM2 have changed, and are Now consider a deep-optimal-order critical point (A 1 , . . .', ', A ).', 'Note that with A ( −2,1) fixed to be a constant, the deep linear network reduces to a shallow linear network with parameters (A , A −1 ).', 'Since (A , A −1 ) is not a non-global minimum critical point of this shallow linear network and A is of optimal-order, we can apply the perturbation scheme in the proof of Proposition 3 to identify a perturbation ( A , A −1 ) with rank( A ) = rank(A ) + 1 that achieves a lower function value.', 'Consider any point in X D .', 'Since A ( ,1) X = 0, we can scale the nonzero row, say, the i-th row (A ) i,: A ( −1,1) X properly in the same way as that in the proof of Proposition 3 to increase the function value.', 'Lastly, item 1 and item 2 imply that every local minimum is a global minimum for these two types of critical points.', 'Moreover, combining items 1,2 and 3, we conclude that every critical point of these two types in X D is a saddle point.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KRB935nOFJ-",
        "outputId": "37c2a228-b42e-4d73-c807-a69bc5d11ecd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]: generating summary 990/1312...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-6ceb3be05262>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  clean_data['extractive_summary'][index] = generate_extractive_summary(clean_data['source'][index],\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "294s\n",
            "[INFO]: generating summary 1000/1312...\n",
            "290s\n",
            "[INFO]: generating summary 1010/1312...\n",
            "344s\n",
            "[INFO]: generating summary 1020/1312...\n",
            "396s\n",
            "[INFO]: generating summary 1030/1312...\n",
            "285s\n",
            "[INFO]: generating summary 1040/1312...\n",
            "351s\n",
            "[INFO]: generating summary 1050/1312...\n",
            "306s\n",
            "[INFO]: generating summary 1060/1312...\n",
            "438s\n",
            "[INFO]: generating summary 1070/1312...\n",
            "256s\n",
            "[INFO]: generating summary 1080/1312...\n",
            "367s\n",
            "[INFO]: generating summary 1090/1312...\n",
            "468s\n",
            "[INFO]: generating summary 1100/1312...\n",
            "463s\n",
            "[INFO]: generating summary 1110/1312...\n",
            "355s\n",
            "[INFO]: generating summary 1120/1312...\n",
            "329s\n",
            "[INFO]: generating summary 1130/1312...\n",
            "300s\n",
            "[INFO]: generating summary 1140/1312...\n",
            "329s\n",
            "[INFO]: generating summary 1150/1312...\n",
            "433s\n",
            "[INFO]: generating summary 1160/1312...\n",
            "443s\n",
            "[INFO]: generating summary 1170/1312...\n",
            "254s\n",
            "[INFO]: generating summary 1180/1312...\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stop_words = stopwords.words('english')\n",
        "top_n = 16\n",
        "total = clean_data.shape[0]\n",
        "prev_index = 0\n",
        "\n",
        "reset_from = 990\n",
        "\n",
        "for index in range(reset_from, total):\n",
        "  if index % 10 == 0:\n",
        "    if (prev_index+10) == index:\n",
        "      end_time = time.time()\n",
        "      print(f'{int(end_time - start_time)}s')\n",
        "    print(f'[INFO]: generating summary {index}/{total}...')\n",
        "    prev_index = index\n",
        "    start_time = time.time()\n",
        "    clean_data.to_csv(BASE_PATH+'extractive_summaries_good.csv', index=False)\n",
        "\n",
        "  clean_data['extractive_summary'][index] = generate_extractive_summary(clean_data['source'][index],\n",
        "                                                                        top_n,\n",
        "                                                                        stop_words)\n",
        "\n",
        "clean_data.to_csv(BASE_PATH+'extractive_summaries+good.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  clean_data['extractive_summary'][1311]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "McNjnhncpeEv",
        "outputId": "c612c427-e5d0-4782-9330-a88e988fd9c7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Our approach transfers the structure of a visual representation space to the textual space by using two complementary sources of information: (1) the cluster information: the implicit knowledge that two sentences associated with the same visual content describe the same underlying reality and (2) the perceptual information contained within the structure of the visual space. Moreover, encoding semantics of sentences is paramount because sentences describe relationships between objects and thus convey complex and high-level knowledge better than individual words, which mostly refer to a single concept BID38 .Relying only on text can lead to biased representations and unrealistic predictions (e.g., text-based models could predict that \"the sky is green\" BID1 ). While there exist numerous approaches to learning sentence representations from text corpora only, and to learning multimodal word embeddings, the problem of the visual grounding of sentences is quite new to the research community. Is perceptual information useful to improve sentence representations?• RQ2: Are cluster and perceptual information complementary, and does their combination compete with previous models based on projections between visual and textual spaces?• RQ3: Is a joint approach better suited than a sequential one regarding the multimodal acquisition of textual and visual knowledge?Our contribution is threefold: (1) We propose a joint multimodal framework for learning grounded sentence representations; (2) We show that cluster and perceptual information are complementary sources of information; (3) To the best of our knowledge, obtained results achieve state-of-the-art performances on multimodal sentence representations. Note that C T and C V are not parallel corpora but that θ is shared between both objectives; in other terms, sentence representations are influenced by their distinct textual and visual contexts. different) sentence to s. Following BID24 ; BID5 , we use a max-margin ranking loss to ensure the gap between both terms is higher than a fixed margin m: DISPLAYFORM2 where (s, s + ) cover visually equivalent pairs; visually different sentences s − are randomly sampled. The final multimodal loss is a linear combination of the aforementioned objectives, weighted by hyperparameters α T , α P and α C : DISPLAYFORM4 To evaluate the impact of visual semantics on sentence grounding, we examine several types of visual context. The sum ranges over the words w of the sentence s, u w is the fixed pretrained word embedding of w, and N is a learned projection.3 EVALUATION PROTOCOL 3.1 DATASETS Textual dataset. In line with previous works on sentence embeddings BID28 BID19 , we consider several benchmarks to evaluate the quality of our learned multimodal representations:Semantic relatedness: We use two well-known semantic similarity benchmarks: STS BID6 and SICK BID35 , which consist of pairs of sentences that are associated with human-labeled similarity scores. Selecting relevant frames (T ) in the video rather than considering all frames with equal importance (A) improves the quality of the embeddings. There is a trade-off between semantic relatedness and classification scores, that we can set properly by tuning α T . To further answer RQ2, we compare our model M with the projection baseline P. Our model obtains higher results than P on semantic relatedness tasks and comparable ones on classification tasks. Since their textual baseline is weaker than ours (due to differences in the encoder and the dimensionality), we do not report their results in Table 4 .3. However, Fincher-Kiefer FORMULA2 ; W. BID49 insist on the intuition that language has to be grounded in the real world and perceptual experience. Our work is different in several ways from theirs: we use a joint approach instead of a sequential one, and we distinguish and exploit cluster and perceptual information; moreover, we use videos instead of sentences and our framework is applicable to any textual sentence representation model. (2) Preserving the structure of the visual space, by modeling textual similarities on visual ones, outperforms a strategy based on projecting one space into the other.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data['sentences_extractive_summary'] = clean_data['extractive_summary'].apply(sent_tokenize)"
      ],
      "metadata": {
        "id": "El-c94HptpLO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(clean_data['sentences_extractive_summary'][1])\n",
        "print(clean_data['source'][1])"
      ],
      "metadata": {
        "id": "YaL-KUMKuCsL",
        "outputId": "59a79457-a8c1-4530-8156-adcdd1a02c73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The experimental results presented in this work suggest that, in the image domain, we can recover many of the properties of GAN models by using convnets trained with simple reconstruction losses.', 'Therefore, it is reasonable to hypothesize that the reasons for the success of GANs in modeling natural images come from two complementary sources: (A1) Leveraging the powerful inductive bias of deep convnets.', '(A2) The adversarial training protocol.', 'While this does not invalidate the promise of GANs as generic models of uncertainty or as methods for building generative models, our results suggest that, in order to more fully test the adversarial construction, research needs to move beyond images and convnets.', 'The most common choices of the representation space for GANs are either the uniform distribution on the hypercube DISPLAYFORM1 In previous literature, Gaussian distributions lead to more stable GAN training BID36 , we will take this choice to design our representation space.', 'Since the early layers of convnets focus on edges, the samples from a GAN are sharper.', 'In the case of GLO, we fit a Gaussian distribution with full covariance to the representation space Z, and sample from such distribution to generate new samples.', 'There is a classical literature on dealing with nuisance parameters while estimating the parameters of interest, including optimization methods as we have used BID40 .', 'In the sequel, we initialize the random vectors of GLO using a Gaussian distribution (for the CelebA dataset) or the top d principal components (for the LSUN dataset).', 'In these works, the total loss function optimized to generate is trained separately from the optimization of the latent representation (in the former, the loss is based on a complex wavelet transform, and in the latter, on separately trained autoencoders and classification convolutional networks).', 'On the one hand, a generator plays to transform noise vectors into fake samples, which resemble real samples drawn from a distribution of natural images.', 'On the other hand, practitioners who care only about generating images for a particular application, and find that the parameterized discriminator does improve their results can use reconstruction losses in their model searches, alleviating some of the instability of GAN training.', 'To turn GLO into a generative model, we observe that it suffices to learn a simple probability distribution on the learned noise vectors.', 'Similarly to word embeddings BID31 , linear arithmetic indicates that the generator organizes the noise space to disentangle the nonlinear factors of variation of natural images into linear statistics.', 'On the other hand, a discriminator plays to distinguish between real and fake samples.', 'Our approach, called Generative Latent Optimization (GLO), maps one learnable noise vector to each of the images in our dataset by minimizing a simple reconstruction loss.', 'For example other loss functions (e.g.', 'a VGG metric, as in BID32 ), model architectures (here we stayed close to DCGAN for ease of comparison), and more sophisticated sampling methods after training the model all may improve the visual quality of the samples.']\n",
            "['Generative Adversarial Networks (GANs) have achieved remarkable results in the task of generating realistic natural images.', 'In most applications, GAN models share two aspects in common.', 'On the one hand, GANs training involves solving a challenging saddle point optimization problem, interpreted as an adversarial game between a generator and a discriminator functions.', 'On the other hand, the generator and the discriminator are parametrized in terms of deep convolutional neural networks.', 'The goal of this paper is to disentangle the contribution of these two factors to the success of GANs.', 'In particular, we introduce Generative Latent Optimization (GLO), a framework to train deep convolutional generators without using discriminators, thus avoiding the instability of adversarial optimization problems.', 'Throughout a variety of experiments, we show that GLO enjoys many of the desirable properties of GANs: learning from large data, synthesizing visually-appealing samples, interpolating meaningfully between samples, and performing linear arithmetic with noise vectors.', 'Generative Adversarial Networks (GANs) BID15 are a powerful framework to learn generative models of natural images.', 'GANs learn these generative models by setting up an adversarial game between two learning machines.', 'On the one hand, a generator plays to transform noise vectors into fake samples, which resemble real samples drawn from a distribution of natural images.', 'On the other hand, a discriminator plays to distinguish between real and fake samples.', 'During training, the generator and the discriminator learn in turns.', 'First, the discriminator learns to assign high scores to real samples, and low scores to fake samples.', 'Then, the generator learns to increase the scores of fake samples, as to fool the discriminator.', 'After proper training, the generator is able to produce realistic natural images from noise vectors.', 'Recently, GANs have been used to produce high-quality images resembling handwritten digits, human faces, and house interiors BID36 .', 'Furthermore, GANs exhibit three strong signs of generalization.', 'First, the generator translates linear interpolations in the noise space into semantic interpolations in the image space.', 'In other words, a linear interpolation in the noise space will generate a smooth interpolation of visually-appealing images.', 'Second, the generator allows linear arithmetic in the noise space.', 'Similarly to word embeddings BID31 , linear arithmetic indicates that the generator organizes the noise space to disentangle the nonlinear factors of variation of natural images into linear statistics.', 'Third, the generator is able to to synthesize new images that resemble those of the data distribution.', 'This allows for applications such as image in-painting BID18 and super-resolution BID26 .Despite their success, training and evaluating GANs is notoriously difficult.', 'The adversarial optimization problem implemented by GANs is sensitive to random initialization, architectural choices, and hyper-parameter settings.', 'In many cases, a fair amount of human care is necessary to find the correct configuration to train a GAN in a particular dataset.', 'It is common to observe generators with similar architectures and hyper-parameters to exhibit dramatically different behaviors.', 'Even when properly trained, the resulting generator may synthesize samples that resemble only a few localized regions (or modes) of the data distribution BID14 .', 'While several advances have been made to stabilize the training of GANs BID37 , this task remains more art than science.', 'The difficulty of training GANs is aggravated by the challenges in their evaluation: since evaluating the likelihood of a GAN with respect to the data is an intractable problem, the current gold standard to evaluate the quality of GANs is to eyeball the samples produced by the generator.', 'The evaluation of discriminators is also difficult, since their visual features do not always transfer well to supervised tasks BID12 BID13 .', 'Finally, the application of GANs to non-image data has been relatively limited.', 'Research question To model natural images with GANs, the generator and discriminator are commonly parametrized as deep Convolutional Networks (convnets) BID24 .', 'Therefore, it is reasonable to hypothesize that the reasons for the success of GANs in modeling natural images come from two complementary sources: (A1) Leveraging the powerful inductive bias of deep convnets. (A2) The adversarial training protocol.', 'This work attempts to disentangle the factors of success (A1) and (A2) in GAN models.', 'Specifically, we propose and study one algorithm that relies on (A1) and avoids (A2), but still obtains competitive results when compared to a GAN.', 'We investigate the importance of the inductive bias of convnets by removing the adversarial training protocol of GANs (Section 2).', 'Our approach, called Generative Latent Optimization (GLO), maps one learnable noise vector to each of the images in our dataset by minimizing a simple reconstruction loss.', 'Since we are predicting images from learnable noise, GLO borrows inspiration from recent methods to predict learnable noise from images BID3 .', 'Alternatively, one can understand GLO as an auto-encoder where the latent representation is not produced by a parametric encoder, but learned freely in a non-parametric manner.', 'In contrast to GANs, we track of the correspondence between each learned noise vector and the image that it represents.', 'Hence, the goal of GLO is to find a meaningful organization of the noise vectors, such that they can be mapped to their target images.', 'To turn GLO into a generative model, we observe that it suffices to learn a simple probability distribution on the learned noise vectors.', 'In our experiments (Section 3), we show that GLO inherits many of the appealing features of GANs, while enjoying a much simpler training protocol.', 'In particular, we study the efficacy of GLO to compress and decompress a dataset of images (Section 3.3.1), generate new samples (Section 3.3.2), perform linear interpolations and extrapolations in the noise space (Section 3.3.3), and perform linear arithmetics (Section 3.3.5).', 'Our experiments provide quantitative and qualitative comparisons to Principal Component Analysis (PCA), Variational Autoencoders (VAE) and GANs.', 'We focus on the CelebA and LSUN-Bedroom datasets.', 'We conclude our exposition in Section 5.', 'First, we consider a large set of images {x 1 , . . .', ', x N }, where each image x i ∈ X has dimensions 3 × w×h.', 'Second, we initialize a set of d-dimensional random vectors {z 1 , . . .', ', z N }, where z i ∈ Z ⊆ R d for all i = 1, . . .', 'N .', 'Third, we pair the dataset of images with the random vectors, obtaining the dataset {(z 1 , x 1 ), . . .', ', (z N , x N )}.', 'Finally, we jointly learn the parameters θ in Θ of a generator g θ : Z → X and the optimal noise vector z i for each image x i , by solving: DISPLAYFORM0 In the previous, : X × X is a loss function measuring the reconstruction error from g(z i ) to x i .', 'We call this model Generative Latent Optimization (GLO).Learnable z i .', 'In contrast to autoencoders BID6 , which assume a parametric model f : X → Z, usually referred to as the encoder, to compute the vector z from samples x, and minimize the reconstruction loss (g(f (x)), x), in GLO we jointly optimize the inputs z 1 , . . .', ', z N and the model parameter θ.', 'Since the vector z is a free parameter, our model can recover all the solutions that could be found by an autoencoder, and reach some others.', 'In a nutshell, GLO can be viewed as an \"encoder-less\" autoencoder, or as a \"discriminator-less\" GAN.', 'Figure 1: Plot of the cumulative sum of the singular values of the optimal Z * matrix.', 'We observe that the proposed GLO model has a better conditioned covariance matrix and therefore better fills the latent space.', 'Choice of Z. The representation space Z should encapsulate all of our prior knowledge about the data {x 1 , . . .', ', x N }.', 'Since we are interested in matching the properties of GANs, we make similar choices to them when it comes to the representation space Z.', 'The most common choices of the representation space for GANs are either the uniform distribution on the hypercube DISPLAYFORM1 In previous literature, Gaussian distributions lead to more stable GAN training BID36 , we will take this choice to design our representation space.', 'In GLO, the random vectors z are learnable and can therefore attain any value during the training process.', 'To avoid extremely large values, we normalize our learnable noise vectors z at all times, to lay on the unit 2 sphere.', 'Choice of loss function.', 'On the one hand, the squared-loss function 2 (x, x ) = x − x 2 2 is a simple choice, but leads to blurry (average) reconstructions of natural images.', 'On the other hand, GANs use a convnet (the discriminator) as loss function.', 'Since the early layers of convnets focus on edges, the samples from a GAN are sharper.', 'Therefore, our experiments provide quantitative and qualitative comparisons between the 2 loss and the Laplacian pyramid Lap 1 loss DISPLAYFORM2 where L j (x) is the j-th level of the Laplacian pyramid representation of x BID27 .', 'Therefore, the Lap 1 loss weights the details at fine scales more heavily.', 'In order to low-frequency content such as color information, we will use a weighted combination of the Lap 1 and the 2 costs.', 'Optimization.', 'For any choice of differentiable generator, the objective (1) is differentiable with respect to z, and θ.', 'Therefore, we will learn z and θ by Stochastic Gradient Descent (SGD).', 'The gradient of (1) with respect to z can be obtained by backpropagating the gradients through the generator function BID4 .', 'We project each z back to the representation space Z after each update.', 'To have noise vectors laying on the unit 2 sphere, we project z after each update by dividing its value by max( z 2 , 1).', 'We initialize the z by either sampling them from a gaussian distribution or by taking the whitened PCA of the raw image pixels.', 'We organized our experiments as follows.', 'First, Section 3.1 describes the generative models that we compare, along with their implementation details.', 'Section 3.2 reviews the image datasets used in our experiments.', 'Section 3.3 discusses the results of our experiments, including the compression of datasets (Section 3.3.1), the generation (Section 3.3.2) and interpolation (Section 3.3.3) of samples, and the results of arithmetic operations with noise vectors (Section 3.3.5).', 'First, PCA BID33 , equivalent to a linear autoencoder BID1 , where we retain the top 256 principal components.', 'Second, DCGAN BID36 .', 'Since GANs do not come with a mechanism (inverse generator) to retrieve the random vector g −1 (x) associated with an image x, we estimate this random vector by 1) instantiating a random vector z 0 , and 2) computing updates DISPLAYFORM0 by backpropagation until convergence, where is either the 2 or the Lap 1 loss.', 'Our experiments measuring reconstruction error are disadvantageous to GANs, since these are models that are not trained to minimize this metric.', 'We use the Adam optimizer BID20 with the parameters from BID36 Table 1 : Reconstruction errors in MSE.', 'We consider methods using both MSE and Lap 1 loss.', 'We also specify the initialization method between random and PCA.Third, VAE BID21 .', 'We train a VAE with the same encoder and decoder architectures as DCGAN.', 'We train it with the default hyper-parameters for 25 epochs.', 'Third, GLO (proposed model).', 'We will train a GLO model where the generator follows the same architecture as the generator in DCGAN.', 'We use Stochastic Gradient Descent (SGD) to optimize both θ and z, setting the learning rate for θ at 1 and the learning rate of z at 10.', 'After each udpdate, the noise vectors z are projected to the unit 2 sphere.', 'In the sequel, we initialize the random vectors of GLO using a Gaussian distribution (for the CelebA dataset) or the top d principal components (for the LSUN dataset).', 'We evaluate all models on two datasets of natural images.', 'Unless specified otherwise, we use the prescribed training splits to train our generative models.', 'All the images are rescaled to have three channels, center-cropped, and normalized to pixel values in [−1, +1].First, CelebA BID29 is a set of 202, 599 portraits of celebrities.', 'We use the aligned and cropped version, scaled to 128 × 128 pixels.', 'Second, LSUN BID44 ) is a set of millions of images of scenes belonging to different scene categories.', 'Following the tradition in GAN papers BID36 , we use the 3, 033, 042 images belonging to the bedroom category.', 'We resize the images to 64 × 64 pixels.', 'We compare the methods described on Section 3.1 when applied to the datasets described on Section 3.2.', 'In particular, we evaluate the performance of the methods in the tasks of compressing a dataset, generating new samples, performing sample interpolation, and doing sample arithmetic.', 'We start by measuring the reconstruction error in terms of the mean-squared loss 2 (x, x ) = x−x 2 2 and the Lap 1 loss (2) Table 1 shows the reconstruction error of all models and datasets for the 2 .', 'This gives a rough idea about the coverage of each model over the dataset.', 'Figure 1 show the quantity of the representation space explained as a function of the number of eigenvectors used to reconstruct it.', 'GLO trained from a random initialization is more aggressive about using the full representation space to spread the information around while PCA or autoencoders tend to concentrate the information in a few directions.', 'For completeness, we computed image reconstructions for the various models on a held-out set of images.', 'To this end we use face images from deep funneled images from Labeled Faces in the Wild BID17 .', 'In order to make the images similar to those found in CelebA we crop the images so as to align the location of eyes.', 'The reconstructions of a random sample of images are presented in Fig. 10 .', 'Figure 4 shows samples from the each of the models on the CelebA dataset, and Figure 5 shows the same fro the LSUN dataset.', 'In the case of GLO, we fit a Gaussian distribution with full covariance to the representation space Z, and sample from such distribution to generate new samples.', 'We can see that the samples are visually appealing even when placing such a simple probabilistic model on the representation space.', 'We leave more careful modeling of Z for future work.', 'The latent space can be explored by decomposing the covariance matrix of the latent vectors and moving along the eigenvectors associated with the largest eigenvalues from an image.', 'The resulting image transformation often contains information about attributes that varies in the dataset.', 'Figure 8 show some examples of image deformation along the principal axes.', 'The image in the middle is the original image.', 'Moving in either direction along an axis produces the images on its left and its right.', 'We see that the main axes seem to contain information about standard face attributes.', 'For example, the 4th component seems to be capturing information about facial expression while the 9th one seems to be capturing information about the age.', 'In absence of supervision, some directions make several attributes move simultaneously, for example smiling seems correlated with the hair color.', 'These correlations are artifacts of the CelebA dataset distribution.', 'In the spirit of BID36 , we showcase the effect of simple arithmetic operations in the noise space of the various models.', 'More precisely, we average the noise vector of three images of men wearing sunglasses, remove the average noise vector of three images of men not wearing sunglasses, and add the average noise vector of three images of women not wearing sunglasses.', 'The resulting image resembles a woman wearing sunglasses glasses, as shown in Figure 9 .', 'Generative Adversarial Networks.', 'GANs were introduced by BID15 , and refined in multiple recent works BID11 BID36 BID47 BID37 .', 'As described in Section 1, GANs construct a generative model of a probability distribution P by setting up an adversarial game between a generator g and a discriminator d: DISPLAYFORM0 In practice, most of the applications of GANs concern modeling distributions of natural images.', 'In these cases, both the generator g and the discriminator d are parametrized as deep convnets BID24 .', 'Among the multiple architectural variations explored in the literature, the most prominent is the Deep Convolutional Generative Adversarial Network (DCGAN) BID36 .', 'Therefore, in this paper we will use the specification of the generator function of the DCGAN to construct the generator of GLO across all of our experiments.', 'Autoencoders.', 'In their simplest form, an Auto-Encoder (AE) is a pair of neural networks, formed by an encoder f : X → Z and a decoder g : Z → X .', 'The role of an autoencoder is the compress the data {x 1 , . . .', ', x N } into the representation {z 1 , . . .', ', z N } using the encoder f (x i ), and decompress it using the decoder g(f (x i )).', 'Therefore, autoencoders minimize E x∼P (g(f (x)), x), where : X ×X is a simple loss function, such as the mean squared error.', 'There is a vast literature on autoencoders, spanning three decades from their conception BID6 BID1 , renaissance BID16 , and recent probabilistic extensions BID43 BID21 .Several works have combined GANs with AEs.', 'For instance, BID47 replace the discriminator of a GAN by an AE, and BID42 replace the decoder of an AE by a generator of a GAN.', 'Similar to GLO, these works suggest that the combination of standard pipelines can lead to good generative models.', 'In this work we attempt one step further, to explore if learning a generator alone is possible.', 'Inverting generators.', 'Several works attempt at recovering the latent representation of an image with respect to a generator.', 'In particular, BID28 ; BID48 show that it is possible to recover z from a generated sample.', 'Similarly, BID10 show that it is possible to learn the inverse transformation of a generator.', 'These works are similar to BID45 , where the gradients of a particular feature of a convnet are back-propagated to the pixel space in order to visualize what that feature stands for.', 'From a theoretical perspective, BID7 explore the theoretical conditions for a network to be invertible.', 'All of these inverting efforts are instances of the pre-image problem, BID22 .', 'BID4 have recently showed that it is possible to recover from a trained generator with compressed sensing.', 'Similar to our work, they use a 2 loss and backpropagate the gradient to the low rank distribution.', 'However, they do not train the generator simultaneously.', 'Jointly learning the representation and training the generator allows us to extend their findings.', 'BID38 also use generative models to compress images.1st eigenvector 2nd eigenvector 4th eigenvector 9th eigenvector Figure 8 : Illustration of the variation around principal components of the GLO latent space on the CelebA 128 × 128 dataset.', 'The original image is in the middle and we move along a eigenvector in both directions.', 'We illustrate this process with the first 2 components as well as some later ones.', 'Several works have used an optimization of a latent representation for the express purpose of generating realistic images, e.g. BID34 BID32 .', 'In these works, the total loss function optimized to generate is trained separately from the optimization of the latent representation (in the former, the loss is based on a complex wavelet transform, and in the latter, on separately trained autoencoders and classification convolutional networks).', 'In this work we train the latent representations and the generator together from scratch; and show that at test time we may sample new latent z either with simple parametric distributions or by interpolation in the latent space.', 'Learning representations.', 'Arguably, the problem of learning representations from data in an unsupervised manner is one of the long-standing problems in machine learning BID2 BID25 .', 'One of the earliest algorithms used to achieve is goal is Principal Component Analysis, or PCA BID33 BID19 .', 'For instance, PCA has been used to learn low-dimensional representations of human faces BID41 , or to produce a hierarchy of features BID8 .', 'The nonlinear extension of PCA is an autoencoder BID1 , which is in turn one of the most extended algorithms to learn low-dimensional representations from data.', 'Similar algorithms learn low-dimensional representations of data with certain structure.', 'For instance, in sparse coding BID0 BID30 , the representation of one image is the linear combination of a very few elements from a dictionary of features.', 'More recently, BID46 realized the capability of deep neural networks to map large collections of images to noise vectors, and Bojanowski and Joulin (2017) exploited a similar procedure to learn visual features unsupervisedly.', 'Similarly to us, BID3 allow the noise vectors z to move in order to better learn the mapping from images to noise vectors.', 'The proposed GLO is the analogous to these works, in the opposite direction: learn a map from noise vectors to images.', 'Finally, the idea of mapping between images and noise to learn generative models is a well known technique BID9 BID23 BID39 BID5 .Nuisance Variables One might consider the generator parameters the variables of interest, and Z to be \"nuisance variables\".', 'There is a classical literature on dealing with nuisance parameters while estimating the parameters of interest, including optimization methods as we have used BID40 .', 'In this framing, it may be better to marginalize over the nuisance variables, but for the models and data we use this is intractable.', 'PCA VAE with Lap 1 GLO with Lap 1 Figure 9 : Illustration of feature arithmetic on CelebA. We show that by taking the average hidden representation of row a, substracting the one of row b and adding the one of row c, we obtain a coherent image.', 'We show such interpolations with PCA, VAE and GLO.Speech generation Optimizing a latent representation of a generative model has a long history in speech BID35 , both for fitting single examples in the context of fitting a generative model, and in the context of speaker adaptation.', 'The experimental results presented in this work suggest that, in the image domain, we can recover many of the properties of GAN models by using convnets trained with simple reconstruction losses.', 'While this does not invalidate the promise of GANs as generic models of uncertainty or as methods for building generative models, our results suggest that, in order to more fully test the adversarial construction, research needs to move beyond images and convnets.', 'On the other hand, practitioners who care only about generating images for a particular application, and find that the parameterized discriminator does improve their results can use reconstruction losses in their model searches, alleviating some of the instability of GAN training.', 'While the visual quality of the results are promising, especially on the CelebA dataset, they are not yet to the level of the results obtained by GANs on the LSUN bedrooms.', 'This suggest several research directions: one possibility, suggested by 3, is that being able to cover the entire dataset is too onerous a task if all that is required is to generate a few nice samples.', 'In that figure we see that GANs have trouble reconstructing randomly chosen images at the same level of fidelity as their generations.', 'However, GANs can produce good images after a single pass through the data with SGD.', 'In future work we hope to better understand the tension between these two observations.', 'There are many possibilities for improving the quality of GLO samples beyond understanding the effects of coverage.', 'For example other loss functions (e.g. a VGG metric, as in BID32 ), model architectures (here we stayed close to DCGAN for ease of comparison), and more sophisticated sampling methods after training the model all may improve the visual quality of the samples.', 'There is also much work to be done in adding structure to the Z space.', 'Because the methods here keep track of the correspondence between samples and their representatives, and because the Z space is free, we hope to be able to organize the Z in interesting ways as we train.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = clean_data['source'][1]\n",
        "for i in range(len(a)):\n",
        "  if '(A1)' in a[i]:\n",
        "    print(i)\n",
        "    print(a[i])"
      ],
      "metadata": {
        "id": "ASndaJTox2Z3",
        "outputId": "adc01ae0-c279-4212-d8d5-dd8aa2ded0b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n",
            "Therefore, it is reasonable to hypothesize that the reasons for the success of GANs in modeling natural images come from two complementary sources: (A1) Leveraging the powerful inductive bias of deep convnets. (A2) The adversarial training protocol.\n",
            "33\n",
            "This work attempts to disentangle the factors of success (A1) and (A2) in GAN models.\n",
            "34\n",
            "Specifically, we propose and study one algorithm that relies on (A1) and avoids (A2), but still obtains competitive results when compared to a GAN.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"Therefore, it is reasonable to hypothesize that the reasons for the success of GANs in modeling natural images come from two complementary sources: (A1) Leveraging the powerful inductive bias of deep convnets.\" in clean_data['source'][1]"
      ],
      "metadata": {
        "id": "jQbsL-mFw421",
        "outputId": "bd2c6e4f-b2a6-41d4-e6dd-2251675de312",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data['number_words_extractive'] = count_words(clean_data, 'extractive_summary')\n",
        "\n",
        "clean_data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "kHvWaPYNiGvW",
        "outputId": "0436ac12-d567-49fe-c5e3-ce3e244b6e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       number_words_target  number_words_extractive\n",
              "count          1312.000000              1312.000000\n",
              "mean             58.935213               621.176067\n",
              "std              20.402388               143.951058\n",
              "min              30.000000               126.000000\n",
              "25%              41.000000               534.000000\n",
              "50%              58.000000               611.000000\n",
              "75%              73.000000               693.000000\n",
              "max             149.000000              1199.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37dfa2d6-ce6f-4487-8e00-3b28625226d8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number_words_target</th>\n",
              "      <th>number_words_extractive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1312.000000</td>\n",
              "      <td>1312.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>58.935213</td>\n",
              "      <td>621.176067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>20.402388</td>\n",
              "      <td>143.951058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>30.000000</td>\n",
              "      <td>126.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>41.000000</td>\n",
              "      <td>534.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>58.000000</td>\n",
              "      <td>611.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>73.000000</td>\n",
              "      <td>693.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>149.000000</td>\n",
              "      <td>1199.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37dfa2d6-ce6f-4487-8e00-3b28625226d8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-37dfa2d6-ce6f-4487-8e00-3b28625226d8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-37dfa2d6-ce6f-4487-8e00-3b28625226d8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ed8e51e6-c293-4acd-bb58-680e38dc408b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ed8e51e6-c293-4acd-bb58-680e38dc408b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ed8e51e6-c293-4acd-bb58-680e38dc408b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 1\n",
        "print(clean_data['source'][i])\n",
        "print(clean_data['target'][i])\n",
        "print(clean_data['extractive_summary'][i])\n",
        "print(clean_data['number_words_extractive'][i])\n",
        "print(clean_data['number_words_extractive'][i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7Q_PWBPjjCu",
        "outputId": "8f53d6a3-e05e-452d-e566-b97e6e13125b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Generative Adversarial Networks (GANs) have achieved remarkable results in the task of generating realistic natural images.', 'In most applications, GAN models share two aspects in common.', 'On the one hand, GANs training involves solving a challenging saddle point optimization problem, interpreted as an adversarial game between a generator and a discriminator functions.', 'On the other hand, the generator and the discriminator are parametrized in terms of deep convolutional neural networks.', 'The goal of this paper is to disentangle the contribution of these two factors to the success of GANs.', 'In particular, we introduce Generative Latent Optimization (GLO), a framework to train deep convolutional generators without using discriminators, thus avoiding the instability of adversarial optimization problems.', 'Throughout a variety of experiments, we show that GLO enjoys many of the desirable properties of GANs: learning from large data, synthesizing visually-appealing samples, interpolating meaningfully between samples, and performing linear arithmetic with noise vectors.', 'Generative Adversarial Networks (GANs) BID15 are a powerful framework to learn generative models of natural images.', 'GANs learn these generative models by setting up an adversarial game between two learning machines.', 'On the one hand, a generator plays to transform noise vectors into fake samples, which resemble real samples drawn from a distribution of natural images.', 'On the other hand, a discriminator plays to distinguish between real and fake samples.', 'During training, the generator and the discriminator learn in turns.', 'First, the discriminator learns to assign high scores to real samples, and low scores to fake samples.', 'Then, the generator learns to increase the scores of fake samples, as to fool the discriminator.', 'After proper training, the generator is able to produce realistic natural images from noise vectors.', 'Recently, GANs have been used to produce high-quality images resembling handwritten digits, human faces, and house interiors BID36 .', 'Furthermore, GANs exhibit three strong signs of generalization.', 'First, the generator translates linear interpolations in the noise space into semantic interpolations in the image space.', 'In other words, a linear interpolation in the noise space will generate a smooth interpolation of visually-appealing images.', 'Second, the generator allows linear arithmetic in the noise space.', 'Similarly to word embeddings BID31 , linear arithmetic indicates that the generator organizes the noise space to disentangle the nonlinear factors of variation of natural images into linear statistics.', 'Third, the generator is able to to synthesize new images that resemble those of the data distribution.', 'This allows for applications such as image in-painting BID18 and super-resolution BID26 .Despite their success, training and evaluating GANs is notoriously difficult.', 'The adversarial optimization problem implemented by GANs is sensitive to random initialization, architectural choices, and hyper-parameter settings.', 'In many cases, a fair amount of human care is necessary to find the correct configuration to train a GAN in a particular dataset.', 'It is common to observe generators with similar architectures and hyper-parameters to exhibit dramatically different behaviors.', 'Even when properly trained, the resulting generator may synthesize samples that resemble only a few localized regions (or modes) of the data distribution BID14 .', 'While several advances have been made to stabilize the training of GANs BID37 , this task remains more art than science.', 'The difficulty of training GANs is aggravated by the challenges in their evaluation: since evaluating the likelihood of a GAN with respect to the data is an intractable problem, the current gold standard to evaluate the quality of GANs is to eyeball the samples produced by the generator.', 'The evaluation of discriminators is also difficult, since their visual features do not always transfer well to supervised tasks BID12 BID13 .', 'Finally, the application of GANs to non-image data has been relatively limited.', 'Research question To model natural images with GANs, the generator and discriminator are commonly parametrized as deep Convolutional Networks (convnets) BID24 .', 'Therefore, it is reasonable to hypothesize that the reasons for the success of GANs in modeling natural images come from two complementary sources: (A1) Leveraging the powerful inductive bias of deep convnets. (A2) The adversarial training protocol.', 'This work attempts to disentangle the factors of success (A1) and (A2) in GAN models.', 'Specifically, we propose and study one algorithm that relies on (A1) and avoids (A2), but still obtains competitive results when compared to a GAN.', 'We investigate the importance of the inductive bias of convnets by removing the adversarial training protocol of GANs (Section 2).', 'Our approach, called Generative Latent Optimization (GLO), maps one learnable noise vector to each of the images in our dataset by minimizing a simple reconstruction loss.', 'Since we are predicting images from learnable noise, GLO borrows inspiration from recent methods to predict learnable noise from images BID3 .', 'Alternatively, one can understand GLO as an auto-encoder where the latent representation is not produced by a parametric encoder, but learned freely in a non-parametric manner.', 'In contrast to GANs, we track of the correspondence between each learned noise vector and the image that it represents.', 'Hence, the goal of GLO is to find a meaningful organization of the noise vectors, such that they can be mapped to their target images.', 'To turn GLO into a generative model, we observe that it suffices to learn a simple probability distribution on the learned noise vectors.', 'In our experiments (Section 3), we show that GLO inherits many of the appealing features of GANs, while enjoying a much simpler training protocol.', 'In particular, we study the efficacy of GLO to compress and decompress a dataset of images (Section 3.3.1), generate new samples (Section 3.3.2), perform linear interpolations and extrapolations in the noise space (Section 3.3.3), and perform linear arithmetics (Section 3.3.5).', 'Our experiments provide quantitative and qualitative comparisons to Principal Component Analysis (PCA), Variational Autoencoders (VAE) and GANs.', 'We focus on the CelebA and LSUN-Bedroom datasets.', 'We conclude our exposition in Section 5.', 'First, we consider a large set of images {x 1 , . . .', ', x N }, where each image x i ∈ X has dimensions 3 × w×h.', 'Second, we initialize a set of d-dimensional random vectors {z 1 , . . .', ', z N }, where z i ∈ Z ⊆ R d for all i = 1, . . .', 'N .', 'Third, we pair the dataset of images with the random vectors, obtaining the dataset {(z 1 , x 1 ), . . .', ', (z N , x N )}.', 'Finally, we jointly learn the parameters θ in Θ of a generator g θ : Z → X and the optimal noise vector z i for each image x i , by solving: DISPLAYFORM0 In the previous, : X × X is a loss function measuring the reconstruction error from g(z i ) to x i .', 'We call this model Generative Latent Optimization (GLO).Learnable z i .', 'In contrast to autoencoders BID6 , which assume a parametric model f : X → Z, usually referred to as the encoder, to compute the vector z from samples x, and minimize the reconstruction loss (g(f (x)), x), in GLO we jointly optimize the inputs z 1 , . . .', ', z N and the model parameter θ.', 'Since the vector z is a free parameter, our model can recover all the solutions that could be found by an autoencoder, and reach some others.', 'In a nutshell, GLO can be viewed as an \"encoder-less\" autoencoder, or as a \"discriminator-less\" GAN.', 'Figure 1: Plot of the cumulative sum of the singular values of the optimal Z * matrix.', 'We observe that the proposed GLO model has a better conditioned covariance matrix and therefore better fills the latent space.', 'Choice of Z. The representation space Z should encapsulate all of our prior knowledge about the data {x 1 , . . .', ', x N }.', 'Since we are interested in matching the properties of GANs, we make similar choices to them when it comes to the representation space Z.', 'The most common choices of the representation space for GANs are either the uniform distribution on the hypercube DISPLAYFORM1 In previous literature, Gaussian distributions lead to more stable GAN training BID36 , we will take this choice to design our representation space.', 'In GLO, the random vectors z are learnable and can therefore attain any value during the training process.', 'To avoid extremely large values, we normalize our learnable noise vectors z at all times, to lay on the unit 2 sphere.', 'Choice of loss function.', 'On the one hand, the squared-loss function 2 (x, x ) = x − x 2 2 is a simple choice, but leads to blurry (average) reconstructions of natural images.', 'On the other hand, GANs use a convnet (the discriminator) as loss function.', 'Since the early layers of convnets focus on edges, the samples from a GAN are sharper.', 'Therefore, our experiments provide quantitative and qualitative comparisons between the 2 loss and the Laplacian pyramid Lap 1 loss DISPLAYFORM2 where L j (x) is the j-th level of the Laplacian pyramid representation of x BID27 .', 'Therefore, the Lap 1 loss weights the details at fine scales more heavily.', 'In order to low-frequency content such as color information, we will use a weighted combination of the Lap 1 and the 2 costs.', 'Optimization.', 'For any choice of differentiable generator, the objective (1) is differentiable with respect to z, and θ.', 'Therefore, we will learn z and θ by Stochastic Gradient Descent (SGD).', 'The gradient of (1) with respect to z can be obtained by backpropagating the gradients through the generator function BID4 .', 'We project each z back to the representation space Z after each update.', 'To have noise vectors laying on the unit 2 sphere, we project z after each update by dividing its value by max( z 2 , 1).', 'We initialize the z by either sampling them from a gaussian distribution or by taking the whitened PCA of the raw image pixels.', 'We organized our experiments as follows.', 'First, Section 3.1 describes the generative models that we compare, along with their implementation details.', 'Section 3.2 reviews the image datasets used in our experiments.', 'Section 3.3 discusses the results of our experiments, including the compression of datasets (Section 3.3.1), the generation (Section 3.3.2) and interpolation (Section 3.3.3) of samples, and the results of arithmetic operations with noise vectors (Section 3.3.5).', 'First, PCA BID33 , equivalent to a linear autoencoder BID1 , where we retain the top 256 principal components.', 'Second, DCGAN BID36 .', 'Since GANs do not come with a mechanism (inverse generator) to retrieve the random vector g −1 (x) associated with an image x, we estimate this random vector by 1) instantiating a random vector z 0 , and 2) computing updates DISPLAYFORM0 by backpropagation until convergence, where is either the 2 or the Lap 1 loss.', 'Our experiments measuring reconstruction error are disadvantageous to GANs, since these are models that are not trained to minimize this metric.', 'We use the Adam optimizer BID20 with the parameters from BID36 Table 1 : Reconstruction errors in MSE.', 'We consider methods using both MSE and Lap 1 loss.', 'We also specify the initialization method between random and PCA.Third, VAE BID21 .', 'We train a VAE with the same encoder and decoder architectures as DCGAN.', 'We train it with the default hyper-parameters for 25 epochs.', 'Third, GLO (proposed model).', 'We will train a GLO model where the generator follows the same architecture as the generator in DCGAN.', 'We use Stochastic Gradient Descent (SGD) to optimize both θ and z, setting the learning rate for θ at 1 and the learning rate of z at 10.', 'After each udpdate, the noise vectors z are projected to the unit 2 sphere.', 'In the sequel, we initialize the random vectors of GLO using a Gaussian distribution (for the CelebA dataset) or the top d principal components (for the LSUN dataset).', 'We evaluate all models on two datasets of natural images.', 'Unless specified otherwise, we use the prescribed training splits to train our generative models.', 'All the images are rescaled to have three channels, center-cropped, and normalized to pixel values in [−1, +1].First, CelebA BID29 is a set of 202, 599 portraits of celebrities.', 'We use the aligned and cropped version, scaled to 128 × 128 pixels.', 'Second, LSUN BID44 ) is a set of millions of images of scenes belonging to different scene categories.', 'Following the tradition in GAN papers BID36 , we use the 3, 033, 042 images belonging to the bedroom category.', 'We resize the images to 64 × 64 pixels.', 'We compare the methods described on Section 3.1 when applied to the datasets described on Section 3.2.', 'In particular, we evaluate the performance of the methods in the tasks of compressing a dataset, generating new samples, performing sample interpolation, and doing sample arithmetic.', 'We start by measuring the reconstruction error in terms of the mean-squared loss 2 (x, x ) = x−x 2 2 and the Lap 1 loss (2) Table 1 shows the reconstruction error of all models and datasets for the 2 .', 'This gives a rough idea about the coverage of each model over the dataset.', 'Figure 1 show the quantity of the representation space explained as a function of the number of eigenvectors used to reconstruct it.', 'GLO trained from a random initialization is more aggressive about using the full representation space to spread the information around while PCA or autoencoders tend to concentrate the information in a few directions.', 'For completeness, we computed image reconstructions for the various models on a held-out set of images.', 'To this end we use face images from deep funneled images from Labeled Faces in the Wild BID17 .', 'In order to make the images similar to those found in CelebA we crop the images so as to align the location of eyes.', 'The reconstructions of a random sample of images are presented in Fig. 10 .', 'Figure 4 shows samples from the each of the models on the CelebA dataset, and Figure 5 shows the same fro the LSUN dataset.', 'In the case of GLO, we fit a Gaussian distribution with full covariance to the representation space Z, and sample from such distribution to generate new samples.', 'We can see that the samples are visually appealing even when placing such a simple probabilistic model on the representation space.', 'We leave more careful modeling of Z for future work.', 'The latent space can be explored by decomposing the covariance matrix of the latent vectors and moving along the eigenvectors associated with the largest eigenvalues from an image.', 'The resulting image transformation often contains information about attributes that varies in the dataset.', 'Figure 8 show some examples of image deformation along the principal axes.', 'The image in the middle is the original image.', 'Moving in either direction along an axis produces the images on its left and its right.', 'We see that the main axes seem to contain information about standard face attributes.', 'For example, the 4th component seems to be capturing information about facial expression while the 9th one seems to be capturing information about the age.', 'In absence of supervision, some directions make several attributes move simultaneously, for example smiling seems correlated with the hair color.', 'These correlations are artifacts of the CelebA dataset distribution.', 'In the spirit of BID36 , we showcase the effect of simple arithmetic operations in the noise space of the various models.', 'More precisely, we average the noise vector of three images of men wearing sunglasses, remove the average noise vector of three images of men not wearing sunglasses, and add the average noise vector of three images of women not wearing sunglasses.', 'The resulting image resembles a woman wearing sunglasses glasses, as shown in Figure 9 .', 'Generative Adversarial Networks.', 'GANs were introduced by BID15 , and refined in multiple recent works BID11 BID36 BID47 BID37 .', 'As described in Section 1, GANs construct a generative model of a probability distribution P by setting up an adversarial game between a generator g and a discriminator d: DISPLAYFORM0 In practice, most of the applications of GANs concern modeling distributions of natural images.', 'In these cases, both the generator g and the discriminator d are parametrized as deep convnets BID24 .', 'Among the multiple architectural variations explored in the literature, the most prominent is the Deep Convolutional Generative Adversarial Network (DCGAN) BID36 .', 'Therefore, in this paper we will use the specification of the generator function of the DCGAN to construct the generator of GLO across all of our experiments.', 'Autoencoders.', 'In their simplest form, an Auto-Encoder (AE) is a pair of neural networks, formed by an encoder f : X → Z and a decoder g : Z → X .', 'The role of an autoencoder is the compress the data {x 1 , . . .', ', x N } into the representation {z 1 , . . .', ', z N } using the encoder f (x i ), and decompress it using the decoder g(f (x i )).', 'Therefore, autoencoders minimize E x∼P (g(f (x)), x), where : X ×X is a simple loss function, such as the mean squared error.', 'There is a vast literature on autoencoders, spanning three decades from their conception BID6 BID1 , renaissance BID16 , and recent probabilistic extensions BID43 BID21 .Several works have combined GANs with AEs.', 'For instance, BID47 replace the discriminator of a GAN by an AE, and BID42 replace the decoder of an AE by a generator of a GAN.', 'Similar to GLO, these works suggest that the combination of standard pipelines can lead to good generative models.', 'In this work we attempt one step further, to explore if learning a generator alone is possible.', 'Inverting generators.', 'Several works attempt at recovering the latent representation of an image with respect to a generator.', 'In particular, BID28 ; BID48 show that it is possible to recover z from a generated sample.', 'Similarly, BID10 show that it is possible to learn the inverse transformation of a generator.', 'These works are similar to BID45 , where the gradients of a particular feature of a convnet are back-propagated to the pixel space in order to visualize what that feature stands for.', 'From a theoretical perspective, BID7 explore the theoretical conditions for a network to be invertible.', 'All of these inverting efforts are instances of the pre-image problem, BID22 .', 'BID4 have recently showed that it is possible to recover from a trained generator with compressed sensing.', 'Similar to our work, they use a 2 loss and backpropagate the gradient to the low rank distribution.', 'However, they do not train the generator simultaneously.', 'Jointly learning the representation and training the generator allows us to extend their findings.', 'BID38 also use generative models to compress images.1st eigenvector 2nd eigenvector 4th eigenvector 9th eigenvector Figure 8 : Illustration of the variation around principal components of the GLO latent space on the CelebA 128 × 128 dataset.', 'The original image is in the middle and we move along a eigenvector in both directions.', 'We illustrate this process with the first 2 components as well as some later ones.', 'Several works have used an optimization of a latent representation for the express purpose of generating realistic images, e.g. BID34 BID32 .', 'In these works, the total loss function optimized to generate is trained separately from the optimization of the latent representation (in the former, the loss is based on a complex wavelet transform, and in the latter, on separately trained autoencoders and classification convolutional networks).', 'In this work we train the latent representations and the generator together from scratch; and show that at test time we may sample new latent z either with simple parametric distributions or by interpolation in the latent space.', 'Learning representations.', 'Arguably, the problem of learning representations from data in an unsupervised manner is one of the long-standing problems in machine learning BID2 BID25 .', 'One of the earliest algorithms used to achieve is goal is Principal Component Analysis, or PCA BID33 BID19 .', 'For instance, PCA has been used to learn low-dimensional representations of human faces BID41 , or to produce a hierarchy of features BID8 .', 'The nonlinear extension of PCA is an autoencoder BID1 , which is in turn one of the most extended algorithms to learn low-dimensional representations from data.', 'Similar algorithms learn low-dimensional representations of data with certain structure.', 'For instance, in sparse coding BID0 BID30 , the representation of one image is the linear combination of a very few elements from a dictionary of features.', 'More recently, BID46 realized the capability of deep neural networks to map large collections of images to noise vectors, and Bojanowski and Joulin (2017) exploited a similar procedure to learn visual features unsupervisedly.', 'Similarly to us, BID3 allow the noise vectors z to move in order to better learn the mapping from images to noise vectors.', 'The proposed GLO is the analogous to these works, in the opposite direction: learn a map from noise vectors to images.', 'Finally, the idea of mapping between images and noise to learn generative models is a well known technique BID9 BID23 BID39 BID5 .Nuisance Variables One might consider the generator parameters the variables of interest, and Z to be \"nuisance variables\".', 'There is a classical literature on dealing with nuisance parameters while estimating the parameters of interest, including optimization methods as we have used BID40 .', 'In this framing, it may be better to marginalize over the nuisance variables, but for the models and data we use this is intractable.', 'PCA VAE with Lap 1 GLO with Lap 1 Figure 9 : Illustration of feature arithmetic on CelebA. We show that by taking the average hidden representation of row a, substracting the one of row b and adding the one of row c, we obtain a coherent image.', 'We show such interpolations with PCA, VAE and GLO.Speech generation Optimizing a latent representation of a generative model has a long history in speech BID35 , both for fitting single examples in the context of fitting a generative model, and in the context of speaker adaptation.', 'The experimental results presented in this work suggest that, in the image domain, we can recover many of the properties of GAN models by using convnets trained with simple reconstruction losses.', 'While this does not invalidate the promise of GANs as generic models of uncertainty or as methods for building generative models, our results suggest that, in order to more fully test the adversarial construction, research needs to move beyond images and convnets.', 'On the other hand, practitioners who care only about generating images for a particular application, and find that the parameterized discriminator does improve their results can use reconstruction losses in their model searches, alleviating some of the instability of GAN training.', 'While the visual quality of the results are promising, especially on the CelebA dataset, they are not yet to the level of the results obtained by GANs on the LSUN bedrooms.', 'This suggest several research directions: one possibility, suggested by 3, is that being able to cover the entire dataset is too onerous a task if all that is required is to generate a few nice samples.', 'In that figure we see that GANs have trouble reconstructing randomly chosen images at the same level of fidelity as their generations.', 'However, GANs can produce good images after a single pass through the data with SGD.', 'In future work we hope to better understand the tension between these two observations.', 'There are many possibilities for improving the quality of GLO samples beyond understanding the effects of coverage.', 'For example other loss functions (e.g. a VGG metric, as in BID32 ), model architectures (here we stayed close to DCGAN for ease of comparison), and more sophisticated sampling methods after training the model all may improve the visual quality of the samples.', 'There is also much work to be done in adding structure to the Z space.', 'Because the methods here keep track of the correspondence between samples and their representatives, and because the Z space is free, we hope to be able to organize the Z in interesting ways as we train.']\n",
            "Are GANs successful because of adversarial training or the use of ConvNets? We show a ConvNet generator trained with a simple reconstruction loss and learnable noise vectors leads many of the desirable properties of a  GAN.\n",
            "The experimental results presented in this work suggest that, in the image domain, we can recover many of the properties of GAN models by using convnets trained with simple reconstruction losses. Therefore, it is reasonable to hypothesize that the reasons for the success of GANs in modeling natural images come from two complementary sources: (A1) Leveraging the powerful inductive bias of deep convnets. (A2) The adversarial training protocol. While this does not invalidate the promise of GANs as generic models of uncertainty or as methods for building generative models, our results suggest that, in order to more fully test the adversarial construction, research needs to move beyond images and convnets. The most common choices of the representation space for GANs are either the uniform distribution on the hypercube DISPLAYFORM1 In previous literature, Gaussian distributions lead to more stable GAN training BID36 , we will take this choice to design our representation space. Since the early layers of convnets focus on edges, the samples from a GAN are sharper. In the case of GLO, we fit a Gaussian distribution with full covariance to the representation space Z, and sample from such distribution to generate new samples. There is a classical literature on dealing with nuisance parameters while estimating the parameters of interest, including optimization methods as we have used BID40 . In the sequel, we initialize the random vectors of GLO using a Gaussian distribution (for the CelebA dataset) or the top d principal components (for the LSUN dataset). In these works, the total loss function optimized to generate is trained separately from the optimization of the latent representation (in the former, the loss is based on a complex wavelet transform, and in the latter, on separately trained autoencoders and classification convolutional networks). On the one hand, a generator plays to transform noise vectors into fake samples, which resemble real samples drawn from a distribution of natural images. On the other hand, practitioners who care only about generating images for a particular application, and find that the parameterized discriminator does improve their results can use reconstruction losses in their model searches, alleviating some of the instability of GAN training. To turn GLO into a generative model, we observe that it suffices to learn a simple probability distribution on the learned noise vectors. Similarly to word embeddings BID31 , linear arithmetic indicates that the generator organizes the noise space to disentangle the nonlinear factors of variation of natural images into linear statistics. On the other hand, a discriminator plays to distinguish between real and fake samples. Our approach, called Generative Latent Optimization (GLO), maps one learnable noise vector to each of the images in our dataset by minimizing a simple reconstruction loss. For example other loss functions (e.g. a VGG metric, as in BID32 ), model architectures (here we stayed close to DCGAN for ease of comparison), and more sophisticated sampling methods after training the model all may improve the visual quality of the samples.\n",
            "493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'summarize_text' is a string\n",
        "summarize_text = \"This is the first sentence. This is the second sentence. And this is the third sentence.\"\n",
        "\n",
        "# Split the string into a list of sentences\n",
        "list_of_sentences = sent_tokenize(summarize_text)\n",
        "\n",
        "# Print the result\n",
        "print(list_of_sentences)"
      ],
      "metadata": {
        "id": "xAC4SdvPvfaj",
        "outputId": "6a9a638c-6da3-4551-eb94-8cce896fd185",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This is the first sentence.', 'This is the second sentence.', 'And this is the third sentence.']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMu0mjC+Cwz2btFKRhM05sN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}