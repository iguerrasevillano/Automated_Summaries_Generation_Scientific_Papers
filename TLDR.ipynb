{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iguerrasevillano/Automated_Summaries_Generation_Scientific_Papers/blob/clean_version/TLDR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Requirements"
      ],
      "metadata": {
        "id": "FEZEiEhlnp8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install rouge_score\n",
        "!pip install huggingface_hub\n",
        "!pip install tensorflow==2.15.0\n",
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DCyyzSCaF2VU",
        "outputId": "4c7d23b8-83c2-45b8-8b41-628e7def90d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.23.5)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.2)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=38907ac23206751ea0c93e88cb26898a9364264037ee55945b7a4c262ff95e15\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n",
            "Collecting tensorflow==2.15.0\n",
            "  Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.3.7)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.62.1)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.0)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.0)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.16,>=2.15.0 (from tensorflow==2.15.0)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.27.0)\n",
            "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, keras, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 0.4.6\n",
            "    Uninstalling google-auth-oauthlib-0.4.6:\n",
            "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.0\n",
            "    Uninstalling tensorboard-2.12.0:\n",
            "      Successfully uninstalled tensorboard-2.12.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "Successfully installed google-auth-oauthlib-1.2.0 keras-2.15.0 tensorboard-2.15.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              },
              "id": "96580c1ebf5f4c3ab71cbce8d9e29005"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3108, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2901, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 441, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 572, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2821, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3110, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3120, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3173, in __init__\n",
            "    super(Requirement, self).__init__(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 102, in __init__\n",
            "    req = REQUIREMENT.parseString(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n",
            "    loc, tokens = self._parse(instring, 0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4959, in parseImpl\n",
            "    loc, tokens = self_expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 5226, in parseImpl\n",
            "    return super().parseImpl(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 776, in _parseNoCache\n",
            "    def _parseNoCache(\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1622, in _log\n",
            "    record = self.makeRecord(self.name, level, fn, lno, msg, args,\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1591, in makeRecord\n",
            "    rv = _logRecordFactory(name, level, fn, lno, msg, args, exc_info, func,\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 332, in __init__\n",
            "    self.threadName = threading.current_thread().name\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1137, in name\n",
            "    assert self._initialized, \"Thread.__init__() not called\"\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "nU-ExPlO1I2n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234,
          "referenced_widgets": [
            "919460898d50479dbacfd6b154432db2",
            "ea0db1df40844b81926b993f912d3541",
            "e43e0ce08f1e418893c90058d1d2fd6b",
            "376b1761f5ed497482f4ee5f67ad0556",
            "c1c512568fff4e17866a21a789a54bf0",
            "c22a9d0db20343a084fa0eaf11f31bb9",
            "522f6171ad5e4b3bb765f7e60fae426d",
            "94ab1479d9454e0b96125e141a2a7242",
            "d3a531e9408a4346a9be5ba5d0e2a20f",
            "d036d181946742c2878211e72e694b9d",
            "4c5960b058154637abcb228b4edf1aec"
          ]
        },
        "id": "x7-Ua4kJJ-I_",
        "outputId": "05df8a54-bd29-4e28-f689-bb19c8302e18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "<ipython-input-1-d54cd7d9c1fe>:37: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric('rouge', seed=42) #It is not deterministic\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "919460898d50479dbacfd6b154432db2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# LIBRARIES\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.callbacks import History\n",
        "\n",
        "# Transformers\n",
        "from datasets import Dataset, DatasetDict, load_metric\n",
        "from transformers import BartTokenizer, T5Tokenizer, pipeline, TFT5ForConditionalGeneration\n",
        "from transformers import TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
        "from transformers import AdamWeightDecay\n",
        "from transformers.keras_callbacks import KerasMetricCallback\n",
        "from transformers import PushToHubCallback\n",
        "\n",
        "# NLTK\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# AST\n",
        "import ast\n",
        "\n",
        "# Metrics\n",
        "metric = load_metric('rouge', seed=42) #It is not deterministic\n",
        "\n",
        "# Current directory\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logins, Paths and Auxiliar Functions"
      ],
      "metadata": {
        "id": "PJRJURyg1Spt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlyJWKdLJ_JN",
        "outputId": "fa3a8b21-4040-492a-9352-00ba6e3d521b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# Connect w/ Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# PATHS\n",
        "BASE_PATH = '/content/drive/MyDrive/VIU/TFM/Desarrollo/'\n",
        "\n",
        "documents = os.listdir(BASE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOo2flUzaIGG"
      },
      "outputs": [],
      "source": [
        "# AUXILIAR FUNCTIONS\n",
        "\n",
        "# Function to convert strings to lists\n",
        "def convert_to_list(cell):\n",
        "    try:\n",
        "        return ast.literal_eval(cell)\n",
        "    except (SyntaxError, ValueError):\n",
        "        return cell\n",
        "\n",
        "\n",
        "\n",
        "# Function to join all the sentences of input document\n",
        "def clean_data(data, column):\n",
        "  data[column] = data[column].apply(lambda x : ' '.join(x))\n",
        "  return data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define the metric to use (ROUGE Scores)\n",
        "def metric_fn(eval_predictions):\n",
        "  predictions, labels = eval_predictions\n",
        "\n",
        "  for prediction in predictions:\n",
        "      prediction[prediction < 0] = tokenizer.pad_token_id  # Replace masked prediction tokens\n",
        "\n",
        "  decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "\n",
        "  for label in labels:\n",
        "      label[label < 0] = tokenizer.pad_token_id  # Replace masked label tokens\n",
        "\n",
        "  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "  # Rouge expects a newline after each sentence\n",
        "  decoded_predictions = [\n",
        "      '\\n'.join(nltk.sent_tokenize(pred.strip())) for pred in decoded_predictions\n",
        "  ]\n",
        "  decoded_labels = [\n",
        "      '\\n'.join(nltk.sent_tokenize(label.strip())) for label in decoded_labels\n",
        "  ]\n",
        "  result = metric.compute(\n",
        "      predictions=decoded_predictions, references=decoded_labels, use_stemmer=True\n",
        "  )\n",
        "\n",
        "  # Extract a few results\n",
        "  result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "\n",
        "  # Add mean generated length\n",
        "  prediction_lens = [\n",
        "      np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions\n",
        "  ]\n",
        "  result['gen_len'] = np.mean(prediction_lens)\n",
        "\n",
        "  return result\n",
        "\n",
        "\n",
        "\n",
        "  def plot_graphics(H):\n",
        "\n",
        "    # Create a figure with 1 row and 2 columns, and set the figure size\n",
        "    fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
        "\n",
        "    # Plot the training and validation loss for each epoch in the first subplot\n",
        "    ax[0].plot(np.arange(0,len(H.history['loss']) ), H.history['loss'], 'r', label='loss')\n",
        "    ax[0].plot(np.arange(0,len(H.history['loss'])), H.history['val_loss'], 'c', label='val_loss')\n",
        "\n",
        "    ax[0].set_xlabel('epoch')\n",
        "    ax[0].set_ylabel('loss')\n",
        "\n",
        "    ax[0].legend(loc='upper right')\n",
        "\n",
        "    ax[1].plot(np.arange(0,len(H.history['loss'])), H.history['rouge1'], label='rouge1')\n",
        "    ax[1].plot(np.arange(0,len(H.history['loss'])), H.history['rouge2'], label='rouge2')\n",
        "    ax[1].plot(np.arange(0,len(H.history['loss'])), H.history['rougeL'], label='rougeL')\n",
        "    ax[1].plot(np.arange(0,len(H.history['loss'])), H.history['rougeLsum'], label='rougeLsum')\n",
        "\n",
        "    ax[1].set_xlabel('epoch')\n",
        "    ax[1].set_ylabel('score')\n",
        "    ax[1].legend()\n",
        "\n",
        "\n",
        "def substitution(text, syn, articles):\n",
        "  list_words = text.split()\n",
        "  new_list_words = []\n",
        "  for index, word in enumerate(list_words):\n",
        "    if word in articles and list_words[index+1] in syn:\n",
        "      new_list_words.append(word)\n",
        "      new_list_words.append(random.choice(syn))\n",
        "    elif word in syn and list_words[index-1] in articles:\n",
        "      continue\n",
        "    else:\n",
        "      new_list_words.append(word)\n",
        "  return ' '.join(new_list_words)\n",
        "\n",
        "\n",
        "def shuffle_list(text):\n",
        "    lst = text.split('. ')\n",
        "    lst[:-1] = [sentence + '.' for sentence in lst[:-1]]\n",
        "    random.shuffle(lst)\n",
        "    return ' '.join(lst)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess Data"
      ],
      "metadata": {
        "id": "u2-4mQ872R2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(BASE_PATH+'Data/Dev/Results/Extractive/extractive_summaries.csv')\n",
        "\n",
        "data['source'] = data['source'].apply(convert_to_list)\n",
        "data = clean_data(data, 'source')\n",
        "\n",
        "data.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "1I5H39lnQW9o",
        "outputId": "716e2e7b-5b2c-4335-e915-a6ff483e3693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 source    paper_id  \\\n",
              "411   Wasserstein GAN(WGAN) is a model that minimize...  H1ecDoR5Y7   \n",
              "8     Bayesian inference offers a theoretically grou...  Bylhq134Fr   \n",
              "1280  Training a model to perform a task typically r...  B1G9doA9F7   \n",
              "709   Semantic dependency parsing, which aims to fin...  BklS6ANFDH   \n",
              "702   Many automated machine learning methods, such ...  BJxAHgSYDB   \n",
              "\n",
              "                                                 target  \\\n",
              "411   This paper deals with stability of simple grad...   \n",
              "8     We introduce a Gaussian Process Prior over wei...   \n",
              "1280  A new cyclic adversarial learning augmented wi...   \n",
              "709   We propose an approach to semi-supervised lear...   \n",
              "702   Learn to rank learning curves in order to stop...   \n",
              "\n",
              "                                                  title  number_words_target  \\\n",
              "411   Local Stability and Performance of Simple Grad...                   43   \n",
              "8                                                   NaN                   34   \n",
              "1280  Augmented Cyclic Adversarial Learning for Low ...                   62   \n",
              "709   Semi-Supervised Semantic Dependency Parsing Us...                   44   \n",
              "702                    Learning to Rank Learning Curves                   64   \n",
              "\n",
              "                                     extractive_summary  \n",
              "411   GANs have been implemented in many application...  \n",
              "8     However, it is challenging to specify a meanin...  \n",
              "1280  One way of learning such mappings is through G...  \n",
              "709   While a lot of work has been done on supervise...  \n",
              "702   A common technique to determine the likelihood...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77a0040c-4cd0-4b07-968b-c12c5e49ee52\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>paper_id</th>\n",
              "      <th>target</th>\n",
              "      <th>title</th>\n",
              "      <th>number_words_target</th>\n",
              "      <th>extractive_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>Wasserstein GAN(WGAN) is a model that minimize...</td>\n",
              "      <td>H1ecDoR5Y7</td>\n",
              "      <td>This paper deals with stability of simple grad...</td>\n",
              "      <td>Local Stability and Performance of Simple Grad...</td>\n",
              "      <td>43</td>\n",
              "      <td>GANs have been implemented in many application...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Bayesian inference offers a theoretically grou...</td>\n",
              "      <td>Bylhq134Fr</td>\n",
              "      <td>We introduce a Gaussian Process Prior over wei...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34</td>\n",
              "      <td>However, it is challenging to specify a meanin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1280</th>\n",
              "      <td>Training a model to perform a task typically r...</td>\n",
              "      <td>B1G9doA9F7</td>\n",
              "      <td>A new cyclic adversarial learning augmented wi...</td>\n",
              "      <td>Augmented Cyclic Adversarial Learning for Low ...</td>\n",
              "      <td>62</td>\n",
              "      <td>One way of learning such mappings is through G...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>709</th>\n",
              "      <td>Semantic dependency parsing, which aims to fin...</td>\n",
              "      <td>BklS6ANFDH</td>\n",
              "      <td>We propose an approach to semi-supervised lear...</td>\n",
              "      <td>Semi-Supervised Semantic Dependency Parsing Us...</td>\n",
              "      <td>44</td>\n",
              "      <td>While a lot of work has been done on supervise...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>702</th>\n",
              "      <td>Many automated machine learning methods, such ...</td>\n",
              "      <td>BJxAHgSYDB</td>\n",
              "      <td>Learn to rank learning curves in order to stop...</td>\n",
              "      <td>Learning to Rank Learning Curves</td>\n",
              "      <td>64</td>\n",
              "      <td>A common technique to determine the likelihood...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77a0040c-4cd0-4b07-968b-c12c5e49ee52')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-77a0040c-4cd0-4b07-968b-c12c5e49ee52 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-77a0040c-4cd0-4b07-968b-c12c5e49ee52');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-45e5533e-833a-4bbf-b734-76e17d2dea74\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-45e5533e-833a-4bbf-b734-76e17d2dea74')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-45e5533e-833a-4bbf-b734-76e17d2dea74 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Bayesian inference offers a theoretically grounded and general way to train neural networks and can potentially give calibrated uncertainty. However, it is challenging to specify a meaningful and tractable prior over the network parameters, and deal with the weight correlations in the posterior. To this end, this paper introduces two innovations: (i) a Gaussian process-based hierarchical model for the network parameters based on recently introduced unit embeddings that can flexibly encode weight structures, and (ii) input-dependent contextual variables for the weight prior that can provide convenient ways to regularize the function space being modeled by the network through the use of kernels. \\n We show these models provide desirable test-time uncertainty estimates, demonstrate cases of modeling inductive biases for neural networks with kernels and demonstrate competitive predictive performance on an active learning benchmark. The question of which priors one should use for Bayesian neural networks is largely unanswered, as two considerations need to be balanced: First, we want to keep inference in the high dimensional weight posterior tractable; Second, we desire to express our beliefs about the properties of the modeled functions compactly by modeling the collection of weights. Especially the latter is typically hard, as functional regularization for weight-based models is non-trivial. In order to cope with richer posterior inference than mean-field typically achieves, a variety of structured posterior models have been proposed recently, for instance utilizing radial posteriors (Oh et al., 2019) , or rich weight posteriors based on Gaussian processes (Louizos and Welling, 2016) . When it comes to modeling priors on weights with correlations, recent work has attempted to capture feature-level correlations using for instance a horseshoe prior (Ghosh et al., 2018) . One interesting direction of inquiry has focused on utilizing hyper-networks in order to model distributions over weights for an entire network (Ha et al., 2016; Pradier et al., 2018) , or alternatively to utilize unit-level level variables combined with compact hyper-networks to regress to single weights and capture weight correlations through the auxiliary variables (Karaletsos et al., 2018) . We propose to tackle some of the challenges in modeling weight priors by extending the latter work and combining it with ideas from the Gaussian process literature to replace the hyper-network with a Gaussian process prior over weights. We explore the use of compositional kernels to add input-dependence to the prior for our model and obtain rich models with beneficial properties in tasks such as active learning, and generalization, while maintaining tractable inference properties. In (Karaletsos et al., 2018 ) each unit (visible or hidden) of the l-th layer of the network has a corresponding latent hierarchical variable z l,i , of dimensions D z , where i denotes the index of the unit in a layer. These latent variables are used to construct the weights in the network such that a weight in the l-th weight layer, w l,i,j is linked to the latent variables z's of the i-th input unit and the j-th output unit of the weight layer. We can summarize this relationship by introducing a set of weight encodings, C w (z), one for each individual weight, c w l,i,j = z l+1,i , z l,j . The probabilistic description of the relationship between the weight codes and the weights w is: , where l denotes a visible or hidden layer and H l is the number of units in that layer, and w denotes all the weights in this network. In (Karaletsos et al., 2018) , a small parametric neural network regression model maps the latent variables to the weights, . We will call this network a meta mapping. We assume p(z) = N (z; 0, I). We can thus write down the joint density of the resulting hierarchical model as follows, Variational inference was employed in prior work to infer z (and w implicitly), and to obtain a point estimate of \\u03b8, as a by-product of optimising the variational lower bound. Notice that in Sec.2, the meta mapping from the hierarchical latent variables to the weights is a parametric non-linear function, specified by a neural network. We replace the parametric neural network by a probabilistic functional mapping and place a nonparametric Gaussian process (GP) prior over this function. That is, where we have assumed a zero-mean GP, k \\u03b3 (\\u00b7, \\u00b7) is a covariance function and \\u03b3 is a small set of hyper-parameters. The effect is that the latent function introduces correlations for the individual weight predictions, Notably, while the number of latent variables and weights can be large, the input dimension to the GP mapping is only 2D z , where D z is the dimensionality of each latent variable z. The GP mapping effectively performs one-dimensional regression from latent variables to individual weights while capturing their correlations. We will refer to this mapping as a GP-MetaPrior (metaGP). We define the following factorized kernel at the example of two weights in the network, In this section and what follows, we will use the popular exponentiated quadratic (EQ) kernel with ARD lengthscales, are the lengthscales and \\u03c3 2 k is the kernel variance. We cover inference and learning in App. A. We first note that whilst the hierarchical latent variables and meta mappings introduce nontrivial coupling between the weights a priori, the weights and latent variables are inherently global. That is, a function drawn from the model, represented by a set of weights, does not take into account the inputs at which the function will be evaluated. To this end, we introduce the input variable into the weight codes c w l,i,j = z l+1,i , z l,j , x n . In turn, this yields input-conditional weight models p(w n,l,i,j |f, z l+1,i , z l,j , x n ). We again turn to compositional kernels and introduce a new input kernel K x which we use as follows, As a result of having private contextual inputs to the meta mapping, the weight priors are now also local to each data point. We can utilize multiple useful kernels from the GP literature that allow modelers to describe relationships between data, but were previously inaccessible to neural network modelers. We consider this a novel form of functional regularization, as the entire network can be given structure that will constrain its function space. To scale this to large inputs, we learn transformations of inputs for the conditional weight model n = g(Vx n ), for a learned mapping V and a nonlinearity g: We write down the joint density of all variables in the model when using our weight prior in a neural network: We discuss inference and learning in the Appendix Sec. A. We study our suggested priors empirically in two distinct settings in the following: first, we study the effect of kernel choice in the local model for a regression problem where we may have available intuitions as inductive biases. Second, we explore how the input-dependence behaves in out of distribution generalization tasks. We explore the utility of the contextual variable towards modeling inductive biases for neural networks and evaluate on predictive performance on a regression example. In particular, we generate 100 training points from a synthetic sinusoidal function and create two test sets that contains in-sample inputs and out-of-sample inputs, respectively. We test an array of models and inference methods, including BNN with MFVI, metaGP and metaGP with contextual variables. We can choose the covariance function to be used for the auxiliary variables to encode our belief about how the weights should be modulated by the input. We pick EQ and periodic kernels (MacKay, 1998) in this example. Fig. 2 summarizes the results and illustrate the qualitative difference between models. Note that the periodic kernel allows the model to discover and encode periodicity, allowing for more long-range confident predictions compared to that of the EQ kernel. We test the ability of this model class to produce calibrated predictive uncertainty to outof-distribution samples. We first train a neural network classifier with one hidden layer of 100 rectified linear units on the MNIST dataset, and apply the metaGP prior only to the last layer of the network. After training, we compute the entropy of the predictions on various test sets, including notMNIST, fashionMNIST, Kuzushiji-MNIST, and uniform and Gaussian noise inputs. Following (Lakshminarayanan et al., 2017; Louizos and Welling, 2017) , the CDFs of the predictive entropies for various methods are shown in Fig. 3 . In most out-of-distribution sets considered, metaGP and metaGP with local auxiliary variables demonstrate competitive performance to Gaussian MFVI. Notably, MAP estimation tends to give wildly poor uncertainty estimates on out-of-distribution samples. We illustrated the utility of a GP-based hierarchical prior over neural network weights and a variational inference scheme that captures weight correlations and allows input-dependent contextual variables. We plan to evaluate the performance of the model on more challenging decision making tasks and to extend the inference scheme to handle continual learning. Appendix A. Appendix: Inference and learning using stochastic structured variational inference Performing inference is challenging due to the non-linearity of the neural network and the need to infer an entire latent function f . To address these problems, we derive a structured variational inference scheme that makes use of innovations from inducing point GP approximation literature (Titsias, 2009; Hensman et al., 2013; Qui\\u00f1onero-Candela and Rasmussen, 2005; Matthews et al., 2016; Bui et al., 2017) and previous work on inferring meta-representations (Karaletsos et al., 2018) . As a reminder, we write down the joint density of all variables in the model: We first partition the space Z of inputs to the function f into a finite set of M variables called inducing inputs z u and the remaining inputs, Z = {x u , Z =xu }. The function f is partitioned identically, f = {u, f =u }, where u = f (x u ). We can then rewrite the GP prior as follows, The inducing inputs and outputs, {x u , u}, will be used to parameterize the approximation. In particular, a variational approximation is judiciously chosen to mirror the form of the joint density: where the variational distribution over w is made to explicitly depend on remaining variables through the conditional prior, and q(z) is chosen to be a diagonal (mean-field) Gaussian densitie, q(z) = N (z; \\u00b5 \\u00b5 \\u00b5 z , diag(\\u03c3 \\u03c3 \\u03c3 2 z )), and q(u) is chosen to be a correlated multivariate Gaussian, q(u) = N (u; \\u00b5 \\u00b5 \\u00b5 u , \\u03a3 u ). This approximation allows convenient cancellations yielding a tractable variational lower bound as follows, where the last expectation has been partly approximated using simple Monte Carlo with the reparameterization trick, i.e. z k \\u223c q(z). We will next discuss how to approximate the expectation F k = w,f q(w, f |z k ) log p(y|w, x). Note that we split f into f =u and u, and that we can integrate f =u out exactly to give, q(w|z k , u) = N (w; A (k) u, B (k) ), At this point, we can either (i) sample u from q(u), or (ii) integrate u out analytically. We opt for the second approach, which gives In contrast to GP regression and classification in which the likelihood term is factorized point-wise w.r.t. the parameters and thus their expectations only involve a low dimensional integral, we have to integrate out w in this case, which is of much higher dimensions. When necessary or practical, we resort to Kronecker factored models or make an additional diagonal approximation as follows, Whilst the diagonal approximation above might look poor from the first glance, it is conditioned on a sample of the latent variables z k and thus the weights' correlations are retained after integrating out z. Such correlation is illustrated in 4 where we show the marginal and conditional covariance structures for the weights of a small neural network, separated into diagonal and full covariance models. The diagonal approximation above has been observed to give pathological behaviours in the GP regression case (Bauer et al., 2016 ), but we did not observe these in practice. F k is approximated by F k \\u2248 wq (w|z k ) log p(y|w, x) which can be subsequently efficiently estimated using the local reparameterization trick (Kingma et al., 2015) . The final lower bound is then optimized to obtain the variational parameterers of q(u), q(z), and estimates for the noise in the meta-GP model, the kernel hyper-parameters and the inducing inputs. selection and more crucially using the proposed model and inference scheme seems to yield comparable or better predictive errors with a similar number of queries. This simple setting quantitatively reveals the inferior performance of MFVI, compared to MAP and metaGP.\",\n          \"Many automated machine learning methods, such as those for hyperparameter and neural architecture optimization, are computationally expensive because they involve training many different model configurations. In this work, we present a new method that saves computational budget by terminating poor configurations early on in the training. In contrast to existing methods, we consider this task as a ranking and transfer learning problem. We qualitatively show that by optimizing a pairwise ranking loss and leveraging learning curves from other data sets, our model is able to effectively rank learning curves without having to observe many or very long learning curves. We further demonstrate that our method can be used to accelerate a neural architecture search by a factor of up to 100 without a significant performance degradation of the discovered architecture. In further experiments we analyze the quality of ranking, the influence of different model components as well as the predictive behavior of the model. A method commonly used by human experts to speed up the optimization of neural architectures or hyperparameters is the early termination of iterative training processes that are unlikely to improve the current solution. A common technique to determine the likelihood of no improvement is to compare the learning curve of a new configuration to the one of the currently best configuration. This idea can also be used to speed up automated machine learning processes. For this purpose, it is common practice to extrapolate the partial learning curve in order to predict the final performance of the currently investigated model. Current extrapolation techniques have several weaknesses that make them unable to realize their full potential in practice. Many of the methods require sufficient sample learning curves to make reliable predictions (Chandrashekaran & Lane, 2017; Klein et al., 2017; Baker et al., 2018) . Thus, the extrapolation method for the first candidates can not be used yet, which means more computational effort. Other methods do not have this disadvantage, but require sufficiently long learning curves to make reliable predictions which again means unnecessary overhead (Domhan et al., 2015) . Many of these methods also do not take into account other information such as the hyperparameters of the model being examined or its network architecture. We address the need for sample learning curves by devising a transfer learning technique that uses learning curves from other problems. Since the range of accuracy varies from data set to data set, we are forced to consider this in our modeling. But since we are not interested in predicting the performance of a model anyway, we use a ranking model that models the probability that the model currently being investigated surpasses the best solution so far. This does not only solve the problem but also provides a better modeling of the actual task. In order to be able to make reliable predictions for short learning curves, we consider further characteristics of the model such as its network architecture. We compare our ranking method with respect to a ranking measure against different methods on five different image classification data sets. We also show that our method is capable of significantly accelerating a neural architecture search. Furthermore, we conduct several ablation studies to provide a better motivation of our model and its behavior. Most of the prior work for learning curve prediction is based on the idea of extrapolating the partial learning curve by using a combination of continuously increasing basic functions. Domhan et al. (2015) define a set of 11 parametric basic functions, estimate their parameters and combine them in an ensemble. Klein et al. (2017) propose a heteroscedastic Bayesian model which learns a weighted average of the basic functions. Chandrashekaran & Lane (2017) do not use basic functions but use previously observed learning curves of the current data set. An affine transformation for each previously seen learning curve is estimated by minimizing the mean squared error with respect to the partial learning curve. The best fitting extrapolations are averaged as the final prediction. Baker et al. (2018) use a different procedure. They use support vector machines as sequential regressive models to predict the final accuracy based on features extracted from the learning curves, its gradients, and the neural architecture itself. The predictor by Domhan et al. (2015) is able to forecast without seeing any learning curve before but requires observing more epochs for accurate predictions. The model by Chandrashekaran & Lane (2017) requires seeing few learning curves to extrapolate future learning curves. However, accurate forecasts are already possible after few epochs. Algorithms proposed by Klein et al. (2017) ; Baker et al. (2018) need to observe many full-length learning curves before providing any useful forecasts. However, this is prohibiting in the scenarios where learning is time-consuming such as in large convolutional neural networks. All previous methods for automatically terminating iterative learning processes are based on methods that predict the learning curve. Ultimately, however, we are less interested in the exact learning curve but rather whether the current learning curve leads to a better result. This way of obtaining a ranking is referred to as pointwise ranking methods (Liu, 2011) . They have proven to be less efficient than pairwise ranking methods which directly optimize for the objective function (Burges et al., 2005 ). Yet, we are the first to consider a pairwise ranking loss for this application. There are some bandit-based methods which leverage early termination as well. Successive Halving (Jamieson & Talwalkar, 2016 ) is a method that trains multiple models with settings chosen at random simultaneously and terminates the worst performing half in predefined intervals. Hyperband (Li et al., 2017) identifies that the choice of the intervals is vital and therefore proposes to run Successive Halving with different intervals. BOHB (Falkner et al., 2018 ) is an extension of Hyperband which proposes to replace the random selection of settings with Bayesian optimization. The use of methods that terminate less promising iterative training processes early are of particular interest in the field of automated machine learning, as they can, for example, significantly accelerate hyperparameter optimization. The most computationally intensive subproblem of automated machine learning is Neural Architecture Search (Zoph & Le, 2017) , the optimization of the neural network topology. Our method is not limited to this problem, but as it is currently one of the major challenges in automated machine learning, we use this problem as a sample application in our evaluation. For this particular application, optimization methods that leverage parameter sharing (Pham et al., 2018) have become established as a standard method. Here, a search space spanning, overparametrised neural network is learned and finally used to determine the best architecture. DARTS (Liu et al., 2019 ) is one of the last extensions of this idea which uses a continuous relaxation of the search space, which allows learning of the shared parameters as well as of the architecture by means of gradient descent. This method can be a strong alternative to early termination methods but does not transfer to general machine learning or arbitrary architecture search spaces. With learning curve we refer to the function of qualitative performance with growing number of iterations of an iterative learning algorithm. We use the term final learning curve to explicitly denote the entire learning curve, y 1 , . . . , y L , reflecting the training process from beginning to end. Here, y i is a measure of the performance of the model (e.g., classification accuracy), which is determined at regular intervals. Contrary, a partial learning curve, y 1 , . . . , y l , refers to learning curves that are observed only up to a time l. We visualize the concepts of the terms in Figure 1 . There is a set of automated early termination methods which follow broadly the same principle. The first model is trained to completion and is considered as the current best model m max with its performance being y max . For each further model m i , the probability that it is better than the current best model, p (m i > m max ), is monitored at periodic intervals during training. If it is below a given threshold, the model's training is terminated (see Algorithm 1). All existing methods rely on a two- step approach to determine this probability which involves extrapolating the partial learning curve and a heuristic measure. Instead of the two-step process to determine the probability, we propose LCRankNet to predict the probability that a model m i is better than m j directly. LCRankNet is based on a neural network f which considers model characteristics and the partial learning curve x i as input. We define the probability that m i is better than m j as Using the logistic function is an established modelling approach in the learning-to-rank community (Burges et al., 2005) . Given a set of final learning curves for some models, the estimation of the posterior values p i,j between these models is trivial since we know whether m i is better than m j or not. Therefore, we set We minimize the cross-entropy loss to determine the parameters of f . Now the probability p(m i > m j ) can be predicted for arbitrary pairs m i and m j using Equation (1). Train m on d for a step and observe a further part of the learning curve y t . if max 1\\u2264i\\u2264l y i > y max then 4: return y 7: return y We have defined the prediction of our model in Equation (1). It depends on the outcome of the function f which takes a model representation x as input. The information contained in this representation depends on the task at hand. Since we will consider Neural Architecture Search, the representation consists of three different parts. First, the partial learning curve y 1 , . . . , y l . Second, the description of the model's architecture which is a sequence of strings representing the layers it is comprised of. Third, a data set ID to indicate on which data set the corresponding architecture and learning curve was trained and observed. We model f using a neural network and use special layers to process the different parts of the representation. The learned representation for the different parts are finally concatenated and fed to a fully connected layer. The architecture is visualized in Figure 2 . We will now describe the different components in detail. Learning curve component A convolutional neural network is used to process the partial learning curve. We consider up to four different convolutional layers with different kernel sizes. The exact number depends on the length of the learning curve since we consider no kernel sizes larger than the learning curve length. Each convolution is followed by a global max pooling layer and their outputs are concatenated. This results in the learned representation for the learning curve. Architecture component For our learning curve prediction we use architectures of the popular NASNet search space . We use the most common configuration which consists of two cells and every cell of five blocks. This results into 40 choices to be made which is encoded as a sequence of integers. Please refer to for further details regarding the search space. We learn an embedding for every choice. An LSTM takes this embedding and generates the architecture embedding. Data set component As we intend to learn from learning curves of other data sets, we include data set embeddings as one of the components. Every data set has its own embedding and it will be used whenever a learning curve observed on this data set is selected. If the data set is new, then the corresponding embedding is initialized at random. As the model observes more learning curves from this data set, it improves the data set embedding. The embedding helps us to model data-set-specific peculiarities in order to adjust the ranking if necessary. Technical details During the development process, we found that the architecture component leads to instabilities during training. To avoid this, we regularize the output of the LSTM layer by using it as an input to an autoregressive model, similar to a sequence-to-sequence model (Sutskever et al., 2014) that recreates the original description of the architecture. In addition, we use the attention mechanism (Bahdanau et al., 2015) to facilitate this process. All parameters of the layers in f are trained jointly by means of Adam (Kingma & Ba, 2015) by minimizing a weighted linear combination of the ranking loss (Equation (3)) and the reconstruction loss with respect to its parameters. The hyperparameter \\u03b4 allows for trading precision vs. recall or search time vs. regret, respectively. There are two extreme case: if we set \\u03b4 \\u2265 1 every run is terminated immediately. If we set \\u03b4 \\u2264 0 we never terminate any run. For our experiment we set \\u03b4 = 0.45 which means that if the predicted probability that the new model is better than the best one is below 45%, the run is terminated early. In this section, we first discuss how to create the meta-knowledge and then analyze our model in terms of learning curve ranking and the ability to use it as a way to accelerate Neural Architecture Search. Finally, we examine its individual components and behavior in certain scenarios. We compare our method to similar methods on five different data sets: CIFAR-10, CIFAR-100, Fashion-MNIST, Quickdraw, and SVHN. We use the original train/test splits if available. Quickdraw has a total of 50 million data points and 345 classes. To reduce the training time, we select a subset of this data set. We use 100 different randomly selected classes and choose 300 examples per class for the training split and 100 per class for the test split. 5,000 random data points of the training data set serve as validation split for all data sets. To create the meta-knowledge, we choose 200 architectures per data set at random from the NASNet search space ) such that we train a total of 1,000 architectures. We would like to point out that these are 1,000 unique architectures, there is no architecture that has been trained on several different data sets. Each architecture is trained for 100 epochs with stochastic gradient descent and cosine learning rate schedule without restart (Loshchilov & Hutter, 2017) . We use standard image preprocessing and augmentation: for every image, we first subtract the channel mean and then divide by the channel standard deviation. Images are padded by a margin of four pixels and randomly cropped back to the original dimension. For all data sets but SVHN we apply random horizontal flipping. Additionally, we use Cutout (DeVries & Taylor, 2017). The following experiments are conducted in a leave-one-data-set-out cross-validation. That means when considering one data set, all meta-knowledge but the one for this particular data set is used as meta-knowledge. First, we analyze the quality of the learning curve rankings by different learning curve prediction methods. In this experiment we choose 50 different learning curves at random as a test set. Five random learning curves are used as a training set for every repetition. Each learning curve prediction method ranks the 50 architectures by observing the partial learning curve whose length varies from 0 to 30 percent of the final learning curve. We repeat the following experiment ten times and report the mean and standard deviation of the correlation between the true and the predicted ranking in Figure 3 . As a correlation metric, we use Spearman's rank correlation coefficient. Thus, the correlation is 1 for a perfect ranking and 0 for an uncorrelated, random ranking. Our method LCRankNet shows for all data sets better performance. If there are no or only very short partial learning curves available, our method shows the biggest difference to the existing methods. The reason for this is a combination of the consideration of the network architecture together with additional meta-knowledge. We analyze the impact of each component in detail in Section 4.5. The method of Chandrashekaran & Lane (2017) consistently shows the second best results and in some cases can catch up to the results of our method. The method of Baker et al. (2018) stands out due to the high standard deviation. It is by far the method with the smallest squared error on test. However, the smallest changes in the prediction lead to a significantly different ranking, which explains the high variance in their results. The method of Domhan et al. (2015) requires a minimum length of the learning curve to make predictions. Accordingly, we observe rank correlation values starting from a learning curve length of 4%. Using the last seen value to determine the ranking of learning curves is a simple yet efficient method (Klein et al., 2017) . In fact, it is able to outperform some of the more elaborate methods. In this experiment, we demonstrate the utility of learning curve predictors in the search for network architectures. For the sake of simplicity we accelerate a random search in the NASNet search space . The random search samples 200 models and trains each of them for 100 epochs to obtain the final accuracy. In the end, the best of all these models is returned. Now each learning curve predictor iterates over these sampled architectures in the same order and determines at every third epoch if the training should be aborted. For Successive Halving (Jamieson & Talwalkar, 2016) and Hyperband (Li et al., 2017) we follow the algorithm defined by the authors and use the recommended settings. The current best model discovered after iterating over all 200 architectures is returned as the best model for this learning curve predictor. The goal of the methods is to minimize the regret compared to a random search without early stopping and at the same time reduce the computational effort. One of our observations is that Domhan et al. (2015) 's method underestimates performance when the learning curve is short. As a result, the method ends each training process early after only a few epochs. Therefore, we follow the recommendation of Domhan et al. (2015) and do not end processes before we have seen the first 30 epochs. We summarize the results in Table 1 . Our first observation is that all methods accelerate the search with little regret. Here we define regret as the difference between the accuracy of the model found by the random search and the accuracy of the model found by one of the methods. Not surprisingly, Domhan et al. (2015) 's method takes up most of the time, as it requires significantly longer learning curves to make its decision. In addition, we can confirm the results of Baker et al. (2018) ; Chandrashekaran & Lane (2017) , both of which report better results than Domhan et al. (2015) . Our method requires the least amount of time for each data set. For CIFAR-100 we do not observe any regret, but a reduction of the time by a factor of 100. In some cases we observe an insignificantly higher regret than some of the other methods. In our opinion, the time saved makes up for it. In Figure 4 we visualize the random search for SVHN. As you can see, many curves not only have similar behavior but also similar accuracy. For this reason, it is difficult to decide whether to discard a model safely, which explains the increased runtime. The only methods that do not show this behavior are Successive Halving and Hyperband. The simple reason is that the number of runs terminated and the time they are discarded are fixed by the algorithm and do not rely on the properties of the learning curve. The disadvantages are obvious: promising runs may be terminated and unpromising runs may run longer than needed. Finally, we compare our method with DARTS (Liu et al., 2019) , a method that accelerates the search by using the parameter sharing. We train the architecture discovered in the previous experiment with an equivalent training setup like DARTS for a fair comparison. This architecture reached a 2.99% classification error on CIFAR-10 after only 20 GPU hours were searched. By comparison, DARTS (1st order) requires 36 GPU hours for a similarly good architecture (3.00% error). DARTS (2nd order) can improve these results to 2.76%, but requires 96 GPU hours. We saw in the previous selection that LCRankNet does not perform perfectly. There are cases where its regret is greater than zero or where the search time is higher which indicates that early stopping was applied later than maybe possible. In this section we try to shed some light on the decisions made by the model and try to give the reader some insight of the model's behavior. We provide four example decisions of LCRankNet in Figure 5 . The plots in the top row show cases where LCRankNet made a correct decision, the plots in the bottom row are examples for incorrect decisions. In both of the correct cases (top row), LCRankNet assigns a higher probability to begin with, using meta-knowledge. However, in the top left case it becomes evident after only very few epochs that m max is consistently better than m such that the probability p (m > m max ) reduces sharply to values close to zero which would correctly stop training early on. The case in the top right plot is more tricky. The probability is increasing until a learning curve length of 12% as the learning curve seem to indicate that m is better than m max . However, the learning curve of m max approaches the values of m and then the probability decreases and training is stopped early. We continue now with the discussion of the two examples in the bottom row which LCRankNet false terminated early which cause a regret higher than zero in Table 1 . In the bottom left we show an example where sometimes m is better for a longer period and sometimes m max . This is arguable a very difficult problem and it is hard to predict which curve will eventually be better. However, LCRankNet shows a reasonable behavior. As the learning curve of m is consistently worse than m max in the segment from 15% to 42%, the probability is decreasing. Starting from a length of 57%, where m shows superior performance than m max for several epochs, the probability starts to raise. From learning curve length of 70% onwards, both the learning curves are very close and the difference in the final accuracy is only 0.0022. The example visualized in the bottom right plot is a very interesting one. The learning curve of m max is consistently better than or almost equal to m up to the very end. Towards the end, learning curves are getting very close. In fact, from learning curve length 63% onwards, the maximum difference between m and m max per epoch is only 0.008. Hence, in the beginning it seems like a trivial decision to reject m. However, eventually m turns out to be better than m max . In conclusion, deciding whether one model will be better than another one based on a partial learning curve is a challenging task. A model that turns out to be (slightly) better than another one can be dominated consistently for most of the learning curve. This makes it not only a very challenging problem for automated methods but for human experts as well. We briefly mentioned before which components of our learning curve ranker have an essential influence on its quality. We would like to deepen the analysis at this point and compare the configuration we have proposed with different variants in Figure 6 . We consider variants with and without metadata, architecture description or learning curve consideration. In addition, we compare our configuration trained with pairwise ranking loss to one trained with a pointwise ranking loss. One of the most striking observations is that the metadata is essential for the model. This is not surprising since in particular the learning of architecture embedding needs sufficient data. Sufficient data is not available in this setup, so we observe a much higher variance for these variants. Even the variant that only considers the learning curve benefits from additional meta-knowledge. But even this is not surprising, since stagnating learning processes show similar behavior regardless of the data set. Using the meta-knowledge, both components achieve good results on their own. It can be clearly seen that these components are orthogonal to one another. The variant, which only considers the architecture, shows very good results for short learning curves. If only the learning curve is considered, the results are not very good at first, but improve significantly with the length of the learning curve. A combination of both methods ultimately leads to our method and further improves the results. Finally, we compare the use of a pointwise ranking loss (L2 loss) versus a pairwise ranking loss. Although our assumption was that the latter would have to be fundamentally better, since it optimizes the model parameters directly for the task at hand, in practice this does not necessarily seem to be the case. Especially for short learning curves, the simpler method achieves better results. However, once the learning curve is long enough, the pairwise ranking loss pays off. In this paper we present LCRankNet, a method to automatically terminate unpromising model configurations early. The two main novelties of the underlying model are that it is able to consider learning curves from other data sets and that it uses a pairwise ranking loss. The former allows to predict for relatively short, and in extreme cases even without, learning curves. The latter directly allows to model the probability that one configuration is better than the another. We analyze our method on five different data sets against three alternatives. In an experiment to optimize network architectures, we obtain the fastest results. In the best case, LCRankNet is 100 times faster without sacrificing accuracy. We also examine the components and predictions of our method to give the reader a better understanding of the design choices and functionalities.\",\n          \"Training a model to perform a task typically requires a large amount of data from the domains in which the task will be applied.\\n However, it is often the case that data are abundant in some domains but scarce in others. Domain adaptation deals with the challenge of adapting a model trained from a data-rich source domain to perform well in a data-poor target domain. In general, this requires learning plausible mappings between domains. CycleGAN is a powerful framework that efficiently learns to map inputs from one domain to another using adversarial training and a cycle-consistency constraint. However, the conventional approach of enforcing cycle-consistency via reconstruction may be overly restrictive in cases where one or more domains have limited training data. In this paper, we propose an augmented cyclic adversarial learning model that enforces the cycle-consistency constraint via an external task specific model, which encourages the preservation of task-relevant content as opposed to exact reconstruction. We explore digit classification in a low-resource setting in supervised, semi and unsupervised situation, as well as high resource unsupervised. In low-resource supervised setting, the results show that our approach improves absolute performance by 14% and 4% when adapting SVHN to MNIST and vice versa, respectively, which outperforms unsupervised domain adaptation methods that require high-resource unlabeled target domain.   Moreover, using only few unsupervised target data, our approach can still outperforms many high-resource unsupervised models. Our model also outperforms on USPS to MNIST and synthetic digit to SVHN for high resource unsupervised adaptation. In speech domains, we similarly adopt a speech recognition model from each domain as the task specific model. Our approach improves absolute performance of speech recognition by 2% for female speakers in the TIMIT dataset, where the majority of training samples are from male voices. Domain adaptation BID18 BID36 BID1 aims to generalize a model from source domain to a target domain. Typically, the source domain has a large amount of training data, whereas the data are scarce in the target domain. This challenge is typically addressed by learning a mapping between domains, which allows data from the source domain to enrich the available data for training in the target domain. One way of learning such mappings is through Generative Adversarial Networks (GANs BID8 with cycle-consistency constraint (CycleGAN Zhu et al., 2017) , which enforces that mapping of an example from the source to the target and then back to the source domain would result in the same example (and vice versa for a target example). Due to this constraint, CycleGAN learns to preserve the 'content' 1 from the source domain while only transferring the 'style' to match the distribution of the target domain. This is a powerful constraint, and various works BID37 BID12 have demonstrated its effectiveness in learning cross domain mappings. Enforcing cycle-consistency is appealing as a technique for preserving semantic information of the data with respect to a task, but implementing it through reconstruction may be too restrictive when data are imbalanced across domains. This is because the reconstruction error encourages exact match of samples from the reverse mapping, which may in turn encourage the forward-mapping to keep the sample close to the original domain. Normally, the adversarial objectives would counter this effect; however, when data from the target domain are scarce, it is very difficult to learn a powerful discriminator that can capture meaningful properties of the target distribution. Therefore, the resulting mappings learned is likely to be sub-optimal. Importantly, for the learned mapping to be meaningful, it is not necessary to have the exact reconstruction. As long as the 'semantic' information is preserved and the 'style' matches the corresponding distribution, it would be a valid mapping. To address this issue, we propose an augmented cyclic adversarial learning model (ACAL) for domain adaptation. In particular, we replace the reconstruction objective with a task specific model. The model learns to preserve the 'semantic' information from the data samples in a particular domain by minimizing the loss of the mapped samples for the task specific model. On the other hand, the task specific model also serves as an additional source of information for the corresponding domain and hence supplements the discriminator in that domain to facilitate better modeling of the distribution. The task specific model can also be viewed as an implicit way of disentangling the information essential to the task from the 'style' information that relates to the data distribution of different domain. We show that our approach improves the performance by 40% as compared to the baseline on digit domain adaptation. We improve the phoneme error rate by \\u223c 5% on TIMIT dataset, when adapting the model trained on one speech from one gender to the other. Our work is broadly related to domain adaptation using neural networks for both supervised and unsupervised domain adaptation. Supervised Domain Adaptation When labels are available in the target domain, a common approach is to utilize the label information in target domain to minimize the discrepancy between source and target domain BID15 BID33 BID7 BID6 . For example, BID15 applies the marginal Fisher analysis criteria and Maximum Mean Discrepancy (MMD) to minimize the distribution difference between source and target domain. BID33 proposed to add a domain classifier that predicts domain label of the inputs, with a domain confusion loss. BID7 leverages attributes by using attribute and class level classification loss with attribute consistent loss to fine-tune the target model. Our method also employs models from both domains, however, our models are used to assist adversarial learning for better learning of the target domain distribution. In addition, our final model for supervised domain adaptation is obtained by training on data from target domain as well as the transfered data from the source domain, rather than fine-tuning a source/target domain model. More recently, various work have taken advantage of the substantial generation capabilities of the GAN framework and applied them to domain adaptation BID23 BID2 BID37 BID34 BID20 BID12 . However, most of these works focus on high-resource unsupervised domain adaptation, which may be unsuitable for situations where the target domain data are limited. BID2 uses a GAN to adapt data from the source to target domain while simultaneously training a classifier on both the source and adapted data. Our method also employs task specific models; however, we use the models to augment the CycleGAN formulation. We show that having cycles in both directions (i.e. from source to target and vice versa) is important in the case where the target domain has limited data (see sec. 4). BID34 proposes adversarial discriminative domain adaptation (ADDA), where adversarial learning is employed to match the representation learned from the source and target domain. Our method also utilizes pre-trained model from source domain, but we only implicitly match the representation distributions rather than explicitly enforcing representational similarity. Cycle-consistent adversarial domain adaptation (CyCADA Hoffman et al., 2018) is perhaps the most similar work to our own. This approach uses both 1 and semantic consistency to enforce cycle-consistency. An important difference in our work is that we also include another cycle that starts from the target domain. This is important because, if the target domain is of low resource, the adaptation from source to target may fail due to the difficulty in learning a good BID39 . Middle: Relaxed cycle-consistent model (RCAL), where the cycle-consistency is enforced through task specific models in corresponding domain. Right: Augmented cycle-consistent model (ACAL). In addition to the relaxed model, the task specific model is also used to augment the discriminator of corresponding domain to facilitate learning. In the diagrams x and L denote data and losses, respectively. We point out that the ultimate goal of our approach is to use the mapped Source \\u2192 Target samples (x S \\u2192T ) to augment the limited data of the target domain (x T ). discriminator in the target domain. BID0 also suggests to improve CycleGAN by explicitly enforcing content consistency and style adaptation, by augmenting the cyclic adversarial learning to hidden representation of domains. Our model is different from recent cyclic adversarial learning, due to implicit learning of content and style representation through an auxiliary task, which is more suitable for low resource domains. Using classification to assist GAN training has also been explored previously BID31 BID32 BID21 . BID31 proposed CatGAN, where the discriminator is converted to a multi-class classifier. We extend this idea to any task specific model, including speech recognition task, and use this model to preserve task specific information regarding the data. We also propose that the definition of task model can be extended to unsupervised tasks,such as language or speech modeling in domains, meaning augmented unsupervised domain adaptation. To learn the true data distribution P data (X) in a nonparametric way, BID8 proposed the generative adversarial network (GAN). In this framework, a discriminator network D(x) learns to discriminate between the data produced by a generator network G(z) and the data sampled from the true data distribution P data (X), whereas the generator models the true data distribution by learning to confuse the discriminator. Under certain assumptions BID8 , the generator would learn the true data distribution when the game reaches equilibrium. Training of GAN is in general done by alternately optimizing the following objective for D and G. min DISPLAYFORM0 2.2 CYCLEGAN CycleGAN BID39 extends this framework to multiple domains, P S (X) and P T (X), while learning to map samples back and forth between them. Adversarial learning is applied such that the result mapping from G S \\u2192T will match the target distribution P T (X), and similarly for the reverse mapping from G T \\u2192S . This is accomplished by the following adversarial objectives: DISPLAYFORM1 CycleGAN also introduces cycle-consistency, which enforces that each mapping is able to invert the other. In the original work, this is achieved by including the following reconstruction objective: DISPLAYFORM2 Learning the CycleGAN model involves optimizing a weighted combination of the above objectives 2, 3 and 4. Enforcing cycle-consistency using a reconstruction objective (e.g. eq. 4) may be too restrictive and potentially results in sub-optimal mapping functions. This is because the learning dynamics of CycleGAN balance the two contrastive forces. The adversarial objective encourages the mapping functions to generate samples that are close to the true distribution. At the same time, the reconstruction objective encourages identity mapping. Balancing these objectives may works well in the case where both domains have a relatively large number of training samples. However, problems may arise in case of domain adaptation, where data within the target domain are relatively sparse. Let P S (X) and P T (X) denote source and target domain distributions, respectively, and samples from P T (X) are limited. In this case, it will be difficult for the discriminator D T to model the actual distribution P T (X). A discriminator model with sufficient capacity will quickly overfit and the resulting D T will act like delta function on the sample points from P T (X). Attempts to prevent this by limiting the capacity or using regularization may easily induce over-smoothing and under-fitting such that the probability outputs of D T are only weakly sensitive to the mapped samples. In both cases, the influence of the reconstruction objective should begin to outweigh that of the adversarial objective, thereby encouraging an identity mapping. More generally, even if we are are able to obtain a reasonable discriminator D T , the support of the distribution learned through it would likely to be small due to limited data. Therefore, the learning signal G S \\u2192T receive from D T would be limited. To sum up, limited data within P T (X) would make it less likely that the discriminator will encourage meaningful cross domain mappings. The root of the above issue in domain adaptation is two fold. First, exact reconstruction is a too strong objective for enforcing cycle-consistency. Second, learning a mapping function to a particular domain which solely depends on the discriminator for that domain is not sufficient. To address these two problems, we propose to 1) use a task specific model to enforce the cycle-consistency constraint, and 2) use the same task specific model in addition to the discriminator to train more meaningful cross domain mappings. In more detail, let M S and M T be the task specific models trained on domains P S (X, Y ) and P T (X, Y ), and L task denotes the task specific loss. Our cycle-consistent objective is then: DISPLAYFORM0 Here, L task enforces cycle-consistency by requiring that the reverse mappings preserve the semantic information of the original sample. Importantly, this constraint is less strict than when using reconstruction, because now as long as the content matches that of the original sample, the incurred loss will not increase. (Some style consistency is implicitly enforced since each model M is trained on data within a particular domain.) This is a much looser constraint than having consistency in the original data space, and thus we refer to this as the relaxed cycle-consistency objective. To address the second issue, we augment the adversarial objective with corresponding objective: DISPLAYFORM1 Similar to adversarial training, we optimize the above objective by maximizing D S (D T ) and minimizing G T \\u2192S (G S \\u2192T ) and M S (M T ). With the new terms, learning of the mapping functions G get assists from both the discriminator and the task specific model. The task specific model learns to capture conditional probability distribution P S (Y |X) (P T (Y |X)), that also preserves information regarding P S (X) (P T (X)). This conditional information is different than the information captured through the discriminator D S (D T ). The difference is that the model is only required to preserve DISPLAYFORM2 end end useful information regarding X respect to predicting Y , for modeling the conditional distribution, which makes learning the conditional model a much easier problem. In addition, the conditional model mediates the influence of data that the discriminator does not have access to (Y ), which should further assist learning of the mapping functions G T \\u2192S (G S \\u2192T ).In case of unsupervised domain adaptation, when there is no information of target conditional probability distribution P T (Y |X), we propose to use source model DISPLAYFORM3 . Therefore, proposed model can be extended to unsupervised domain adaptation, with the corresponding modified objectives: DISPLAYFORM4 To further extend this approach to semi-supervised domain adaptation, both supervised and unsupervised objectives for labeled and unlabeled target samples are used interchangeably, as explained in Algorithm 1. In this section, we evaluate our proposed model on domain adaptation for visual and speech recognition. We continue the convention of referring to the data domains as 'source' and 'target', where target denotes the domain with either limited or unlabeled training data. Visual domain adaptation is evaluated using the MNIST dataset (M) BID22 , Street View House Numbers (SVHN) datasets (S) BID26 , USPS (U) BID19 , MNISTM (MM) and Synthetic Digits (SD) BID4 . Adaptation on speech is evaluated on the domain of gender within the TIMIT dataset BID5 , which contains broadband 16kHz recordings of 6300 utterances (5.4 hours) of phonetically-balanced speech. The male/female ratio of speakers across train/validation/test sets is approximately 70% to 30%. Therefore, we treat male speech as the source domain and female speech as the low resource target domain. To get an idea of the contribution from each component of our model, in this section we perform a series of ablations and present the results in TAB0 . We perform these ablations by treating SVHN as the source domain and MNIST as the target domain. We down sample the MNIST training data so only 10 samples per class are available during training, denoted as MNIST-(10), which is only 0.17% of full training data. The testing performance is calculated on the full MNIST test set. We use a modified LeNet for all experiments in this ablation. The Modified LeNet consists of two convolutional layers with 20 and 50 channels, followed by a dropout layer and two fully connected layers of 50 and 10 dimensionality. There are various ways that one may utilize cycle-consistency or adversarial training to do domain adaptation from components of our model. One way is to use adversarial training on the target domain to ensure matching of distribution of adapted data, and use the task specific model to ensure the 'content' of the data from the source domain is preserved. This is the model described in BID2 , except their model is originally unsupervised. This model is denoted as S \\u2192 T in TAB0 . It is also interesting to examine the importance of the double cycle, which is proposed in BID39 and adopted in our work. Theoretically, one cycle would be sufficient to learn the mapping between domains; therefore, we also investigate the performance of one cycle only models, where one direction would be from source to target and then back, and similarly for the other direction. These models are denoted as (S\\u2192T\\u2192S)-One Cycle and (T\\u2192S\\u2192T)-One Cycle in TAB0 , respectively. To test the effectiveness of the relaxed cycle-consistency (eq. 5) and augmented adversarial loss (eq. 6 and 7), we also test one cycle models while progressively adding these two losses. Interestingly, the one cycle relaxed and one cycle augmented models are similar to the model proposed in BID12 when their model performs mapping from source to target domain and then back. The difference is that their model is unsupervised and includes more losses at different levels. As can be seen from TAB0 , the simple conditional model performed surprisingly well as compared to more complicated cyclic counterparts. This may be attributed to the reduced complexity, since it only needs to learn one set of mapping. As expected, the single cycle performance is poor when the target domain is of limited data due to inefficient learning of discriminator in the target domain (see section 3). When we change the cycle to the other direction, where there are abundant data in the target domain, the performance improves, but is still worse than the simple one without cycle. This is because the adaptation mapping (i.e. G S \\u2192T ) is only learned via the generated samples from G T \\u2192S , which likely deviate from the real examples in practice. This observation also suggests that it would be beneficial to have cycles in both directions when applying the cycle-consistency constraint, since then both mappings can be learned via real examples. The trends get reversed when we are using relaxed implementation of cycle-consistency from the reconstruction error with the task specific losses. This is because now the power of the task specific model is crucial to preserve the content of the data after the reverse mapping. When the source domain dataset is sufficiently large, the cycle-consistency is preserved. As such, the resulting learned mapping functions would preserve meaningful semantics of the data while transferring the styles to the target domain, and vice versa. In addition, it is clear that augmenting the discriminator with task specific loss is helpful for learning adaptations. Furthermore, the information added from the task specific model is clearly beneficial for improving the adaptation performance, without this none of the models outperform the baseline model, where no adaptation is performed. Last but not least, it is also clear from the results that using task specific model improves the overall adaptation performance. DISPLAYFORM0 To further evaluate the effectiveness of using task-specific loss with two cycles for low-resource unsupervised domain adaptation scenario, we comapre our model with CyCADA BID12 , and when no reconstruction loss is used in CyCADA, referred as \\\"CyCADA (Relaxed)\\\". The latter resembles the (S \\u2192 T \\u2192 S)-ACAL in TAB0 , but with a different semantic loss. As shown in FIG1 , CyCADA model and its relaxed variation fail to learn a good adaptation, where target domain contains few unlabaled samples per class. Additionally, CyCADA models show high instability in low-resource situation. As described in section 1.1, instability is an expected behvaiour of CyCADA when having limited target data, because the source to target cycle fails to preserve consistency, due to weak target domain discriminator. However, ACAL model indicates stable and consistent performance, due to proper use of source classifier to enforce consistency, rather than relying on target and source discriminators. In this section, we experiment on domain adaptation for the task of digit recognition. In each experiment, we select one domain (MNIST, USPS, MNISTM, SVHN, Synthetic Digits) to be the target. We conduct three types of domain adaptation, i.e. low-resource supervised, high-resource unsupervised, and low-resource semi-supervised adaptation. The evaluation results are based on not using any data augmentation. Low-resource supervised adaptation: In this setting, we sub-sample the target to contain only a few labeled samples per class, and using the other full dataset as the source domain. In this setting, no unlabeled sample is used. Comparison with recent low resource domain adaptation, FADA BID25 for MNIST, USPS, and SVHN adaptation is shown in FIG2 . To provide more baselines, we also compared with model trained only on limited target data, and on combination of both labeled source and limited target domains. As shown in FIG4 , ACAL outperforms FADA and two other baselines in all adaptations. High-resource unsupervised adaptation; Here, we use the whole target domain with no label. Evaluation results on all adaptation directions are presented in TAB1 (Appendix A). It is evident that ACAL model performance is on par with the state of the art unsupervised approaches, and outperforms on MNIST\\u2192USPS and Syn-Digits\\u2192SVHN. It is worth mentioning that Shu et al. (2018) improved their VADA adversarial model using natural gradient as teacher-student training, which is not directly comparable to adversarial approaches. Moreover, the source-only baseline of BID30 ) is stronger than the reported unsupervised approaches, as well as our baseline. DISPLAYFORM0 Low-resource semi-supervised adaptation: We also evaluate the performance of ACAL algorithm when there are limited labeled and unlabeled target samples in Table 6 (Appendix A). In case of MNIST\\u2192USPS, our model outperforms many high-resource unsupervised domain adaptation in TAB1 by using < 1000 unlabeled samples only. We also apply our proposed model to domain adaptation in speech recognition. We use TIMIT dataset, where the male to female speaker ratio is about 7 : 3 and thus we choose the data subset from male speakers as the source and the subset from female speakers as the target domain. We evaluate performance on the standard TIMIT test set and use phoneme error rate (PER) as the evaluation metric. Spectrogram representation of audio is chosen for model evaluation. As demonstrated by BID13 , multi-discriminator training significantly impacts adaptation performance. Therefore, we used the multi-discriminator architecture as the discriminator for the adversarial loss in our evaluation. Our task-specific model is a pre-trained speech recognition model within each domain in this set of experiments. The result are shown in Table 3 . We observe significant performance improvements over the baseline model as well as comparable or better performance as compared to previous methods. It is interesting to note that the performance of the proposed model on the adapted male (M \\u2192 F) almost matches the baseline model performance, where the model is trained on true female speech. In addition, the performance gap in this case is significant as compared to other methods, which suggests the adapted distribution is indeed close to the true target distribution. In addition, when combined with more data, our model further outperforms the baseline by a noticeable margin. Table 3 : Speech domain adaptation results on TIMIT. We treat Male (M) and Female (F) voices for the source and target domains, respectively, based on the intrinsic imbalance of speaker genders in the dataset (about 7 : 3 male/female ratio). For the evaluation metric, lower is better. In this paper, we propose to use augmented cycle-consistency adversarial learning for domain adaptation and introduce a task specific model to facilitate learning domain related mappings. We enforce cycle-consistency using a task specific loss instead of the conventional reconstruction objective. Additionally, we use the task specific model as an additional source of information for the discriminator in the corresponding domain. We demonstrate the effectiveness of our proposed approach by evaluating on two domain adaptation tasks, and in both cases we achieve significant performance improvement as compared to the baseline. By extending the definition of task-specific model to unsupervised learning, such as reconstruction loss using autoencoder, or self-supervision, our proposed method would work on all settings of domain adaptation. Such unsupervised task can be speech modeling using wavenet BID35 , or language modeling using recurrent or transformer networks BID27 . In this section, we evaluate domain adaptation for MNIST\\u2194SVHN for comparison with CycleGAN, as well as the relaxed version of the cycle-consistent objective (Relaxed-Cyc, see eq. 5 in section 3). For the former, 1 reconstruction loss is replaced with the model loss in order to encouraging cycle-consistency. We also experiment with two different task specific models M : specifically, DenseNet BID17 , representing a relatively complex architecture) and a modified LeNet (representing a relatively simple architecture, see section 4.1). TAB2 and 5 show the results on augmenting the low resource MNIST and SVHN with the complementary high resource domain. This approach improves test performance of the target classifier by a large margin, compared to when trained only using the target domain data. We observe that training a more complicated deep model for the target domain weakens this effect. As shown in TAB2 , using DenseNet as a classifier on MNIST (target) achieves \\u2248 24% lower test classification accuracy than using a variant of LeNet. This difference likely reflects differences in the two architectures' degree of overfitting. Overfitting will produce a false gradient signal during cycle adversarial learning (when classifying the adapted source examples). Based on this observation, we use a comparatively simpler LeNet architecture with SVHN as the target domain (see TAB3 ). Using our proposed approach, SVHN test performance improves by 27% over domain adaptation using CycleGAN. We also include some qualitative results when performing domain adaptation from SVHN (source) to MNIST (target), as shown in Figure 5 . We also compare the performance with different number of labeled target samples in FIG4 . It indicates the improvement on generalization performance of target model using Augmented cyclic adaptation, with variable labeled target domain on MNIST and SVHN datasets. Evaluation of semi supervised adaptation is presented in Table 6 . 74.61\\u00b10.43Figure 5: Qualitative comparison of domain adaptation for experimental models. Each column illustrates the mapping performed by each of the models from the original SVHN image (source domain) to MNIST (target domain, 10 labeled samples per class in total). It can be seen that the augmented cycle-consistent model is able to preserve most of the semantic information, while still approximately match the target distribution. Table 6 : Low-resource semi and unsupervised domain adaptation on MNIST (M), USPS (U) and SVHN (S) datasets. Note: n = 10 means 10 samples per class, and 10% denotes the percentage of target samples (per class) which have labels. 0% corresponds to low-resource unsupervised adaptation. BID39 with modifications mentioned in BID13 . Both generators in CycleGAN are based on U-net BID28 architecture with 4 layers of convolution of sizes (8,3,3,1,1), (16,3,3,1,1), (32,3,3,2,2) , (64,3,3,2,2), followed by corresponding deconvolution layers. To increase stability of adversarial training, as proposed by BID13 , the discriminator output is modified to predict a single scalar as real/fake probability. Discriminator has 4 convolution layers of sizes (8,4,4,2,2), (16,4,4,2,2), (32,4,4,2,2), (64,4,4,2,2), as default kernel and stride sizes in BID13 . ASR model is implemented based on BID38 , which is trained only with maximum likelihood. The model includes one convolutional layer of size (32, 41, 11, 2, 2) , and five residual convolution blocks of size (32,7,3,1,1), (32,5,3,1,1), (32,3,3,1,1), (64,3,3,2,1), (64,3,3,1,1) respectively. Convolutional layers are followed by 4 layers of bidirectional GRU RNNs with 1024 hidden units per direction per layer. Finally, a fully-connected hidden layer of size 1024 is used as the output layer. DISPLAYFORM0 In this section we show some qualitative results on transcriptions produced from different models. No Adaptation sil dh ah f aa sil p er z ih n ih n sil dh ih m z er v er r aa v iy ng aa n sil t ay m sil CycleGAN sil b er f aa sil p r ih th iy n m ih sil b ih ih m n sil f r eh m er r aw n iy ng er n sil t er m sil ACAL sil dh ih f aa l sil p r ih z ih n ih sil dh iy ih m f er m er r aa dh ih ng aa n sil t ah m sil True sil ch iy sil s sil t aa sil k ih ng z r ah n dh ih f er s sil t ay m dh eh r w aa r n sil No Adaptation sil ch iy sil ch s sil t aa sil k ih n ng z r ah m dh ah f er s sil t aa m dh eh w ah r n sil CycleGAN sil ch iy sil ch s sil t aa sil k ih ng z r ah n dh ih f er ih s sil t ay n dh eh r w aa r ng sil ACAL sil sh iy sil ch s sil t aa sil k ih ng z r ah m dh ah f er s sil t ay m dh eh r w aa r n sil No Adaptation sil k eh l s iy ih m ey sil k s sil b ow n z ih n sil t iy sil s sil t r aa l sil CycleGAN sil t aw s iy ih m n m ey sil k s sil b ow n z ih n sil t iy sil s sil t r aa ng sil ACAL sil k aw s iy ih m ey sil k s sil b ow n z ih n sil t iy sil s sil t r aa ng sil\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Bylhq134Fr\",\n          \"BJxAHgSYDB\",\n          \"B1G9doA9F7\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"We introduce a Gaussian Process Prior over weights in a neural network and explore its ability to model input-dependent weights with benefits to various tasks, including uncertainty estimation and generalization in the low-sample setting.\",\n          \"Learn to rank learning curves in order to stop unpromising training jobs early. Novelty: use of pairwise ranking loss to directly model the probability of improving and transfer learning across data sets to reduce required training data. The paper proposes a method to rank learning curves of neural networks that can model learning curves across different datasets, achieving higher speed-ups on image classification tasks.\",\n          \"A new cyclic adversarial learning augmented with auxiliary task model which improves domain adaptation performance in low resource supervised and unsupervised situations  Proposes an extension of cycle-consistent adversatial adaptation methods in order to tackle domain adaptation where limited supervised target data is available. This paper introduces a domain adaptation approach based on the idea of Cyclic GAN and proposes two different algorithms.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Augmented Cyclic Adversarial Learning for Low Resource Domain Adaptation\",\n          \"Learning to Rank Learning Curves\",\n          \"Local Stability and Performance of Simple Gradient Penalty $\\\\mu$-Wasserstein GAN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"number_words_target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 34,\n        \"max\": 64,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          34,\n          64,\n          62\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"extractive_summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"However, it is challenging to specify a meaningful and tractable prior over the network parameters, and deal with the weight correlations in the posterior. To this end, this paper introduces two innovations: (i) a Gaussian process-based hierarchical model for the network parameters based on recently introduced unit embeddings that can flexibly encode weight structures, and (ii) input-dependent contextual variables for the weight prior that can provide convenient ways to regularize the function space being modeled by the network through the use of kernels. \\n The question of which priors one should use for Bayesian neural networks is largely unanswered, as two considerations need to be balanced: First, we want to keep inference in the high dimensional weight posterior tractable; Second, we desire to express our beliefs about the properties of the modeled functions compactly by modeling the collection of weights. In order to cope with richer posterior inference than mean-field typically achieves, a variety of structured posterior models have been proposed recently, for instance utilizing radial posteriors (Oh et al., 2019) , or rich weight posteriors based on Gaussian processes (Louizos and Welling, 2016) . When it comes to modeling priors on weights with correlations, recent work has attempted to capture feature-level correlations using for instance a horseshoe prior (Ghosh et al., 2018) . One interesting direction of inquiry has focused on utilizing hyper-networks in order to model distributions over weights for an entire network (Ha et al., 2016; Pradier et al., 2018) , or alternatively to utilize unit-level level variables combined with compact hyper-networks to regress to single weights and capture weight correlations through the auxiliary variables (Karaletsos et al., 2018) . We explore the use of compositional kernels to add input-dependence to the prior for our model and obtain rich models with beneficial properties in tasks such as active learning, and generalization, while maintaining tractable inference properties. In (Karaletsos et al., 2018 ) each unit (visible or hidden) of the l-th layer of the network has a corresponding latent hierarchical variable z l,i , of dimensions D z , where i denotes the index of the unit in a layer. Notice that in Sec.2, the meta mapping from the hierarchical latent variables to the weights is a parametric non-linear function, specified by a neural network. Notably, while the number of latent variables and weights can be large, the input dimension to the GP mapping is only 2D z , where D z is the dimensionality of each latent variable z. The GP mapping effectively performs one-dimensional regression from latent variables to individual weights while capturing their correlations. That is, a function drawn from the model, represented by a set of weights, does not take into account the inputs at which the function will be evaluated. We study our suggested priors empirically in two distinct settings in the following: first, we study the effect of kernel choice in the local model for a regression problem where we may have available intuitions as inductive biases. We test an array of models and inference methods, including BNN with MFVI, metaGP and metaGP with contextual variables. We first train a neural network classifier with one hidden layer of 100 rectified linear units on the MNIST dataset, and apply the metaGP prior only to the last layer of the network. Whilst the diagonal approximation above might look poor from the first glance, it is conditioned on a sample of the latent variables z k and thus the weights' correlations are retained after integrating out z. Such correlation is illustrated in 4 where we show the marginal and conditional covariance structures for the weights of a small neural network, separated into diagonal and full covariance models. The final lower bound is then optimized to obtain the variational parameterers of q(u), q(z), and estimates for the noise in the meta-GP model, the kernel hyper-parameters and the inducing inputs.\",\n          \"A common technique to determine the likelihood of no improvement is to compare the learning curve of a new configuration to the one of the currently best configuration. Other methods do not have this disadvantage, but require sufficiently long learning curves to make reliable predictions which again means unnecessary overhead (Domhan et al., 2015) . Many of these methods also do not take into account other information such as the hyperparameters of the model being examined or its network architecture. But since we are not interested in predicting the performance of a model anyway, we use a ranking model that models the probability that the model currently being investigated surpasses the best solution so far. We use the term final learning curve to explicitly denote the entire learning curve, y 1 , . . . The first model is trained to completion and is considered as the current best model m max with its performance being y max . In this section, we first discuss how to create the meta-knowledge and then analyze our model in terms of learning curve ranking and the ability to use it as a way to accelerate Neural Architecture Search. If there are no or only very short partial learning curves available, our method shows the biggest difference to the existing methods. The method of Domhan et al. (2015) requires a minimum length of the learning curve to make predictions. One of our observations is that Domhan et al. (2015) 's method underestimates performance when the learning curve is short. As a result, the method ends each training process early after only a few epochs. The simple reason is that the number of runs terminated and the time they are discarded are fixed by the algorithm and do not rely on the properties of the learning curve. However, the learning curve of m max approaches the values of m and then the probability decreases and training is stopped early. If only the learning curve is considered, the results are not very good at first, but improve significantly with the length of the learning curve. Although our assumption was that the latter would have to be fundamentally better, since it optimizes the model parameters directly for the task at hand, in practice this does not necessarily seem to be the case. The two main novelties of the underlying model are that it is able to consider learning curves from other data sets and that it uses a pairwise ranking loss.\",\n          \"One way of learning such mappings is through Generative Adversarial Networks (GANs BID8 with cycle-consistency constraint (CycleGAN Zhu et al., 2017) , which enforces that mapping of an example from the source to the target and then back to the source domain would result in the same example (and vice versa for a target example). Importantly, for the learned mapping to be meaningful, it is not necessary to have the exact reconstruction. To address this issue, we propose an augmented cyclic adversarial learning model (ACAL) for domain adaptation. On the other hand, the task specific model also serves as an additional source of information for the corresponding domain and hence supplements the discriminator in that domain to facilitate better modeling of the distribution. For example, BID15 applies the marginal Fisher analysis criteria and Maximum Mean Discrepancy (MMD) to minimize the distribution difference between source and target domain. In addition to the relaxed model, the task specific model is also used to augment the discriminator of corresponding domain to facilitate learning. To address these two problems, we propose to 1) use a task specific model to enforce the cycle-consistency constraint, and 2) use the same task specific model in addition to the discriminator to train more meaningful cross domain mappings. The difference is that the model is only required to preserve DISPLAYFORM2 end end useful information regarding X respect to predicting Y , for modeling the conditional distribution, which makes learning the conditional model a much easier problem. To get an idea of the contribution from each component of our model, in this section we perform a series of ablations and present the results in TAB0 . It is also interesting to examine the importance of the double cycle, which is proposed in BID39 and adopted in our work. Theoretically, one cycle would be sufficient to learn the mapping between domains; therefore, we also investigate the performance of one cycle only models, where one direction would be from source to target and then back, and similarly for the other direction. Interestingly, the one cycle relaxed and one cycle augmented models are similar to the model proposed in BID12 when their model performs mapping from source to target domain and then back. As such, the resulting learned mapping functions would preserve meaningful semantics of the data while transferring the styles to the target domain, and vice versa. Low-resource supervised adaptation: In this setting, we sub-sample the target to contain only a few labeled samples per class, and using the other full dataset as the source domain. Each column illustrates the mapping performed by each of the models from the original SVHN image (source domain) to MNIST (target domain, 10 labeled samples per class in total). It can be seen that the augmented cycle-consistent model is able to preserve most of the semantic information, while still approximately match the target distribution.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "\n",
        "# Shuffle target sentences\n",
        "data['target'] = data['target'].apply(shuffle_list)"
      ],
      "metadata": {
        "id": "03zjLD42tXLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count number of words of source and target\n",
        "def count_words(data, column):\n",
        "  return data[column].apply(lambda x : len(x.split()))\n",
        "\n",
        "data['number_words_target'] = count_words(data, 'target')\n",
        "data['number_words_source'] = count_words(data, 'source')\n",
        "data['number_words_extractive'] = count_words(data, 'extractive_summary')"
      ],
      "metadata": {
        "id": "eoYG245eurut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['number_words_target'].describe())\n",
        "print(data['number_words_source'].describe())\n",
        "print(data['number_words_extractive'].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjsgp2YRUwZ1",
        "outputId": "66ab2b05-9266-4c9c-ac0c-20b3ae8d499b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    1312.000000\n",
            "mean       58.935213\n",
            "std        20.402388\n",
            "min        30.000000\n",
            "25%        41.000000\n",
            "50%        58.000000\n",
            "75%        73.000000\n",
            "max       149.000000\n",
            "Name: number_words_target, dtype: float64\n",
            "count     1312.000000\n",
            "mean      5177.437500\n",
            "std       2107.094236\n",
            "min        126.000000\n",
            "25%       4069.750000\n",
            "50%       5001.500000\n",
            "75%       6187.750000\n",
            "max      24589.000000\n",
            "Name: number_words_source, dtype: float64\n",
            "count    1312.000000\n",
            "mean      621.176067\n",
            "std       143.951058\n",
            "min       126.000000\n",
            "25%       534.000000\n",
            "50%       611.000000\n",
            "75%       693.000000\n",
            "max      1199.000000\n",
            "Name: number_words_extractive, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogramas\n",
        "data.hist(bins=30)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "ip8aBXD3ZCuc",
        "outputId": "883ef477-82c0-4da3-f322-f156dfa5361e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter summaries whose length is less than 40 words\n",
        "data = data[data['number_words_target']>=40].reset_index(drop=True)\n",
        "data['number_words_target'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOCCUFXpg772",
        "outputId": "c160ebc3-dfdb-4719-bbfd-d4b4278e035a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    1012.000000\n",
              "mean       66.381423\n",
              "std        17.169049\n",
              "min        40.000000\n",
              "25%        54.000000\n",
              "50%        64.000000\n",
              "75%        77.000000\n",
              "max       149.000000\n",
              "Name: number_words_target, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Substitute synonyms words\n",
        "synonyms_paper = ['paper', 'study', 'work', 'article']\n",
        "articles = ['The', 'the', 'This', 'this', 'A', 'a', 'An', 'an']\n",
        "\n",
        "data['extractive_summary'] = data['extractive_summary'].apply(lambda x : substitution(x, synonyms_paper, articles))\n",
        "data['target'] = data['target'].apply(lambda x : substitution(x, synonyms_paper, articles))"
      ],
      "metadata": {
        "id": "WVce8pJfdwFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data in different sets\n",
        "data_training, data_test = train_test_split(data,\n",
        "                                      test_size=0.20,\n",
        "                                      shuffle=True,\n",
        "                                      random_state=42)\n",
        "\n",
        "data_train, data_val = train_test_split(data_training,\n",
        "                                        test_size=0.20,\n",
        "                                        shuffle=True,\n",
        "                                        random_state=42)"
      ],
      "metadata": {
        "id": "2cBrIvVfpgqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(data_train['number_words_source'], bins=25, edgecolor='black', alpha=0.5, label='Training')\n",
        "plt.hist(data_val['number_words_source'], bins=25, edgecolor='black', alpha=0.5, label='Validation')\n",
        "plt.hist(data_test['number_words_source'], bins=25, edgecolor='black', alpha=0.5, label='Test')\n",
        "\n",
        "\n",
        "plt.xlabel('Nº of words in document')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "FzpOP09JQyTU",
        "outputId": "b4e8b8f4-7f01-4fcd-aafb-39e6ce01ed69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7d062909e770>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(data_train['number_words_target'], bins=25, edgecolor='black', alpha=0.5, label='Training')\n",
        "plt.hist(data_val['number_words_target'], bins=25, edgecolor='black', alpha=0.5, label='Validation')\n",
        "plt.hist(data_test['number_words_target'], bins=25, edgecolor='black', alpha=0.5, label='Test')\n",
        "\n",
        "\n",
        "plt.xlabel('Nº of words in target')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "OC8JMu-aUOHV",
        "outputId": "9f972ecb-1a0a-4dc2-daf3-08914382e4cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7d0629afb6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_test.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "o46lFUVw5taI",
        "outputId": "2dfdd86a-715b-449a-e318-d08971af0759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                source    paper_id  \\\n",
              "631  With the recently rapid development in deep le...  ByxmXnA9FQ   \n",
              "634  Neural machine translation (NMT) models learn ...  H1z-PsR5KX   \n",
              "963  Recent results from linear algebra stating tha...  SkeUG30cFQ   \n",
              "625  Analogical reasoning has been a principal focu...  SylLYsCcFm   \n",
              "365  Recent advances in computing technology and se...   ByJbJwxCW   \n",
              "\n",
              "                                                target  \\\n",
              "631  A new framework based variational inference fo...   \n",
              "634  Unsupervised methods for finding, analyzing, a...   \n",
              "963  We provide a theoretical study of the properti...   \n",
              "625  The most robust capacity for analogical reason...   \n",
              "365  We propose a deep Multi Instance Learning fram...   \n",
              "\n",
              "                                                 title  number_words_target  \\\n",
              "631  A Variational Dirichlet Framework for Out-of-D...                   78   \n",
              "634  Identifying and Controlling Important Neurons ...                   54   \n",
              "963  The Expressive Power of Deep Neural Networks w...                   54   \n",
              "625  Learning to Make Analogies by Contrasting Abst...                   67   \n",
              "365  Relational Multi-Instance Learning for Concept...                   97   \n",
              "\n",
              "                                    extractive_summary  number_words_source  \\\n",
              "631  Therefore, it is very essential to design a ro...                 3289   \n",
              "634  First, it targets the whole vector representat...                 4933   \n",
              "963  Recent results from linear algebra stating tha...                 4143   \n",
              "625  It is natural to consider, however, whether th...                 6473   \n",
              "365  Most of the medical time series lack annotatio...                 4819   \n",
              "\n",
              "     number_words_extractive  \n",
              "631                      695  \n",
              "634                      456  \n",
              "963                      594  \n",
              "625                      673  \n",
              "365                      513  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6399f330-5b4d-422d-9781-cedbccc606b3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>paper_id</th>\n",
              "      <th>target</th>\n",
              "      <th>title</th>\n",
              "      <th>number_words_target</th>\n",
              "      <th>extractive_summary</th>\n",
              "      <th>number_words_source</th>\n",
              "      <th>number_words_extractive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>631</th>\n",
              "      <td>With the recently rapid development in deep le...</td>\n",
              "      <td>ByxmXnA9FQ</td>\n",
              "      <td>A new framework based variational inference fo...</td>\n",
              "      <td>A Variational Dirichlet Framework for Out-of-D...</td>\n",
              "      <td>78</td>\n",
              "      <td>Therefore, it is very essential to design a ro...</td>\n",
              "      <td>3289</td>\n",
              "      <td>695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>634</th>\n",
              "      <td>Neural machine translation (NMT) models learn ...</td>\n",
              "      <td>H1z-PsR5KX</td>\n",
              "      <td>Unsupervised methods for finding, analyzing, a...</td>\n",
              "      <td>Identifying and Controlling Important Neurons ...</td>\n",
              "      <td>54</td>\n",
              "      <td>First, it targets the whole vector representat...</td>\n",
              "      <td>4933</td>\n",
              "      <td>456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>963</th>\n",
              "      <td>Recent results from linear algebra stating tha...</td>\n",
              "      <td>SkeUG30cFQ</td>\n",
              "      <td>We provide a theoretical study of the properti...</td>\n",
              "      <td>The Expressive Power of Deep Neural Networks w...</td>\n",
              "      <td>54</td>\n",
              "      <td>Recent results from linear algebra stating tha...</td>\n",
              "      <td>4143</td>\n",
              "      <td>594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625</th>\n",
              "      <td>Analogical reasoning has been a principal focu...</td>\n",
              "      <td>SylLYsCcFm</td>\n",
              "      <td>The most robust capacity for analogical reason...</td>\n",
              "      <td>Learning to Make Analogies by Contrasting Abst...</td>\n",
              "      <td>67</td>\n",
              "      <td>It is natural to consider, however, whether th...</td>\n",
              "      <td>6473</td>\n",
              "      <td>673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365</th>\n",
              "      <td>Recent advances in computing technology and se...</td>\n",
              "      <td>ByJbJwxCW</td>\n",
              "      <td>We propose a deep Multi Instance Learning fram...</td>\n",
              "      <td>Relational Multi-Instance Learning for Concept...</td>\n",
              "      <td>97</td>\n",
              "      <td>Most of the medical time series lack annotatio...</td>\n",
              "      <td>4819</td>\n",
              "      <td>513</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6399f330-5b4d-422d-9781-cedbccc606b3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6399f330-5b4d-422d-9781-cedbccc606b3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6399f330-5b4d-422d-9781-cedbccc606b3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4c7591fb-08a9-47f6-a261-0ed627f6186c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4c7591fb-08a9-47f6-a261-0ed627f6186c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4c7591fb-08a9-47f6-a261-0ed627f6186c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_test",
              "summary": "{\n  \"name\": \"data_test\",\n  \"rows\": 203,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 203,\n        \"samples\": [\n          \"Quantum computers promise significant advantages over classical computers for a number of different applications. We show that the complete loss function landscape of a neural network can be represented as the quantum state output by a quantum computer. We demonstrate this explicitly for a binary neural network and, further, show how a quantum computer can train the network by manipulating this state using a well-known algorithm known as quantum amplitude amplification. We further show that with minor adaptation, this method can also represent the meta-loss landscape of a number of neural network architectures simultaneously. We search this meta-loss landscape with the same method to simultaneously train and design a binary neural network. Finding a suitable set of weights for a neural network has become one of the most studied problems of modern machine learning. It has presented a significant challenge to computer scientists for whom few successful alternatives to back-propagation are available. It can be difficult to explore very large search spaces efficiently and, worse, optimization may converge to a local minima far from global optimum BID2 . Understanding the cost function landscape is also hard, and choosing hyper-parameters and designing neural networks remains mostly a manual process. As Moore's law approaches its end, two new computing paradigms have been explored, neuromorphic and quantum computers. Quantum computing is based on quantum bits (or qbits) obeying the laws of quantum physics as opposed to the classical bits of today that are based on classical physics. Note that in physics the term classical is used to mean non-quantum and we use this terminology throughout. Quantum machine learning aims to find an advantage in applying quantum computing to machine learning. Current research into quantum machine learning falls into one of two catgeories. Some quantum algorithms promise a revolution in machine learning in theory, but contain many gaps in their implementation in practice. In contrast, others are more realistic in their method, but struggle to justify a place amongst the well-established methods of machine learning. In this paper, it is shown that a quantum computer can output a quantum state that represents the entire cost landscape for a given neural network. The method is shown to be versatile and even able to represent a meta-cost landscape of all possible hyperparameters and parameters. Applying it to the connectivities and weights of a binary neural network and simulating the quantum algorithm on a classical computer, we further show that this landscape state can be used for training and metatraining the binary neural network for a small toy problem using quantum amplitude amplification, a standard quantum algorithm. Binary Neural Networks (BNNs) are neural networks with weights and activations restricted to taking only binary values, usually \\u00b11. The greatest advantage of BNNs is in their deployment as using binary provides great advantages in compression and inference time, as well as computational efficiency through the use of bitwise operations. On the other hand they are relatively tricky to train as the sign function has a derivative of zero nearly everywhere, the search space is discrete, and alternative training methods take significantly longer than non-binarized neural networks. Nonetheless, BNNs have achieved state-of-the-art performance on smaller datasets such as MNIST and CIFAR10 BID4 but initially suffered when applied to larger datasets such as ImageNet. A popular approach to solving this issue has been to relax the binarisation constraints. This has been achieved by using multiple binary activations BID13 or by introducing scale factors BID16 , both of which result in improvements in accuracy. On the other hand, it has been argued that a better training strategy for BNNs is sufficient to achieve high accuracy on large datasets without compromising on the pure binary nature BID22 . After investigating the accuracy failures of the previous methods, a number of improvements to the BNN training process have been suggested such as changing the activation function, lowering the learning rate and using a different regularization term. These changes helped achieve both high accuracy and high compression rates on ImageNet. Again, this solution is not entirely ideal, as training BNNs is already relatively slow, and a lower learning rate exacerbates this issue. Between the efficient deployment, discrete search space, slow training and relatively small problem size (near-term quantum computers favor problems that require fewer bits), training a binary neural network represents an ideal test case for a quantum computer. Finally, BNNs have been suggested as a candidate for efficient hybrid architectures through transfer learning. The idea is that a BNN pretrained on ImageNet may be used as a feature extractor for other datasets by retraining a final non-binarised layer. In this way, a hybrid hardware-software architecture can implement the binary part using efficient hardware and the non-binary final layer in software BID12 . Quantum computers use quantum bits, manipulated with quantum gates in quantum circuits according to quantum algorithms. The advantage of quantum computers over classical computers is that certain quantum algorithms show significantly improved computational complexity compared to the best known classical algorithms. Such improved scaling, combined with the exponentially growing computational power of qubits suggests that (large, error-free) quantum computers would be able to easily handle and process very large amounts of data. Most relevant to this paper is the quantum search algorithm known as Grover's algorithm BID8 , itself a specific case of another algorithm known as quantum amplitude amplification BID0 . These algorithms can search for an element of an unstructured dataset of size N in O( \\u221a N ) operations, over the classical O(N ). It is important to keep in mind that these are compared to the best-known classical algorithms, and not that they are better than all possible classical algorithms. A recent paper BID21 has challenged the presumed superiority of a quantum recommendation algorithm with a new classical algorithm inspired by the quantum method that shows similar scaling. In our case, the optimality of Grover's algorithm has been proven BID24 and so the assumption of its inherent advantage is robust. Some quantum algorithms are able to efficiently perform k-means clustering BID14 and solve linear systems of equations BID9 , among other such achievements (see BID3 for a review). All of these algorithms require the classical data to be encoded into an accessible quantum form of RAM known as a qRAM. Although there is some work on how this might be done BID7 it is not known to even be possible to construct a qRAM in an efficient manner for a completely general dataset. To many, this is a significant drawback that cannot be ignored, and places a heavy burden on the feasibility of these methods. An alternative approach has been to mimic the progress of classical machine learning by using methods classically known to work. Many have taken to using classical computers to train parametrized quantum circuits to perform classification BID19 or to learn generative models BID6 . Some, but not all, of these circuits mimic neural networks in that they are layered and try to utilize non-linearities . The biggest issue with this approach is the lack of an efficient algorithm for training quantum circuits and so current methods are akin to black box optimization. The motivation is that the output of quantum circuits are known to be impossible to efficiently simulate with classical computers and could therefore provide superior performance on that basis. A slightly different approach to training a perceptron using quantum amplitude amplification has been explored before and its complexity studied compared to classical methods BID10 . Previous work has demonstrated and experimentally implemented the use of quantum hardware to perform binary classification, BID15 ) but this is not the same as the method proposed in this paper, as this work is based on a different, more general gate-based form of quantum computation as opposed to the quantum annealing devices of the former. Quantum computing follows the structure of classical computing very closely. Quantum bits, or qubits, are the fundamental unit of quantum information. Their values are manipulated by applying quantum (logic) gates to them in the form of quantum circuits. Qubits are challenging to manufacture in practice due to the noise-sensitive nature of quantum properties. The biggest such device in existence today contains just 72 highly imperfect qubits, but it is worth noting that progress has advanced at a particularly rapid pace over the past few years and a number are available for public access on the cloud. In addition, simulating the behaviour of qubits using classical computers is difficult, requiring exponentially increasing resources as the number of qubits increases -with an upper limit of 50 (perfect) qubits often cited for the most powerful supercomputers. Therefore, quantum algorithms are almost always defined in terms of their circuit implementation, as opposed to the higher level abstraction of classical algorithms. Qubits are the unit of quantum information and are fundamentally different to classical bits. Whilst classical bits are completely described as being in one of two states, either 0 or 1, the state of a qubit cannot be fully described by just a single number. It can be in the 0 state, the 1 state or a quantum superposition of both. Mathematically the state of a qubit is a two dimensional vector with complex elements and a unit norm. We can write a general form for this vector as DISPLAYFORM0 Here \\u03b1 and \\u03b2 are the probability amplitudes of the zero state |0 and the one state |1 respectively. Qubits cannot be simply read out as classical bits are, but are instead measured. Measurement is a unique feature of quantum mechanics. If the qubit given above is measured, it will be found in the zero state with probability |\\u03b1| 2 , outputting a value of 0, and the one state with probability |\\u03b2| 2 outputting a value of 1. Therefore measurement of a qubit state always produces a binary outcome, no matter the actual state itself. Measurement is fundamentally indeterministic, probabilistic and irreversible. Upon measurement, the original state is lost along with the values of \\u03b1 and \\u03b2 as the qubit collapses to the state |0 or |1 corresponding to the measurement outcome. As a result, the values \\u03b1 and \\u03b2 cannot be obtained without repeated measurements of many identical copies of the state. Here \\u03c6 is a phase that does not affect measurement outcome, but can be manipulated with quantum gates and play a role in quantum algorithms. Part of the power of quantum computing is the ability to harness superposition to parallelize certain computations and processes. An important feature of qubits is the way in which they are combined. N qubits are collectively described by a complex vector of unit norm in a similar way as the above, but the length of this vector is given by 2 N . It is this exponential scaling that makes even modest numbers of qubits unfeasible to simulate on a classical computer. In both classical and quantum computing, gates manipulate the states of bits and qubits. As complex vectors, qubit states are transformed into one another by applying complex matrices called operators or simply, quantum gates. This transformation follows the rules of linear algebra and a state |\\u03c8 is transformed into a different state |\\u03c6 by a gate U according to the matrix transformation |\\u03c6 = U |\\u03c8 . In order to maintain the stringent requirement of a unit norm, these matrices are restricted to being unitary. A unitary matrix is defined as any square matrix who's inverse is its complex conjugate transpose. Unitarity implies that every quantum gate is reversible, in a manner similar to reversible computing. This fundamental difference in the kinds of operations that can be performed on qubits compared to classical bits is part of the power of quantum computing, but can make analogies to classical computing difficult. Many quantum operations have no classical analogue and conversely, certain simple classical operations (e.g copying the state of a general qubit) are impossible in quantum computing. Just as in classical computing, small sets of quantum gates are universal in that they can be combined to generate any other. It transpires that a small set of quantum gates are sufficient to our work and we choose to list them here, both in terms of their actions and their matrix forms. The X (NOT) gate flips the state of a qubit from |1 to |0 and vice versa. For qubits in superposition, it swaps the amplitudes of the |1 and |0 states. Its matrix form is DISPLAYFORM0 The Z gate has no classical analogue and takes the matrix form DISPLAYFORM1 It transforms an arbitrary state \\u03b1 |0 + \\u03b2 |1 into the state \\u03b1 |0 \\u2212 \\u03b2 |1 . The probability amplitude of the |1 component has changed sign, but the probabilities associated with measurement outcome, as squares of the probability amplitudes, remain unchanged. Note that this still represents a completely different state. The Hadamard (H) gate also has no classical analogue. It is used to transform qubits from their initial state |0 into the state DISPLAYFORM2 |1 -an equal quantum superposition of 0 and 1. As a matrix it is DISPLAYFORM3 The controlled-not (CNOT) gate can be thought of as a generalisation of the classical XOR gate. It performs a NOT gate on a target qubit if a control qubit is in the state |1 . We write this as DISPLAYFORM4 Note that controlled gates can be extended both to arbitrary gates (e.g. CZ) and to arbitrary numbers of control qubits (e.g. CCCNOT). The main advantage of qubits over classical bits is their ability to be placed and processed in quantum superpositions of states. The key to our method is to use superposition to parallelize the processing of weights in a way not possible classically. Our scheme proceeds as follows: Step 1: The weights are represented in some way by the quantum state of a set of qubits. Setting those qubits into a state that represents an equal superposition of every possible set of weights allows them to define the domain. Step 2: We then build a quantum circuit analogue of the neural network U QN N that takes in a given set of weights (encoded within qubits as above) and an empty register, and outputs onto the register the corresponding accuracy according to the chosen neural network i.e U QN N (w, 0) = (w, acc w ).Step 3: Since U QN N is a quantum circuit, inputting weights in superposition form allows them to be processed in parallel. Thus by using the domain-defining qubits as the weights input to U QN N the output will be a superposition correlating all possible weights to their corresponding accuracies. This is what we refer to as the landscape state. We can write this as DISPLAYFORM0 where W is the set of all possible weights, W is its size and O w the accuracy of the neural network given the set of weights w. This is a single quantum state representing the entire landscape of the neural network by correlating every possible set of weights with its resultant accuracy. In the language of quantum physics the weights and the accuracies are entangled. This method can be adapted in many ways. For example, if just a single weight is set it to superposition and the rest kept to a given value, then the output is the cost landscape of just that one weight conditional on the value of the others. We are not limited to only setting weights in superposition. We note that a meta-neural network with the presence/absence of the connections within the neural network themselves represented by binary parameters can also be created. These meta-parameters can also be encoded in qubits, formed into a quantum circuit and set to superposition. If we set both the weights and the connection meta-parameters to superposition then the output state of the quantum circuit contains an entire meta-cost landscape of every possible weight with every possible connectivity of a neural network simultaneously correlated with the respective accuracy. We demonstrate our method by generating the landscape state for a small binary neural network on simple toy problems and use it to train the network. The advantage of binary neural networks is that each weight can be naturally represented by just one qubit and so are therefore a suitable demonstration given the fundamentally small number of qubits that can be simulated on a nonquantum device. We construct two toy problems, both of which are a binary classification on three binary features x i \\u2208 {\\u22121, 1} of eight data points corresponding to every 2 3 arrangement of those features. In problem 1, the label is given by the function DISPLAYFORM0 and for problem 2 the label is given by DISPLAYFORM1 In both cases we define the sign function as: DISPLAYFORM2 We choose to implement the BNN given in figure 1 meaning that we are aiming to find eight binary weights. To construct a quantum circuit equivalent to the BNN, henceforth known as the Quantum Binary Neural Network (QBNN), every operation in the implementation of a BNN must be mapped to a quantum equivalent. Below we detail each of these and their quantum implementation. Representing numerical values with qubits is already well established in the literature BID20 . Other parts of our construction are, however, incompatible with non-binary input and so we restrict ourselves to the simple case of a binary data input. In this case, the qubit states |1 and |0 represent the values +1, \\u22121 respectively. In a quantum circuit, all qubits begin in the |0 state and need only an application of a single NOT gate to be set to |1 where appropriate. Given two qubits representing binary values \\u00b11 as described above, we can multiply them using an anti-CNOT gate. An anti-CNOT gate applies a NOT gate to a target qubit if the control qubit is in the state |0 instead of |1 . Its truth table is identical to an XNOR gate and outputs |1 if both input values are equal, and |0 otherwise. This truth table matches the truth table of multiplying two binary values and thus performs the same function. It can be constructed using two NOT gates and a CNOT gate. Qubits that encode weights must always be used as control qubits to preserve the values they encode. Since the sign function is highly non-linear, it poses the greatest challenge to translate to the linear algebra-based language of quantum mechanics. Generally, the problem can be overcome by the addition of extra helper or 'ancilla' qubits. If we restrict the problem to the special case of binary arguments only, the sign function 1 is reduced to finding whether there exist N/2 qubits out of N in state |1 . This can be achieved by constructing a quantum analogue of a classical majority function by replacing AND gates with CCNOT gates and constructing OR gates out of CNOT and NOT gates. The number of gates needed scales as the binomial coefficient N choose N/2. As an example, figure 2 shows a three input neuron and its quantum circuit implementation. Note that this is just a single neuron, and not our entire network. In practice, it works in the same manner as a classical neural network. The activations of each neuron in one layer are then weighted by their own weight qubits and used as input to the next layer and so on. This whole circuit is what we refer to as the QBNN. For each data point on the training set we must compare the prediction to the label in order to find the accuracy. We initialise a register of qubits to store the predictions. The reversibility of quantum circuits allows us to apply the QBNN for a given data point, store its output value onto its corresponding qubit on the register, perform the same QBNN in reverse order -its inverse -to refresh the other qubits, and continue for the next data point in the training set. This resetting is a common, necessary workaround for small quantum computers and is easily avoided by parallelization given more qubits. For a training set of size N , we obtain a register of N qubits containing the predictions of the QBNN for each of them. Since both the labels and the outputs are binary, we can represent the accuracy of each of these predictions by performing a NOT gate on all the qubits corresponding to a data point with a label of 0. Each qubit in this register will then be in the state |1 if it corresponds to a correctly classified data point and |0 if it does not. By applying the QBNN over the entire training set with the weights initialized in superposition, our circuit output is the cost landscape state. Training the BNN can be seen as a search for a single state within the cost function landscape, for which we use a quantum algorithm known as quantum amplitude amplification. It is not the first time that quantum amplitude amplification has been suggested as a means to train quantum neural networks BID17 ), but they did not construct the actual details of an implementation such as the method of generating a nonlinearity. Quantum amplitude amplification is a technique to amplify the probability amplitudes that correspond to desired state(s) within the superposition and therefore increase the probability of measuring one of these. It works by splitting the space of all states into a 'good' and a 'bad' subspace and rotating their relative probabilities when measured. In this case the 'good' subspace is defined as that which has all the qubits in the prediction register in the state |1 implying that all data points have been correctly classified. It is known that quantum amplitude amplification requires just O(1/ \\u221a a) to search for an entry with an occurrence probability of a BID0 . Quantum amplitude amplification works by first constructing the amplifying operator, Q. DISPLAYFORM0 The composite operation, Q, is interpreted as a sequence of operations applied from right to left as read in the equation above. U QBN N is our entire QBNN circuit (for all data points), and U \\u22121 QBN N is its (matrix) inverse. Since quantum gates are reversible, and every gate we have used is self-inverse, we obtain this by applying all of the gates of U QBN N in reverse order. The operations S 0 and S \\u03c7 reverse the sign of the probability amplitudes of the initial state and the target state(s) respectively. In this case, our target states correspond to those with an accuracy of 100% and S \\u03c7 is a controlled-Z gate performed on each of the target qubits. Similarly, the initial state of any quantum computer is defined as having all the qubits in the state |0 , and thus we can implement S 0 by first applying a NOT gate to each qubit and then applying the same controlled-Z gates as for S \\u03c7 . FIG2 is a pictorial representation of how quantum amplitude amplification changes the probability distribution of the measured weights. If we write the initial probability of obtaining the correct weights by random as p and the number of successive applications of operator Q to be k, it can be shown that the probability of obtaining the optimal weights when measuring the circuit after k amplifications is sin 2 (2k + 1)\\u03b8where p and \\u03b8 obey the relation p = sin 2 \\u03b8 BID0 . The probability of success is therefore highly periodic in k. The problem of training the BNN essentially reduces to a probabilistic search on this one hyper-parameter and its regular periodic landscape. The location of the first maximum, i.e of k * , is inversely proportional to \\u03b8 and hence to the probability of obtaining the weights by random. In other words, a harder problem with more weights to search requires a greater number of quantum amplifications to find. In practical terms the landscape state is a set of 8 weight qubits and 8 prediction qubits. After the search, at the end of the entire process, all the qubits are measured. If the prediction qubits are all in the state |1 the training was a success and the appropriate weights can be simply read off their corresponding qubits. We constructed and simulated the QBNN and quantum amplitude amplification circuits on the projectQ framework BID18 . The use of an actual quantum computer was not possible as the number of gates used during the computation (called circuit depth) exceeds the maximum possible circuit depth for the current generation of imperfect noisy qubits. Furthermore, we use more qubits than are available on current publicly accessible quantum hardware. For each of the two problems defined, we plotted the probability of obtaining an optimal set of weights against the number of iterations of the quantum amplitude amplification and obtained results, shown in FIG3 , that match well with the expected periodic behavior described in equation 3. This confirms that a quantum search of the landscape state can indeed be used to train a BNN in exactly the manner as predicted theoretically. We emphasize here that every reference to finding optimal weights means that the BNN has been trained to an accuracy of 100% on the training data. In order to demonstrate the performance of this method in actual training, we follow the simple algorithm described in BID0 for probing this landscape. This simple algorithm begins with n = 0 and chooses a random integer k of quantum amplifications between 0 and n. n increases by 1 until the training succeeds. In our experiment, we perform 100 runs of this algorithm and present in figure 5 a cumulative plot of the proportion of these runs that were successful against the number of iterations this algorithm required. We find that training succeeds with a probability over 90% after just 5 steps for the first problem and 6 steps for the second. In order to compare this to a classical search, we search the entire space of 2 8 = 256 possible sets of weights and find that there are eight and four correct sets of weights (giving 100% accuracy) for the first and second problem respectively. Statistically, if these weights were to be searched through the analogous classical brute data is the cumulative probability of success over 100 runs of the algorithm. Classical results are analytically derived from the known probability of obtaining a solution by random search. The superior scaling of the quantum algorithm becomes more prominent for harder problems.force search, one would find that it requires 28 and 57 steps respectively to succeed with a confidence over 90%. This matches our expectation of a quadratic speedup of the quantum search over the classical. We then construct a more complex QBNN which can incorporate meta-training by introducing a set of binary indicators that correspond to the presence or absence of a set of connections within the BNN and encode these within qubits in the exact same way as was done with the weights. With the weights and connection parameters both set to superpositions, the output of this circuit is the meta-cost landscape, where weights, connections and accuracy are all entangled with one another. As before quantum amplitude amplification is used to search for the state with all points correctly classified. Again this has been suggested before, but we present a full circuit implementation of this idea (da BID5 . In practice, due to qubit number constraints, we choose to only learn the structure of the first layer of the BNN. The second layer remains fixed. Due to the increased size of the circuit, and the significant increase in computational cost, we did not perform a complete classical search of the space as before but it is clear to see that the space of parameters we are searching has increased and therefore the number of amplifications required has similarly increased. Between 16 and 20 amplifications were found to be sufficient to produce results with a reasonable probability. FIG5 (a) shows the meta-BNN that was used, and (b) and (c) show two solutions to problems 1 and 2 respectively learnt by our meta-QBNN. It is particularly interesting to note that the learned structures of the two BNN solutions seem to match well with their problem definitions (equation 1 and equation 2). Note that due to our circuit construction a neuron that receives no input will always output \\u22121. We show that quantum superposition can be used to represent many parameters of a neural network at once and efficiently encode entire loss landscapes in a quantum state using just a single run of a quantum circuit. We demonstrate this explicitly for both parameters and hyper-parameters of a BNN, and show that further processing of this state can lead to quantum advantage in training and metatraining. As a training method it possesses significant advantages as it is landscape-independent, has a quadratic speedup over a classical search of the same kind, and would be able to solve statistically neutral problems such as parity problems BID23 . It is not, however, without shortcomings. One potential criticism is the issue of over-fitting. Since our problem is so small, we chose to define a target state as one where the accuracy is 100% on the training set but this is rarely desirable in real machine learning. One solution may be to simply run the quantum algorithm and, upon finding a particular set of weights that represents an overfit, run the algorithm again but with a deselection of that particular set of weights. This can be done by simply changing the sign of the probability amplitude corresponding to that state during each iteration of the quantum amplitude amplification. A similar issue is that regular machine learning typically uses batch learning, whilst our method incorporates the entire dataset at once. This too can be fixed by altering our method to use a different batch of the data for each quantum amplitude amplification iteration. This works since no matter what batch we use, a good set of weights should still be amplified by the circuit. In fact, such an implementation is advantageous since it would allow us to use less qubits which in practical terms are limited in number in the near term. A significant limitation in our method is the requirement that the input is binary, and the poor scaling of the activation function. Both of these problems arise completely from our implementation of the sign function, which could either be improved or replaced entirely with a different binary activation function that could be implemented more efficiently on a quantum computer and would be compatible with non-binary input. There has been progress on creating effective non-linear activation functions by so-called repeat-until-success circuits BID1 ). An alternative approach would be to use floating point representations as in classical computing and the quantum equivalent of full-adders, but this would require an overhead in the number of qubits that would take us beyond the limit of classical simulation. Finally, we note that this method scales poorly compared to backpropagation and that the advantage only appears in like for like comparisons of unstructured classical/quantum searches. The cost function landscape is not unstructured and algorithms such as backpropagation take advantage of this. We conjecture that a quantum search method that applies quantum advantage to structured searches, if it exists, can be applied to the cost landscape in place of quantum amplitude amplification. Finding ways to harness quantum computers to aid classical machine learning methods in a meaningful way remains an open problem and we present the loss landscape state as a plausible candidate towards this goal. Whilst we used the example of quantum training, the most fruitful approach in the short term is to ask whether some property of the state can be used to glean useful information for classical machine learning methods. This might take the form of understanding the roughness of the landscape, identifying certain features, or even choosing an appropriate learning rate. Further work in investigating the relationship between the landscape as a quantum state and its features from a machine learning perspective would be a step forward in this direction.\",\n          \"Dialogue research tends to distinguish between chit-chat and goal-oriented tasks. While the former is arguably more naturalistic and has a wider use of language, the latter has clearer metrics and a more straightforward learning signal. Humans effortlessly combine the two, and engage in chit-chat for example with the goal of exchanging information or eliciting a specific response. Here, we bridge the divide between these two domains in the setting of a rich multi-player text-based fantasy environment where agents and humans engage in both actions and dialogue. Specifically, we train a goal-oriented model with reinforcement learning via self-play against an imitation-learned chit-chat model with two new approaches: the policy either learns to pick a topic or learns to pick an utterance given the top-k utterances. We show that both models outperform a strong inverse model baseline and can converse naturally with their dialogue partner in order to achieve goals. In the literature on artificial dialogue agents, a distinction is often made between \\\"goal-oriented\\\" dialogue, where an agent is tasked with filling slots or otherwise obtaining or disseminating specified information from the user to help complete a task, and \\\"chit-chat\\\", where an agent should imitate human small talk. Modeling goal-oriented dialogue can have advantages over chit-chat imitation as it gives clearer metrics of success and perhaps more meaningful learning signals; but goal-oriented dialogue data is often more specialized, covering only a narrow slice of natural language. Current goal-oriented datasets study setting like booking restaurants or airline tickets, or obtaining weather information, as standalone tasks (Raux et al., 2005; Henderson et al., 2014; Bordes et al., 2017; El Asri et al., 2017; Budzianowski et al., 2018) . Chit-chat agents, by contrast, might focus on coarse statistical regularities of dialogue data without accurately modeling the underlying \\\"meaning\\\"; but the data often covers a much wider space of natural language. For example, Twitter or Reddit chitchat tasks (Li et al., 2016a; Yang et al., 2018; Mazar\\u00e9 et al., 2018 ) cover a huge spectrum of language and diverse topics. Chit-chat and goal-oriented dialogue are not mutually exclusive: when humans engage in chit-chat, their aim is to exchange information, or to elicit specific responses from their partners. Modeling such goals, however, is made difficult by the fact that it requires large amounts of world knowledge, and that goals in real life are implicit. In this work, we study goal-oriented dialogue agents in the setting of a multi-player text-based fantasy environment (Urbanek et al., 2019) . The environment is built on top of a game engine that grounds actions and reference objects, and thus codifies a body of world-knowledge. Although the interactions between objects and characters are simulated, the choice and types of interactions, the text used to describe them, and the dialogues between characters, are \\\"natural\\\" and wide-ranging, having been collected from human crowdworkers. We define the general task of, given a particular character in a particular scenario (location, set of objects and other characters to interact with) to conduct open-ended dialogue such that a given action is executed in the future by their dialogue partner. The given action could be an emote action (smile, laugh, ponder, . . . ), or a game action (wear chain mail, drink mead, put glass on table, . . . ). The richness of the environment means that there are a huge set of possible tasks and scenarios in which to achieve a wide range of actions. Thus, this task is ideally suited for bridging the divide between goal-oriented and chit-chat dialogue, combining clearer metrics and learning signals on the one hand, with the richness and complexity of situated but open-domain natural language on the other. Figure 1 : Example episode from the LIGHT dataset, consisting of an environment (location setting, characters with given personas, objects), utterances and game actions. There are 10,777 such humanhuman gameplay episodes, and a rich world of 663 locations, 1755 characters and 3462 objects. We train models to achieve these tasks using reinforcement learning (RL) and a type of self-play between two agents. The first agent, which we call the environment agent, is trained with imitation learning on human-human interactions (game actions, utterances and emotes) and subsequently kept fixed. The second agent, the RL agent, is trained to conduct dialogue given the goal, and the two agents interact within a given environment until the goal is either reached or a given number of turns has expired. At that point, rewards are given, and the RL agent is updated. We compare agents that have been trained to imitate human actions given a goal (an \\\"inverse model\\\") to two different RL approaches: optimizing actions with latent discrete variables (topics), or via rewarding actions sampled from the model (via the top-K outputs). We show that both types of RL agent are able to learn effectively, outperforming the inverse model approach or a vanilla chit-chat imitation baseline, and can converse naturally with their dialogue partner to achieve goals. We work in the LIGHT game environment (Urbanek et al., 2019) , which is a multi-user text-based game, involving many characters playing the game at once. Characters (either played by humans or run by models) can speak to to each other via free text, send emote actions like applaud, nod or pout (22 emote types in total), and take actions to move to different locations and interact with objects (e.g. get cutlery, put cutlery in drawer, etc.), see Appendix A for a full list of game actions. LIGHT at its core has a game engine which can formally be defined as a graph, where each location, object and character is a node, and they are connected by labeled edges representing relationships, for example contained-in, path-to or has-property. Actions in the game result in changes in state of the graph. To a player (agent) a local view of the graph can be seen and this is expressed in text, as are the game actions and changes of state. This text then naturally interleaves with the dialogue utterances of the speakers as well to form a input context sequence from which a character can base their subsequent actions. See Fig. 1 for an example. To make the world and its textual descriptions, LIGHT consists of a large set of human-written game locations, characters, and objects, all based within a fantasy medieval setting. Their names, descriptions and properties were crowd-sourced, yielding a total of 663 locations, 1755 characters, and 3462 objects. They range from beaches with crabs and seaweed to crypts with archaeologists and coffins, yielding an extremely rich environment for agents to learn within. An additional set of crowdworkers were then asked to play the role of characters (randomly picked from the set of 1755) within the created world as rendered by the game engine. This involved them making utterances, game actions and emotes, while interacting with each other (in pairs). The resulting gameplay data consists of 10,777 episodes with an average of 18.3 actions each (game actions, emotes and utterances) of rich human play. These are split into train (8538), validation (500) and test (1739) portions, the latter being split into new episodes in existing settings (test seen, 1000) and completely new settings (test unseen, 739) . This gameplay data can be used for training models using imitation learning, as well as for obtaining \\\"common sense\\\" knowledge about how the world works, i.e., what kinds of things certain characters say; what actions they use with certain objects; what they say and how they act in certain environments or while interacting with certain other characters. The whole environment is thus intended as a proxy for learning about the world within a rich simulation, while avoiding the complexities and bandwidth of rendering (3D) computer graphics. While players were not given specific goals, but instead asked to play the role convincingly of the character given, during play some of them effectively defined their own goals during the interactions, see Fig. 1 . The tasks we consider in this work involve interaction between two agents in a given LIGHT scenario. One of the agents, which we will call M env , together with the game engine, effectively functions as an environment for the other agent, which we will call M RL . Because we will formulate our tasks as a reinforcement learning problem, we will also refer to M env as the \\\"environment agent\\\" and M RL as the \\\"RL agent\\\". We assume that the environment agent is fixed; in this work it will be a model trained via behavioral cloning from human-human interaction data. The RL agent must conduct open-ended dialogue such that a given goal action is executed in the future by the environment agent. Our task is formally defined as follows. The two agents M env and M RL are given their views of the scenario (D env and D RL respectively). These consist of the setting name, scenario description, character names, and their own persona, all described as a sequence of text (see Fig 2) . Note that each agent can only access their own persona but not the persona of the partner with whom they are conversing, but they do know the name of their partner. Denote by t the time-step of the environment, U RL t and U env t the utterances of the agents M RL and M env respectively, and denote by A env t the environment actions by M env . Hence the interaction sequence looks like Note that there is an inversion from the usual reinforcement literature language, as the \\\"actions\\\" of the RL agent are its utterances U RL t ; the actions A env t of the environment agent should be considered as internal mechanics of the environment. The agent M RL is additionally given a goal g to achieve, which consists of an action which must be executed by the other agent. That is, the objective of M RL is for M env to take the action g. An episode ends when A env t == g or when n becomes larger than a set number of turns. The RL agent only speaks, but does not perform game or emote actions. This was chosen for simplicity, but also to guarantee that the RL agent cannot help force the goal to be reached by performing actions itself -it has to pick the appropriate utterances U RL such that M env eventually takes the action g. Goals We experiment separately with two different types of goals: game actions and emote actions. We use the same train, valid, test (seen and unseen) split of the original human-human LIGHT episodes, assign roles M RL and M env randomly, and randomly pick an action by M env that occurs in the episode as the goal. We can then present the corresponding setting to our agents in order to form a new interaction, but within the same scenario and with a goal that was naturally desirable and achievable within that setting. Observations The state observation O t = (D RL , S t\\u22121 , g) at time t given to an RL model consists of the RL agent's setting description (D RL ), the utterance and action history up to that time step (S t\\u22121 ), and the agent's goal (g). Our RL agent models consume O t as a flattened sequence of tokens, and return a dialogue utterance U RL t . Each structured component is represented in the flattened sequenced separated by a special token denoting the types, e.g. names, settings, etc., see Fig. 2 . Note that because the entire history and goal is given to the RL agent, the environment is Markovian. Reward We have a terminal reward of +1 only if the goal g is achieved and 0 otherwise, i.e, it is +1 if the environment agent takes the goal action g. The episode ends after n steps. In our experiments we consider n = 1 and n = 3. In this section we describe the models for M env and M RL . In this work these are retrieval models, using the LIGHT dialogue corpus as candidates. We leave generative models to future work. Base Agent Architecture For all our models we adopt the same base architecture, which is a 12-layer bidirectional transformer (Vaswani et al., 2017) pre-trained on a large dialogue corpus (Reddit, 174M examples), and then fine-tuned on our task 1 . To score retrieval candidates, we use a biencoder as in Urbanek et al., 2019) . That is, two transformers are used, one to encode the context, and another to encoder a candidate dialogue, and a dot product between the first output vector of each scores the match. To produce a dialogue utterance one then takes the utterance with the largest output from the training set candidates (111k in this case). For emotes and actions, the same procedure is used, but with those candidate sets instead. For actions, the candidates are the set of admissible actions at that game state, which are provided by the game engine, for example get apple is only available in the candidate set if it is a valid action (an apple is present in the room). For emotes, all 22 candidates are always available. To train the model, a cross entropy loss is used. Similar to Mazar\\u00e9 et al. (2018) , during training we consider the other elements of the batch as negatives. Environment agent The environment agent is the base agent described above, and stays fixed during episodes where the RL agent is trained. This helps guarantee that our RL models stick to using the semantics of natural language (English) rather than so-called language drift, of learning a new emergent language with the same tokens (Lee et al., 2019) . RL agents We design two RL approaches for our tasks -learn to pick the right latent discrete variables (topics) that lead to the correct U RL i ; and learn to pick the correct U RL i from the top K candidates. These are described in more detail in Sections 4.2 and 4.3. We also discuss a baseline \\\"inverse\\\" model trained via behavioral cloning on the human-human data. We consider an inverse model, trained to imitate human actions given a goal, as both a baseline for comparing to RL models, and for producing weights form which we can fine-tune. The inverse model consists of a Bi-encoder, as described above, which takes as input an observation O t similar to our RL models, and outputs an utterance. We train it by extracting from the human-human game logs training set (which does not have goals) every instance where a game action occurs at time t in S t , that is where for 0 < i < t might be null). We then construct a training example for the inverse model with observation (D RL , g = A env t , S t\\u22121 ). i.e. setting the goal g to be A env t , and with the desired action to be taken by the agent as U RL t . Here we use the subscripts \\\"RL\\\" and \\\"env\\\" just to mark the relative positions in the sequence, as all actions and utterances come from the human logs. Note also that unlike the RL agents we train, the human in the RL agent \\\"position\\\" can take game actions. We can thus train this model in a supervised manner using a cross entropy loss as described before. This model does not learn a policy interactively, and hence might not learn to plan or strategize optimally for goal completion. The data distribution it is trained on is different than the data distribution seen by the RL agents. Nevertheless, it can serve as a strong baseline. Further, when training our RL agents, we initialize their weights to the weights of this model, and then fine-tune from that point. Optimizing all the parameters of a large transformer architecture by RL is both incredibly costly in data efficiency and computing time, and is also known to have the problem of language drift (Lee et al., 2019) -that is, there is no guarantee after training with self-chat that the models will output recognizable natural language utterances. A solution to both problems is to train most of the parameters of the model with human-human language data, and then to either disentangle or only optimize some of the parameters with model self-chat . Here, we propose a straight-forward model for that purpose. We assume an RL agent that consists of two components. The first component F c (O) = P (T c (O)) maps from an observation to a discrete variable with C possible values. It consists of a chain of two functions: a transformer T s that takes in the observation, and outputs a state representations, and a policy chooser c = P (s) \\u2208 (1, . . . , C) which takes in the state representation and outputs the value of the discrete latent variable. The second component T u (O, c) is an additional transformer that takes as input the observation as well as the output of the first component, and outputs a dialogue utterance. That is, the entire model is the chain u = T u (O, P (T s (O))). We make this explicit decomposition so that we can train only part of the model with RL; note that the \\\"action\\\" trained via RL is choosing c, not outputting the final utterance. Initial topics We first pre-train the transformer T s using the inverse model described in Section 4.1, which produces a vectorial representation of a given observation. We then run K-means over the vectorial representations of all observations from the training set to provide the mapping to one of C values, which represent dialogue topics, which we use as our initial function P (s). These two functions together give us our initialization of F c . Table 1 shows the cluster ID and the topic denoted by that cluster along with the most representative sentences (closest to the center) for that cluster for 50 topics. As we can see, the clusters learnt can be coherent about a topic. We use these 50 topics as a set of actions A for our RL setup. From c to A Given our initial choice of F c , we can also pre-train T u . We simply take our initial human-human training data, and for each observation append the topic computed by F c to it. This allows our model to be able to generate an action (utterance) conditional on both an input and a topic. We can now train a policy by RL that optimizes the topic at any given point in the episode. We keep the pre-trained portions of the model T u and T s fixed and during fine-tuning only optimize P . The cluster chooser P is redefined (from the initial K-means) to be an MLP network consisting of 2 layers. A discrete action is sampled from a categorical probability distribution over the possible topics, given by c t \\u223c Categorical(h 2 t ), where h 2 t = tanh(W 2 tanh(W 1 s t + b 1 ) + b 2 ). The state vector s t also encodes the goal g and hence, the policy is conditioned on the goal g of the agent. Hence, the policy can learn strategies that will result in picking actions at each time step t that will help the agent to achieve its goal g. As our RL agent can only choose topics, it cannnot redefine easily the meaning of words to cause language drift. The Top-K model is another approach to keeping the number of trainable parameters small. It uses the inverse model to get a context embedding v context from the observation, and a list of K candidate utterance embeddings v 1 , ...v K . These are the encodings by the inverse model of the K utterances it considers most likely given the context and goal. We then train a small (2-layer) transformer model that takes as input the set {v context , v 1 , ...v K }. We use the attention above weights of v context against the candidates at the last layer of the transformer as the distribution over the candidates for sampling an utterance. We use K = 50 in the experiments. We use the Advantage Actor-Critic implementation (A2C; Kostrikov, 2018) to train the policy and the value function for both the latent-variable and top-K models. Chit-chat dialogue There is an increasing body of work in the domain of chit-chat, where the primary approaches being currently tried are end-to-end neural approaches. They are typically large pre-trained and then fine-tuned transformers, either generative or retrieval, where currently retrieval models work best on a number of tasks (Zhang et al., 2018; Li et al., 2019) . Our work shares a commonality with these approaches in that the original LIGHT dialogue data we use has no specified goals, and humans chit-chat together (and act). Thus, the conversations cover a rich number of diverse topics. In Urbanek et al. (2019) models were trained in a similar fashion to chit-chat task models, and we adopt similar architectures here, but instead adapt them to learn to pursue goals. Goal-oriented dialogue Traditional goal-oriented dialogue has focused on narrow tasks that would typically be useful for a dialogue-based assistant, for example restaurant (Henderson et al., 2014) , taxi, train, and hotel (Budzianowski et al., 2018) or trip (El Asri et al., 2017) booking. Hence, each task typically focuses on a narrow slice of natural language and world knowledge for a specialized domain. Earlier work focused on labeled state representations, slot filling mechanisms and dialogue managers (Rieser & Lemon, 2011) , and more recent work has shifted to an end-to-end approach (Bordes et al., 2017) , in line with chit-chat models, but still the two sets of tasks are rarely considered together, or by using the same methods. RL for dialogue The classical goal-oriented dialogue literature studies RL extensively (Singh et al., 2000) . Typically, they used RL to improve dialogue managers, which manage transitions between dialogue states (Singh et al., 2002; Pietquin et al., 2011; Rieser & Lemon, 2011; Gasic et al., 2013; Fatemi et al., 2016) . Recent works have focused more on end-to-end learning. Some works have focused on self-play type mechanisms for end-to-end reinforcement learning, where the reward is derived from goal. A related approach to ours is the negotation tasks of ; , which require two agents to swap 3 item types (hats, balls, books) where the value of the items is different for the two agents, and derives their personal reward. In contrast, our setup encompasses a rich world of settings and characters -with 3462 object types, and a corresponding large number of actions. This is reflected in the vocabulary size itself (\\u223c32,000 versus \\u223c2,000 in the negotation tasks). Other notable uses of RL in dialogue include within visual question answering (Das et al., 2017) , in the domain of chit-chat where RL has been used to decrease repetitive and generic responses through the the use of self-play (Li et al., 2016b) , and through human-bot conversation (Sankar & Ravi, 2019) . RL for language and games RL is used extensively for learning to play games, one of the most well known examples being AlphaGo (Silver et al., 2016) . Since then, language in games has started to be more deeply explored, for example in graphical games such as Minecraft (Oh et al., 2017) , Real-time strategy war games (Hu et al., 2019) , or in text adventure games (Narasimhan et al., 2015; C\\u00f4t\\u00e9 et al., 2018) . The latter are related to our setting. However, those approaches use RL to optimize the set of actions given feedback in a single-player rather than multi-player game, so the text only refers to the environment, and there is no dialogue or actions from other agents. Our work focuses specifically on the latter. We compare our various models on the game action and emote action tasks. We experiment with differing number of steps n allowed to complete the goal, n = 1 and n = 3. Our main results for both seen and unseen test environments are given in Table 2 . We report the average reward and for n = 3 the average number of turns before completion. The results show clear improvements for our topic RL ( \\u00a74.2) and top-K RL ( \\u00a74.3) compared to the inverse model baseline for all values of n, and both types of actions (game actions and emotes). We show the training curves for topic RL in Fig. 3 , reporting rewards averaged over the batch (512 for n = 1, and 128 for n = 3). They show relatively smooth improvements over time, with clear gains over the baseline. As a sanity check we also tried, after training, to replace the topic RL policy with random topic prediction, which yielded poor results, e.g. 0.217 reward for n = 1 test seen game actions. Our model is clearly learning appropriate topic acts. We show examples of successful utterances, achieving goal actions in Fig. 3 for a diverse range of scenarios, actions and language. (n = 1) (n = 3) (n = 1) (n = 3) In this paper, we investigate agents that can interact (speak or act) and can achieve goals in a rich world with diverse language, bridging the gap between chit-chat and goal-oriented dialogue. We achieve this by defining a task for an agent, where the goal is for the other player to execute a particular action. We explore two reinforcement learning based approaches to solve this task: the policy either learns to pick a topic or learns to pick an utterance given the top K utterances, and compare them against a strong baseline trained to imitate chit-chat. We show that these approaches effectively learn dialogue strategies that lead to successful completion of goals, while producing natural chat. Future work should explore further RL algorithms for agents that can act and speak in natural language at scale in our proposed rich task environment, and we expect further advancements. Constraints Outcome get object actor and object in same room actor is carrying object object is gettable drop object actor is carrying object object is in room object is gettable get object1 from object2 Actor and object2 in same room actor is carrying object1 object1 is gettable object2 is surface or container object2 is carrying object1 put object1 in/on object2 Actor and object2 in same room object2 is carrying object1 object2 is container or surface actor is carrying object1 give object to agent Actor and agent in same room agent is carrying object object is a member of actor steal object from agent actor and agent in same room actor is carrying object object is a member of agent hit agent Actor and agent in same room inform agent of attack hug agent Actor and agent in same room inform agent of hug drink object actor is carrying object inform actor of drinking successfully object is a drink eat object actor is carrying object inform actor of eating successfully object is a food wear object actor is carrying object actor is wearing object object is wearable wield object actor is carrying object actor is wielding object object is a weapon remove object actor is wearing/wielding object actor is carrying object object is wearable or a weapon Table 4 : LIGHT actions and constraints from Urbanek et al. (2019) B GAME EMOTES WITHIN LIGHT applaud, blush, cry, dance, frown, gasp, grin, groan, growl, laugh, nod, nudge, ponder, pout, scream, shrug, sigh, smile, stare, wave, wink, yawn Figure 4: Emote actions within the LIGHT platform from Urbanek et al. (2019)\",\n          \"Deep neural networks are known to be vulnerable to adversarial perturbations. In this paper, we bridge adversarial robustness of neural nets with Lyapunov stability of dynamical systems. From this viewpoint, training neural nets is equivalent to finding an optimal control of the discrete dynamical system, which allows one to utilize methods of successive approximations, an optimal control algorithm based on Pontryagin's maximum principle, to train neural nets. This decoupled training method allows us to add constraints to the optimization, which makes the deep model more robust. The constrained optimization problem can be formulated as a semi-definite programming problem and hence can be solved efficiently. Experiments show that our method effectively improves deep model's adversarial robustness. Deep neural networks achieve state-of-the-art performances on a variety of tasks (LeCun et al., 2015) . However, neural nets are known to be vulnerable to adversarial examples. Imperceptibly perturbed inputs can induce erroneous outputs in neural nets (Szegedy et al., 2013) . In image classification problems of computer vision, previous work has proposed various methods to attack deep models and induce low accuracy (Goodfellow et al., 2015; Madry et al., 2017; Papernot et al., 2016a; Carlini & Wagner, 2017a) . Whereas multiple defenses against adversarial attacks are developed, they don't ensure safety faced with strong attacking methods. There are also theories that explain the existence of adversarial examples (Ilyas et al., 2019; Shamir et al., 2019) , but they often fail to fully explain the features and behaviors of this phenomenon. This makes the study of adversarial attacks important in that it is a threat to real-life machine learning systems (Kurakin et al., 2016) . In this paper, we propose a dynamical system view on the adversarial robustness of the models, as well as new method that significantly defense adversarial attacks. Recent works have shown the connection between deep neural networks and dynamical systems (E, 2017; Haber & Ruthotto, 2017; Lu et al., 2017) . If we regard the neural net as a discretization of an ordinary differential equation (ODE), then training neural nets becomes finding an optimal control of the corresponding discrete dynamical system. Traditionally, we often treat training neural networks as an unconstrained non-convex optimization problem where \\u03b8 denotes the parameters of the model, J denotes the loss function and R denotes the regularizer term, and we solve the problem with (stochastic) gradient-descent based methods (Bottou, 2010; Ruder, 2016) . In the training process, we feed the network with a batch of training data, and compute the gradient with forward and backward propagation (E. Rumelhart et al., 1986) . The propagation process resembles solving optimal control problems that tune the parameters to make the output be close to target states. This viewpoint motivates us to bridge adversarial robustness with Lyapunov stability of a dynamical system, and to train robust networks with algorithms that find stable optimal control. We will formulate the discussion in later sections. 2 RELATED WORK 2.1 ADVERSARIAL DEFENSE Many defense methods have been proposed to improve the models' adversarial robustness. The defenses mainly fall into three types: adversarial training (Szegedy et al., 2013; Zhang et al., 2019) , modifying the networks (Gu & Rigazio, 2015; Lyu et al., 2015; Papernot et al., 2016b; Nayebi & Ganguli, 2017; Ross & Doshi-Velez, 2017) , and adding external models (Lee et al., 2017; Akhtar et al., 2017; Gebhart & Schrater, 2017; Xu et al., 2018; Sun et al., 2019) . Although various defense methods have been developed, a defended deep model is often successfully attacked by newly developed attacks or specific counter-counter measures (Carlini & Wagner, 2017b) . Therefore, it can be hoped that defenses against general attacks will be devised to make deep learning models (adversarially) robust to real-life threats. Recent works have bridged deep neural networks with ODEs and dynamical systems. On the one hand, deep residual networks (He et al., 2015) can be illustrated as forward Euler scheme approximating an ODE (E, 2017), which motivates us to design effective network structures (Lu et al., 2017) . On the other hand, regarding the network as a dynamical system allows us to set up an optimal control viewpoint of neural nets. Pontryagin's Maximum Principle (Boltyanskii et al., 1960) has been applied to train neural nets Li & Hao, 2018) . Given a T -layer neural net, we let the dynamical system {f t (x t , \\u03b8 t ) : t = 0, . . . , T } represents the network, where x t is the input of t-th layer, \\u03b8 t is the parameter, and f t : denotes the t-th layer's transformation, which is usually a non-linear function \\u03c3(\\u03b8 t x t + b t ) for fully-connected layers, convolution layers and batch normalization layers, etc. Therefore, training the neural net can be regarded as controlling the parameters to let the dynamics fit the training data. Specifically, the training optimization problem can be formulated as a typical optimal control problem as follows: . . , T \\u2212 1, where we use x i to denote the i-th input in the batch and B denote the batch size. J and L are the loss function and the regularizer, respectively. Specially, if the model is a deep residual network with structure x t+1 = x t + f t (x t , \\u03b8 t ), we can regard the problem as the forward Euler discretization of the following continuous optimal control problem: where x(t) is a continuous trajectory from the input to the output logits. Adversarial examples are usually clean images added by a small calculated perturbation \\u03b7. The model predicts correct labels fed with clean inputs x 0 , while the output is completely different when it is fed with perturbed input x 0 + \\u03b7. The dynamical system view of neural nets motivate us to characterize this sensitivity with Lyapunov stability of a system (Hirsch et al., 2004) . Definition 1 (Lyapunov Stability). For a given dynamical system\\u1e8b = f (x), x(0) = x 0 , x e is an equilibrium, then \\u2022 The system is asymptotically stable if it is Lyapunov stable and \\u2203 \\u03b4 > 0 such that if x(0) \\u2212 x e < \\u03b4, then lim t\\u2192\\u221e x(t) \\u2212 x e = 0. \\u2022 The system is exponentially stable if it is asymptotically stable and \\u2203 \\u03b1 > 0, \\u03b2 > 0, \\u03b4 > 0 such that if x(0) \\u2212 x e < \\u03b4, then x(t) \\u2212 x e \\u2264 \\u03b1 x(0) \\u2212 x e e \\u2212\\u03b2t , for all t \\u2265 0. The definitions can be easily extended to discrete-time systems. Intuitively, the Lyapunov stability states that for any small perturbation \\u03b7, the trajectory is still \\\"close enough\\\" to the original one. If we regard a neural net as a dynamical system, and ensure the network is Lyapunov stable, then the model is robust to all (adversarial) perturbations. Due to the connection between numerical ODEs and residual networks, we first consider robustness (i.e. Lyapunov stability) of continuous ODEs. , where \\u03c3 is the activation function, e.g., Sigmoid function or ReLU function, it is stable if Re(\\u03bb i (A)) \\u2264 0, \\u2200i, where Re denotes the real part, and \\u03bb i denotes the i-th eigenvalue. One can see, e.g. Hirsch et al. (2004) , for the proof of this theorem. Theorem 1 provides a set of conditions for stable ODEs. However, deep residual network is only a forward Euler discretization scheme of continuous ODE. To ensure numerical stability, we require |1 \\u2212 \\u03bb i (A)h| \\u2264 1 (Ascher & Petzold, 1998) , where the step size h = 1 in residual networks. Added by the identity mapping in residual networks, we can get the stable conditions for discrete dynamics. Theorem 2 (Stable Discrete Networks). For a discrete neural network, i.e., discrete dynamics {f t (x t , \\u03b8 t ) : t = 0, . . . , T }, where f t (x t , \\u03b8 t ) = \\u03c3(\\u03b8 t x t ) (we omit the bias term for simplicity), the network is stable if the \\u03c1(\\u03b8 t ) \\u2264 1, where \\u03c1(A) = max i (|\\u03bb i (A)|) is the spectral radius. If the conditions are added to the unconstrained optimization problem of training, we can greatly improve the adversarial robustness of neural nets. The methods will be discussed in the following section. 4.1 PMP AND MSA For deterministic systems, the Pontryagin's Maximum Principle (PMP) (Boltyanskii et al., 1960) provides a set of necessary conditions for optimal control of the system. Various algorithms have been proposed to solve the deterministic optimal control problem based on PMP. Among them, the Method of Successive Approximations (MSA) (Krylov & Chernous'ko, 1963 ) is one of the simplest algorithms. In the field of deep learning, previous work has utilized MSA to train neural networks Li & Hao, 2018) . Formally, consider the optimal control problem for training neural nets in section 3. For dynamics {f t (x t , \\u03b8 t ) : t = 0, . . . , T }, assume \\u03b8 * = \\u03b8 * 0 , . . . , \\u03b8 * T \\u22121 is a solution to the optimal control problem. Also, we define the Hamiltonian function H : , where the dot denotes the inner product. We have the following necessary conditions for \\u03b8 * . Theorem 3 (Pontryagin's Maximum Principle for Discrete Systems). Assume f t and J are sufficiently smooth. There exists co-states p * = {p * 0 , . . . , p * T } s.t. the following conditions hold: For simplicity of notations, here we assume the batch size is 1. One can easily extend the theorem to minibatch training case by summing over the batch. The theorem can be proved by KKT conditions (Boyd & Vandenberghe, 2004) , where the co-states can be seen as the Lagrangian dual variables. Consider the conditions in PMP, one can find the x equations are exactly the forward propagation of a neural net, and the p equations resemble the backward propagation process. The third condition states that the model parameters must maximize the Hamiltonian function. This motivates us to iteratively compute forward and backward propagation, and solve the Hamiltonian maximization to find the optimal control, which is exactly the Method of Successive Approximations (Algorithm 1). In practice, we usually add regularizer terms that penalize great changes in the maximization step to prevent drastic steps that cause divergence. For the connection between MSA and back-propagationbased gradient descent algorithms, see the appendix of Li & Hao (2018) . Compute the states (forward propagation): The advantages of training by MSA compared with gradient descent algorithms has been discussed in , among which the most significant feature is that the optimization steps on different layers are decoupled. Concretely, after computing the states x and co-states p, the optimization step on layer t is only searching for parameters \\u03b8 t . This not only suggests that the optimization process can be accelerated by parallelization, but also allows us to utilize the features of the problem. The parameter space is greatly reduced compared with the original intractable optimization problem, and hence the optimization is much more easier. This allows us to add constraints that ensure robustness of the model. Consider a layer in the form of f t (x) = \\u03b8 t x, where we leave the activation as an individual layer with no parameters for simplicity, we can derive the following optimization problem for Hamiltonian maximization: max where \\u03b1 \\u03b8 t 2 2 is the L 2 norm regularizer (weight decay), and \\u03b8 t is the initial parameter (i.e., \\u03b8 k t in the algorithm). The last term keeps the training process from drastic steps that cause divergence. The constraint, as illustrated in section 3, is the stable condition for discrete systems. It makes the optimization quite difficult if we directly add the constraints in gradient descent based algorithms, but the decoupled optimization in MSA allows us to do so. With regard to the constraint of parameter's spectral radius, a simple method is to apply special forms of matrices for parameters, e.g. anti-symmetric matrices. For continuous deep models, the only constraint is Theorem 1, i.e., Re(\\u03bb i (\\u03b8 t )) \\u2264 0. Anti-symmetric matrices have only imaginary eigenvalues, and hence we can replace \\u03b8 t with \\u03b8 t \\u2212 \\u03b8 (Goodfellow et al., 2015) 2.34% 77.45% 49.32% PGD-10 (Madry et al., 2017) 0.02% 46.67% 36.33% C&W (Carlini & Wagner, 2017a) Proof. Recall that \\u03c1(A) \\u2264 A 2 = \\u03bb max (A T A), we have Hence we can replace \\u03c1(\\u03b8 t ) \\u2264 1 with a positive semi-definite condition, and we turn the Hamiltonian maximization into a new optimization problem, where the target function is quadratic and the constraint is a semi-definite condition. This can be reduced to a semi-definite programming (SDP) problem (Vandenberghe & Boyd, 1998) , which is a special case of convex optimization, and thus can be solved efficiently by, e.g., interior point methods (Helmberg et al., 1970) in polynomial time. Here we summarize our method. For a given neural network, we use MSA to train the model, i.e., iteratively computing the states (forward propagation) and co-states (backward propagation), and solving the optimization for each layer. Instead of directly maximizing the Hamiltonian, we add a positive semi-definite constraint to the optimization problem, which leads to a stable control of the dynamics. To evaluate the effectiveness of our method, we conduct experiments on CIFAR10. We trained the network on clean data, with adversarial training (PGD-10) and with robust training (our method), respectively. We used FGSM (Goodfellow et al., 2015) , PGD-10 (Madry et al., 2017) and C&W (Carlini & Wagner, 2017a) to attack the network. Due to the limitation of TensorFlow, we used a simple interior point method with gradient descent to solve SDP. The network model was an 18-layer residual network (He et al., 2015) , with 8 residual blocks. We set the perturbation size as = 0.1 for both FGSM and PGD. For C&W, we used the L 0 metric. We trained the model for 150 epochs with a batch size of 200. The learning rate was set to be 10 \\u22122 initially, and was divided by 5 at epoch 30, 60 and 100. The regularizer term constant was set to be 10 \\u22123 . The results can be seen in Table 1 . The accuracy of robust models on clean data is lower than vanilla model's in that robust training and generalization is more difficult and requires more data (Schmidt et al., 2018) . Our method improves model's adversarial robustness, compared with the vanilla model. Figure 1 displays the eigenvalues of the last fully-connected layer's parameter. The complex norm of eigenvalues (spectral radius) of the model trained by our method are effectively bounded below 1, which satisfies the robust constraint on parameters in section 4.2, while eigenvalues of natural training are randomly distributed in the complex plane. Our method is not as effective as traditional adversarial training method. However, it mainly has the following advantages: (a) The training process doesn't require large numbers of gradient propagation, which consumes much time in adversarial training. In our experiment, adversarial training spends about 10 times GPU time as much as our method. (b) The decoupled training process allows us to set different hyperparameters and training methods for different layers, which is more maneuverable for large scale training. We can further control the behavior of different layers in adversarial settings. (c) Lyapunov stability provides a framework for analyzing adversarial robustness of deep models, which may lead to theoretical analysis of adversarial samples in future work. Motivated by the dynamical system view of neural networks, this work bridges adversarial robustness of deep neural models with Lyapunov stability of dynamical systems, and we also propose a method that uses a stable optimal control algorithm to train neural networks to improve the adversarial robustness of deep neural models. Though the result didn't surpass STOA defense methods, the stable control view of training neural nets points out another direction towards adversarially robust models. For future work, on the one hand, mathematical analysis on Lyapunov stability of neural models may be studied to provide theoretical understanding of adversarial robustness. On the other hand, popular platforms for deep learning, e.g., TensorFlow, PyTorch, didn't provide frameworks for optimal control. We will obtain better results if specific algorithms for SDP are applied to solve the optimization problem.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 203,\n        \"samples\": [\n          \"SyxvSiCcFQ\",\n          \"BJxRrlBFwB\",\n          \"BklVA2NYvH\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 203,\n        \"samples\": [\n          \"We show that NN parameter and hyperparameter cost landscapes can be generated as quantum states using a single quantum circuit and that these can be used for training and meta-training. Describes a method where a deep learning framework can be quantised by considering the two state form of a Bloch sphere/qubit and creating a quantum binary neural network. This work proposes quantum amplitude amplification, a new algorithm for training and model selection in binary neural networks. Proposes a novel idea of outputting a quantum state that represents a complete cost landscape of all parameters for a given binary neural network, by constructing a quantum binary neural network (QBNN).\",\n          \"Agents interact (speak, act) and can achieve goals in a rich world with diverse language, bridging the gap between chit-chat and goal-oriented dialogue. This paper studies a multiagent dialog task in which the learning agent aims to generate natural language actions that elicit a particular action from the other agent, and shows RL-agents can achieve higher task completion levels than imitation learning baselines. This work explores the goal-oriented dialogue setting with reinforcement learning in a Fantasy Text Adventure Game and observes that the RL approaches outperform supervised learning models.\",\n          \"An adversarial defense method bridging robustness of deep neural nets with Lyapunov stability The authors formulate training NNs as finding an optimal controller for a discrete dynamical system, allowing them to use method of successive approximations to train a NN in a way to be more robust to adversarial attacks. This article uses the theoretical view of a neural network as a discretized ODE to develop a robust control theory aimed at training the network while enforcing robustness.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 202,\n        \"samples\": [\n          \"Frequency-based Search-control in Dyna\",\n          \"Neural Network Cost Landscapes as Quantum States\",\n          \"Model Distillation with Knowledge Transfer from Face Classification to Alignment and Verification\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"number_words_target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16,\n        \"min\": 40,\n        \"max\": 124,\n        \"num_unique_values\": 61,\n        \"samples\": [\n          78,\n          80,\n          50\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"extractive_summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 203,\n        \"samples\": [\n          \"Although there is some work on how this might be done BID7 it is not known to even be possible to construct a qRAM in an efficient manner for a completely general dataset. Previous work has demonstrated and experimentally implemented the use of quantum hardware to perform binary classification, BID15 ) but this is not the same as the method proposed in this paper, as this study is based on a different, more general gate-based form of quantum computation as opposed to the quantum annealing devices of the former. The biggest such device in existence today contains just 72 highly imperfect qubits, but it is worth noting that progress has advanced at a particularly rapid pace over the past few years and a number are available for public access on the cloud. Just as in classical computing, small sets of quantum gates are universal in that they can be combined to generate any other. Step 2: We then build a quantum circuit analogue of the neural network U QN N that takes in a given set of weights (encoded within qubits as above) and an empty register, and outputs onto the register the corresponding accuracy according to the chosen neural network i.e U QN N (w, 0) = (w, acc w ).Step 3: Since U QN N is a quantum circuit, inputting weights in superposition form allows them to be processed in parallel. This is a single quantum state representing the entire landscape of the neural network by correlating every possible set of weights with its resultant accuracy. If we restrict the problem to the special case of binary arguments only, the sign function 1 is reduced to finding whether there exist N/2 qubits out of N in state |1 . The reversibility of quantum circuits allows us to apply the QBNN for a given data point, store its output value onto its corresponding qubit on the register, perform the same QBNN in reverse order -its inverse -to refresh the other qubits, and continue for the next data point in the training set. Since both the labels and the outputs are binary, we can represent the accuracy of each of these predictions by performing a NOT gate on all the qubits corresponding to a data point with a label of 0. If the prediction qubits are all in the state |1 the training was a success and the appropriate weights can be simply read off their corresponding qubits. In practice, due to qubit number constraints, we choose to only learn the structure of the first layer of the BNN. It is particularly interesting to note that the learned structures of the two BNN solutions seem to match well with their problem definitions (equation 1 and equation 2). In fact, such an implementation is advantageous since it would allow us to use less qubits which in practical terms are limited in number in the near term. Both of these problems arise completely from our implementation of the sign function, which could either be improved or replaced entirely with a different binary activation function that could be implemented more efficiently on a quantum computer and would be compatible with non-binary input. Whilst we used the example of quantum training, the most fruitful approach in the short term is to ask whether some property of the state can be used to glean useful information for classical machine learning methods. Further work in investigating the relationship between the landscape as a quantum state and its features from a machine learning perspective would be a step forward in this direction.\",\n          \"In the literature on artificial dialogue agents, a distinction is often made between \\\"goal-oriented\\\" dialogue, where an agent is tasked with filling slots or otherwise obtaining or disseminating specified information from the user to help complete a task, and \\\"chit-chat\\\", where an agent should imitate human small talk. We compare agents that have been trained to imitate human actions given a goal (an \\\"inverse model\\\") to two different RL approaches: optimizing actions with latent discrete variables (topics), or via rewarding actions sampled from the model (via the top-K outputs). Characters (either played by humans or run by models) can speak to to each other via free text, send emote actions like applaud, nod or pout (22 emote types in total), and take actions to move to different locations and interact with objects (e.g. get cutlery, put cutlery in drawer, etc.), see Appendix A for a full list of game actions. To make the world and its textual descriptions, LIGHT consists of a large set of human-written game locations, characters, and objects, all based within a fantasy medieval setting. While players were not given specific goals, but instead asked to play the role convincingly of the character given, during play some of them effectively defined their own goals during the interactions, see Fig. 1 . Similar to Mazar\\u00e9 et al. (2018) , during training we consider the other elements of the batch as negatives. We consider an inverse model, trained to imitate human actions given a goal, as both a baseline for comparing to RL models, and for producing weights form which we can fine-tune. Optimizing all the parameters of a large transformer architecture by RL is both incredibly costly in data efficiency and computing time, and is also known to have the problem of language drift (Lee et al., 2019) -that is, there is no guarantee after training with self-chat that the models will output recognizable natural language utterances. We then run K-means over the vectorial representations of all observations from the training set to provide the mapping to one of C values, which represent dialogue topics, which we use as our initial function P (s). The cluster chooser P is redefined (from the initial K-means) to be an MLP network consisting of 2 layers. We use the attention above weights of v context against the candidates at the last layer of the transformer as the distribution over the candidates for sampling an utterance. In Urbanek et al. (2019) models were trained in a similar fashion to chit-chat task models, and we adopt similar architectures here, but instead adapt them to learn to pursue goals. Earlier work focused on labeled state representations, slot filling mechanisms and dialogue managers (Rieser & Lemon, 2011) , and more recent work has shifted to an end-to-end approach (Bordes et al., 2017) , in line with chit-chat models, but still the two sets of tasks are rarely considered together, or by using the same methods. Other notable uses of RL in dialogue include within visual question answering (Das et al., 2017) , in the domain of chit-chat where RL has been used to decrease repetitive and generic responses through the the use of self-play (Li et al., 2016b) , and through human-bot conversation (Sankar & Ravi, 2019) . However, those approaches use RL to optimize the set of actions given feedback in a single-player rather than multi-player game, so the text only refers to the environment, and there is no dialogue or actions from other agents. We achieve this by defining a task for an agent, where the goal is for the other player to execute a particular action.\",\n          \"This decoupled training method allows us to add constraints to the optimization, which makes the deep model more robust. In this paper, we propose a dynamical system view on the adversarial robustness of the models, as well as new method that significantly defense adversarial attacks. On the one hand, deep residual networks (He et al., 2015) can be illustrated as forward Euler scheme approximating an ODE (E, 2017), which motivates us to design effective network structures (Lu et al., 2017) . On the other hand, regarding the network as a dynamical system allows us to set up an optimal control viewpoint of neural nets. If we regard a neural net as a dynamical system, and ensure the network is Lyapunov stable, then the model is robust to all (adversarial) perturbations. , where \\u03c3 is the activation function, e.g., Sigmoid function or ReLU function, it is stable if Re(\\u03bb i (A)) \\u2264 0, \\u2200i, where Re denotes the real part, and \\u03bb i denotes the i-th eigenvalue. In the field of deep learning, previous work has utilized MSA to train neural networks Li & Hao, 2018) . Concretely, after computing the states x and co-states p, the optimization step on layer t is only searching for parameters \\u03b8 t . Consider a layer in the form of f t (x) = \\u03b8 t x, where we leave the activation as an individual layer with no parameters for simplicity, we can derive the following optimization problem for Hamiltonian maximization: max It makes the optimization quite difficult if we directly add the constraints in gradient descent based algorithms, but the decoupled optimization in MSA allows us to do so. This can be reduced to a semi-definite programming (SDP) problem (Vandenberghe & Boyd, 1998) , which is a special case of convex optimization, and thus can be solved efficiently by, e.g., interior point methods (Helmberg et al., 1970) in polynomial time. For a given neural network, we use MSA to train the model, i.e., iteratively computing the states (forward propagation) and co-states (backward propagation), and solving the optimization for each layer. Due to the limitation of TensorFlow, we used a simple interior point method with gradient descent to solve SDP. The complex norm of eigenvalues (spectral radius) of the model trained by our method are effectively bounded below 1, which satisfies the robust constraint on parameters in section 4.2, while eigenvalues of natural training are randomly distributed in the complex plane. Motivated by the dynamical system view of neural networks, this article bridges adversarial robustness of deep neural models with Lyapunov stability of dynamical systems, and we also propose a method that uses a stable optimal control algorithm to train neural networks to improve the adversarial robustness of deep neural models. Though the result didn't surpass STOA defense methods, the stable control view of training neural nets points out another direction towards adversarially robust models.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"number_words_source\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1898,\n        \"min\": 131,\n        \"max\": 13830,\n        \"num_unique_values\": 200,\n        \"samples\": [\n          7663,\n          5353,\n          3957\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"number_words_extractive\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 138,\n        \"min\": 131,\n        \"max\": 1069,\n        \"num_unique_values\": 167,\n        \"samples\": [\n          776,\n          609,\n          558\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_train.shape, data_val.shape, data_training.shape, data_test.shape)"
      ],
      "metadata": {
        "id": "UrY4AEOhphm9",
        "outputId": "6abc9a1a-1cc7-4a5c-fad3-65bc99665b51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(647, 8) (162, 8) (809, 8) (203, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all data to HF DatasetDict\n",
        "tf_data_train = Dataset.from_pandas(data_train)\n",
        "tf_data_test = Dataset.from_pandas(data_test)\n",
        "tf_data_val = Dataset.from_pandas(data_val)\n",
        "\n",
        "raw_data = DatasetDict({'train': tf_data_train,\n",
        "                           'validation': tf_data_val,\n",
        "                           'test': tf_data_test})"
      ],
      "metadata": {
        "id": "mDeGyFjUpkVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BART\n",
        "\n"
      ],
      "metadata": {
        "id": "tZwSHOSdoAHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'facebook/bart-base'\n",
        "max_input_length = 1024\n",
        "\n",
        "save_name = 'sampling-norep-v4/'\n",
        "save_path = BASE_PATH + '/Results/TLDR/BART/model_save/' + save_name"
      ],
      "metadata": {
        "id": "LpOqNR1qyJGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prepare Data for Tokenization"
      ],
      "metadata": {
        "id": "t4eTk7kNwH5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize data\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name, errors='ignore')\n",
        "\n",
        "# Function in order to tokenize source and target\n",
        "\n",
        "def tokenize_function(data):\n",
        "  model_inputs = tokenizer(data['extractive_summary'], max_length=max_input_length, truncation=True, padding=True)\n",
        "\n",
        "  with tokenizer.as_target_tokenizer():\n",
        "    labels = tokenizer(data['target'], padding=True)\n",
        "\n",
        "  # The target input_ids tokens are added to the model inputs\n",
        "  model_inputs['labels'] = labels['input_ids']\n",
        "  return model_inputs\n",
        "\n",
        "tokenized_data = raw_data.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "9kNP88WHh5pZ",
        "outputId": "1af0fa12-a887-42ec-ffc3-8c8eae3feb5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "019a29f1b10145c8abc20308424e20ad",
            "87bd56f9f9db417c81d87b260e64717a",
            "e953775064244191a3245084abd7b949",
            "3e0d973080be48c3a61ca7bec49f30f0",
            "32ac86f5ff984aedbefd8393f1953c92",
            "255e5a72897049f9b2d16f5f717a7abc",
            "4edaa22c96884cf6a629cc6e8b277cbd",
            "1d41ba5b64e441caa852290dd525bf5e",
            "eb71b0e1b402499095482662879aeab5",
            "223fc245f51a45e39b4f896fab8b139a",
            "578becc7bb2146c587dca97aea75ad16",
            "1e7407be543141a5b2157b3026af7bfd",
            "fcaa9abbccee4df0bdee6114eff41c45",
            "61672ed9c6d74592a1a8b1c6a0b5fe9c",
            "a7feab89338642ec8b2cd300bf1494bd",
            "d6a8ec6ba5ad4b2cb30f24a0daa5fc94",
            "22130b81744c410093e46123bc3d58df",
            "90a902c031ac467d9b1dd1096f161a83",
            "03c6a89889cb44d98b1a9ce788088a10",
            "505a0197233e4c5aa7c6e6e98e11e245",
            "2ef4b357bbd64bdaa10197bae69d7bac",
            "844f27566bfd47b187c53cf95f6892d2",
            "6394854b894b4ed08ea6a7d7aebda655",
            "b9384ed494d04b6986b1288ef98535f3",
            "5cafb00bc5174d908ebb62d3a89b4d6a",
            "9ff9f762ab8e4d799896bd7a076dcc62",
            "c56297bd321b4449bb3417bb14056f99",
            "2b3b6d5112d849808328064301c54043",
            "b25f5c2839a441b89d956388bae8671b",
            "c8d0f972937443df86c046c5fac48036",
            "dea14f2b97b8496dbcfd30a1bde8ba1a",
            "54caed64fa214117966f4e064f8f9f50",
            "e50da815fbe040e5aa64c04aac264700"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/647 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "019a29f1b10145c8abc20308424e20ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3892: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e7407be543141a5b2157b3026af7bfd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/203 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6394854b894b4ed08ea6a7d7aebda655"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare Data for Training"
      ],
      "metadata": {
        "id": "JZ1r9jZrKK54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BART generation config parameters\n",
        "forbidden_begin_tokens = [tokenizer.convert_tokens_to_ids('We')]\n",
        "\n",
        "forbidden_tokens = [\n",
        "     tokenizer.convert_tokens_to_ids('ĠPro'),\n",
        "     tokenizer.convert_tokens_to_ids('ĠIntrodu')]\n",
        "\n",
        "BART_generation_parameters = {\n",
        "    'max_length' : 150,\n",
        "    'min_length' : 60,\n",
        "    'length_penalty' : 2.0,\n",
        "    'do_sample' : True,\n",
        "    'num_beams' : 4,\n",
        "    'temperature' : 0.5,\n",
        "    'begin_suppress_tokens' : forbidden_begin_tokens,\n",
        "    'suppress_tokens' : forbidden_tokens,\n",
        "    'repetition_penalty' : 1.8,\n",
        "    'no_repeat_ngram_size' : 3\n",
        "}\n",
        "\n",
        "\n",
        "# Training hyper-parameters\n",
        "epochs = 10\n",
        "batch_size = 8\n",
        "learning_rate = 2e-5\n",
        "weight_decay = 0.01"
      ],
      "metadata": {
        "id": "1kcRzvxBzes6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BART Base-Model\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_name,\n",
        "                                                **BART_generation_parameters)\n",
        "\n",
        "\n",
        "if not model.generation_config.do_sample:\n",
        "  model.generation_config.num_beam_groups = 4\n",
        "  model.generation_config.diversity_penalty = 0.5\n",
        "\n",
        "use_XLA = False\n",
        "if use_XLA:\n",
        "  model.generation_config.no_repeat_ngram_size = 0 # In order to use XLA Generation\n",
        "\n",
        "print(model.generation_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mcl-QF2twE6j",
        "outputId": "ca6c02c3-72d7-492a-915a-8679e253d14a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBartForConditionalGeneration.\n",
            "\n",
            "All the weights of TFBartForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GenerationConfig {\n",
            "  \"begin_suppress_tokens\": [\n",
            "    170\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"do_sample\": true,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"length_penalty\": 2.0,\n",
            "  \"max_length\": 150,\n",
            "  \"min_length\": 60,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"repetition_penalty\": 1.8,\n",
            "  \"suppress_tokens\": [\n",
            "    1698,\n",
            "    32687\n",
            "  ],\n",
            "  \"temperature\": 0.5\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data collator for Sequence to Sequence models like BART\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"np\", padding=True)\n",
        "\n",
        "if use_XLA:\n",
        "  generation_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"np\", pad_to_multiple_of=128)\n",
        "else:\n",
        "  generation_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"np\", padding=True)"
      ],
      "metadata": {
        "id": "I5X0CdWU3Z2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare datasets for training\n",
        "train_dataset = model.prepare_tf_dataset(\n",
        "    tokenized_data['train'],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=data_collator,\n",
        "    drop_remainder=False,\n",
        ")\n",
        "\n",
        "validation_dataset = model.prepare_tf_dataset(\n",
        "    tokenized_data['validation'],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=data_collator\n",
        ")\n",
        "\n",
        "generation_dataset = model.prepare_tf_dataset(\n",
        "    tokenized_data['validation'],\n",
        "    batch_size=2*batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=generation_data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "OQiVB8may_xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "optimizer = AdamWeightDecay(\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay_rate=weight_decay\n",
        ")\n",
        "\n",
        "model.compile(optimizer=optimizer)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftwsFHUAEfUT",
        "outputId": "7770d2a7-9369-417f-cd64-f736d369caf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_bart_for_conditional_generation\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " model (TFBartMainLayer)     multiple                  139420416 \n",
            "                                                                 \n",
            " final_logits_bias (BiasLay  multiple                  50265     \n",
            " er)                                                             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 139470681 (532.04 MB)\n",
            "Trainable params: 139420416 (531.85 MB)\n",
            "Non-trainable params: 50265 (196.35 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "\n",
        "metric_callback = KerasMetricCallback(\n",
        "    metric_fn,\n",
        "    eval_dataset=generation_dataset,\n",
        "    predict_with_generate=True,\n",
        "    use_xla_generation=use_XLA\n",
        ")\n",
        "\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=save_path+\"/weights.h5\",\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True,\n",
        "    mode='min',\n",
        ")\n",
        "\n",
        "stop_early = EarlyStopping(monitor='val_loss', patience=3)"
      ],
      "metadata": {
        "id": "YLOqj07QtPLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [metric_callback,\n",
        "             stop_early,\n",
        "             checkpoint_callback]\n",
        "\n",
        "# Train\n",
        "print('[INFO: fine-tuning model...]')\n",
        "H = model.fit(train_dataset,\n",
        "              validation_data=validation_dataset,\n",
        "              epochs=epochs, callbacks=callbacks)\n",
        "\n",
        "# Save the model and tokenizer to a directory\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-fa8UHNoaZn",
        "outputId": "165c4aba-fc55-49c2-d3e4-54a41d7d6583"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO: fine-tuning model...]\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function infer_framework at 0x7d8e5695d6c0> and will run it as-is.\n",
            "Cause: for/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function infer_framework at 0x7d8e5695d6c0> and will run it as-is.\n",
            "Cause: for/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "81/81 [==============================] - 4104s 50s/step - loss: 3.8688 - val_loss: 3.3719 - rouge1: 39.2353 - rouge2: 10.1921 - rougeL: 22.2063 - rougeLsum: 32.0559 - gen_len: 86.5864\n",
            "Epoch 2/10\n",
            "81/81 [==============================] - 3653s 45s/step - loss: 3.5389 - val_loss: 3.3010 - rouge1: 39.3726 - rouge2: 10.5648 - rougeL: 22.4130 - rougeLsum: 32.1531 - gen_len: 84.8519\n",
            "Epoch 3/10\n",
            "81/81 [==============================] - 3281s 41s/step - loss: 3.3532 - val_loss: 3.2627 - rouge1: 39.5196 - rouge2: 10.8404 - rougeL: 22.6945 - rougeLsum: 32.3229 - gen_len: 83.2654\n",
            "Epoch 4/10\n",
            "81/81 [==============================] - 3475s 43s/step - loss: 3.2109 - val_loss: 3.2532 - rouge1: 39.6113 - rouge2: 10.6516 - rougeL: 22.5902 - rougeLsum: 32.1820 - gen_len: 82.9136\n",
            "Epoch 5/10\n",
            "81/81 [==============================] - 3333s 41s/step - loss: 3.0813 - val_loss: 3.2428 - rouge1: 40.2920 - rouge2: 10.7273 - rougeL: 22.6018 - rougeLsum: 32.7908 - gen_len: 82.3951\n",
            "Epoch 6/10\n",
            "81/81 [==============================] - 3316s 41s/step - loss: 2.9701 - val_loss: 3.2385 - rouge1: 40.3328 - rouge2: 10.6940 - rougeL: 22.6790 - rougeLsum: 32.5761 - gen_len: 80.4938\n",
            "Epoch 7/10\n",
            "81/81 [==============================] - 3400s 42s/step - loss: 2.8622 - val_loss: 3.2454 - rouge1: 39.8963 - rouge2: 10.7066 - rougeL: 22.3823 - rougeLsum: 32.2690 - gen_len: 82.3951\n",
            "Epoch 8/10\n",
            "81/81 [==============================] - 3634s 45s/step - loss: 2.7686 - val_loss: 3.2587 - rouge1: 40.2235 - rouge2: 10.9267 - rougeL: 22.7431 - rougeLsum: 33.0138 - gen_len: 83.3951\n",
            "Epoch 9/10\n",
            "81/81 [==============================] - 3248s 40s/step - loss: 2.6739 - val_loss: 3.2882 - rouge1: 40.2523 - rouge2: 10.8509 - rougeL: 22.5084 - rougeLsum: 33.1142 - gen_len: 82.6543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/VIU/TFM/Desarrollo//Results/TLDR/BART/model_save/sampling-norep-v4/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/VIU/TFM/Desarrollo//Results/TLDR/BART/model_save/sampling-norep-v4/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/VIU/TFM/Desarrollo//Results/TLDR/BART/model_save/sampling-norep-v4/vocab.json',\n",
              " '/content/drive/MyDrive/VIU/TFM/Desarrollo//Results/TLDR/BART/model_save/sampling-norep-v4/merges.txt',\n",
              " '/content/drive/MyDrive/VIU/TFM/Desarrollo//Results/TLDR/BART/model_save/sampling-norep-v4/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save training history\n",
        "with open(save_path + 'training_history.json', 'w') as file:\n",
        "    json.dump(H.history, file)"
      ],
      "metadata": {
        "id": "9HMOzV0tMAdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all files in the source folder\n",
        "weights_last_epoch = 'tf_model.h5'\n",
        "\n",
        "source_file_path = os.path.join(save_path, weights_last_epoch)\n",
        "os.makedirs(save_path + 'last_epoch/')\n",
        "destination_file_path = os.path.join(save_path, 'last_epoch/', weights_last_epoch)\n",
        "shutil.move(source_file_path, destination_file_path)\n",
        "\n",
        "print(f\"File {weights_last_epoch} moved from {source_file_path} to {destination_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB0o_XV-BPLe",
        "outputId": "5f64ae63-3c6e-48f0-f4fe-f6bb4f01050b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File tf_model.h5 moved from /content/drive/MyDrive/VIU/TFM/Desarrollo//Results/TLDR/BART/model_save/sampling-norep-v4/tf_model.h5 to /content/drive/MyDrive/VIU/TFM/Desarrollo//Results/TLDR/BART/model_save/sampling-norep-v4/last_epoch/tf_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change name\n",
        "original_path = save_path + '/weights.h5'\n",
        "new_name = 'tf_model.h5'\n",
        "\n",
        "# Create the new file path\n",
        "new_path = os.path.join(os.path.dirname(original_path), new_name)\n",
        "\n",
        "# Rename the file\n",
        "os.rename(original_path, new_path)\n",
        "\n",
        "print(f\"File weights.h5 renamed as {new_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26nxeyrWC6RN",
        "outputId": "c9dfef50-7ba3-4a19-f217-4b58a5c6a606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File weights.h5 renamed as tf_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_graphics(H)\n",
        "plt.savefig(save_path + '/history.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "N1nzU8JqwmtZ",
        "outputId": "ff899fd2-1fdb-4024-8ad2-2a7068688700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## T5"
      ],
      "metadata": {
        "id": "k9aB2nco5LxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'google-t5/t5-small'\n",
        "max_input_length = 512\n",
        "\n",
        "save_name = 'sampling-norep-v1/'\n",
        "save_path = BASE_PATH + '/Results/TLDR/T5/model_save/' + save_name"
      ],
      "metadata": {
        "id": "Lfg9uUqr5ZSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prepare Data for Tokenization"
      ],
      "metadata": {
        "id": "_Xx4VGg82HL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize data\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name, errors='ignore')\n",
        "prefix = 'summarize: '\n",
        "\n",
        "# Function in order to tokenize source and targe\n",
        "\n",
        "def tokenize_function(data):\n",
        "  inputs = [prefix + input for input in data['extractive_summary']]\n",
        "  model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, padding=True)\n",
        "\n",
        "  with tokenizer.as_target_tokenizer():\n",
        "    labels = tokenizer(data['target'], padding=True)\n",
        "\n",
        "  # The target input_ids tokens are added to the model inputs\n",
        "  model_inputs['labels'] = labels['input_ids']\n",
        "  return model_inputs\n",
        "\n",
        "tokenized_data = raw_data.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412,
          "referenced_widgets": [
            "7cd824d319bd41f1ab451a35e350bcd9",
            "d11a588d2b08407a998f1a8fe87c85f2",
            "a8957bb5aec14d018717749e5f2bf56f",
            "1feee70235aa41d2bc884f5e451f2e47",
            "9b4a75ac6b9b41f5934db2f58d88acbd",
            "22cc4157957d43e481cd5c78190020d3",
            "e2891dcf221c4b939253574d485eca14",
            "4888a2f3786e478f81ee225cdb660977",
            "e8a0e297ac004fb49487524b0d2afee5",
            "fd99be58c0584f90ab25f81156e38b6f",
            "f3c9497e4cb44bf491ebebbfb1570246",
            "ea3f01eca525475786c05d7747ebb259",
            "e8644b943c844aa1a96933a34c177eed",
            "28a4f11edc0b4891a8ec4a4def97f82f",
            "28267a69904a40fb8bee9f3cc5985c32",
            "df3d640f660c4313a4f3caa1def94031",
            "eba9d34b5f5a4c59a0c6fe36591586a3",
            "6cdfa1948fd240ef834893400687854b",
            "36b99122c96a46669e7ec15110da2c76",
            "6c850446bc854ba59277cb710521aac7",
            "fe9201c1f5034322a804642d4b8c24fd",
            "1ef37ae55d8f4c3799f7157e97e63e15",
            "48ccb275c1c54a52aa0e6dd5a8b20061",
            "9a4244596c4740909a3d3c1e4641ff95",
            "3dba0693ae4949de864931dff86e4cf8",
            "4af6e28d76034bafb1ab806778f32d3e",
            "f3389674c20b4089b0740860824aa4fd",
            "d9e2093edfbf46079c62ba9acd0c731b",
            "16518ed1aa224d59b7bf02dc4fbf42a8",
            "c2bba5e942d94a76a7076a23b6233e12",
            "4c3db9ff82c1466490f1d79c41f810ad",
            "7642d7ed62194028b113c9c52b13282c",
            "4703db19fd39400c9730b4d58b8c7244",
            "b73e2b36234942a1a444685d154b0a28",
            "f398b65a3b9d46c8a3251ce1f9dd9b15",
            "bf941671e3754310943d1a9b55efbed1",
            "f79cd33c036b46f4b8be296502a919e1",
            "4438a82fd04c4d878be7c071b177841b",
            "f80e15c1b0f64e3f8c37cfb2f98c42b8",
            "473494171ea94d8c931dae7c13843443",
            "5bed0e0341d546b1b83a1de3ac08f41c",
            "db4d0618596c4404abfac4c67f8a3fdf",
            "602dc082c30144939220912b49243280",
            "fb97e778d5b1408388cecd12801f095a",
            "0d6cfb420aaa46129398217426697252",
            "87e15a5d6b6e4f929c3958fb72a95703",
            "3374ac16e49f4906ad48aa0a299abc18",
            "a3d868187b574662a58d26e3862a56e8",
            "8f4ad1598d7746019905d090be8780e1",
            "55146773c79b480a855bae1a7ff3b1dd",
            "d82b49f6f6ee4f25bdd373b9024735d7",
            "da821d597a9946999b2360e0ac0c32bc",
            "1d61df4623da43c5957c2c2aa956bf90",
            "c0c97490bf4e4d8d80d467fa347fc4fd",
            "a560d88b15ae41309069e75c6d257174",
            "bf75e87292774d638d83f63d8bea1a5a",
            "e9418ae533924330a790a6bfeadec59e",
            "a381a311e36e40f8a0f6f1f665da3d0d",
            "2f263e4031594056ac8cf92e07ddc2ce",
            "1b5bbfb3591b4911b90071c971fd765f",
            "d0fe8feb4386497888f5ba22f6192a0e",
            "8b685f4ae450405ba6dd80284e894008",
            "3c8bf63efa284f2c89cc83aab2d3c1b9",
            "4a635e300eb04e1a9d79915bcfe36b85",
            "73c2adc886454979b2cbca484512f4cb",
            "72546f7ba1e641d59b29f9c5dd4a7c53"
          ]
        },
        "id": "gjHkaqLO5LXt",
        "outputId": "7c1e8c4c-29a3-4a51-a466-e368b48cb63b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7cd824d319bd41f1ab451a35e350bcd9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea3f01eca525475786c05d7747ebb259"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48ccb275c1c54a52aa0e6dd5a8b20061"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/647 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b73e2b36234942a1a444685d154b0a28"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3892: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d6cfb420aaa46129398217426697252"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/203 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf75e87292774d638d83f63d8bea1a5a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# T5 generation config parameters\n",
        "forbidden_begin_tokens = [tokenizer.convert_tokens_to_ids('We')]\n",
        "\n",
        "forbidden_tokens = [\n",
        "     tokenizer.convert_tokens_to_ids('ĠPro'),\n",
        "     tokenizer.convert_tokens_to_ids('ĠIntrodu')]\n",
        "\n",
        "forbidden_words = ['We', 'we', 'propose', 'Proposes']\n",
        "\n",
        "T5_generation_parameters = {\n",
        "    'max_length' : 100,\n",
        "    'min_length' : 60,\n",
        "    'length_penalty' : 2.0,\n",
        "    'num_beams' : 4,\n",
        "    'do_sample' : True,\n",
        "    'temperature' : 0.5,\n",
        "    'bad_words_ids' : tokenizer(forbidden_words,\n",
        "                                add_special_tokens=False).input_ids,\n",
        "    'repetition_penalty' : 1.8,\n",
        "    'no_repeat_ngram_size' : 3\n",
        "}\n",
        "\n",
        "\n",
        "# Training hyper-parameters\n",
        "epochs = 14\n",
        "batch_size = 8\n",
        "learning_rate = 2e-4\n",
        "weight_decay = 0.01"
      ],
      "metadata": {
        "id": "L20kOSF15lS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load T5 Base-Model\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_name,\n",
        "                                                **T5_generation_parameters)\n",
        "\n",
        "\n",
        "if not model.generation_config.do_sample:\n",
        "  model.generation_config.num_beam_groups = 4\n",
        "  model.generation_config.diversity_penalty = 0.5\n",
        "\n",
        "\n",
        "print(model.generation_config)\n",
        "\n",
        "use_XLA = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702,
          "referenced_widgets": [
            "78bf88677c924138b00b06f71c7d69a8",
            "0c02c0f802b340d9a8e6e29d95b08e43",
            "e7e011899aa7412494bd6f538f715166",
            "01dc4c08eeb646429535e62090051ad1",
            "de50e04035574ac2ba5dcb22f482b8ee",
            "8ee02a72c04544bfbe7d5f696386801f",
            "64c8f77917804ceea5b35eb074e358d7",
            "f89804a3b18448c1b95873ca9a4d15e3",
            "0b225a6d8e4349df8526c09e39041422",
            "e0b4722f85fc4de1bad9a5c33de311d7",
            "858b48f3ebdd4deab832fef2e456cbb9",
            "631a84f8b821400db639d3ceabd518b0",
            "e4d7c155d7f9467491d0a14e3438fb51",
            "4c42cd41dd6c4cd99f8fce765bdf0856",
            "01d584f403a54e2080d9a811f5feffcb",
            "9ba2653466b142af965e370c61b30923",
            "f41a8d0df7f84418801ead216cddb95b",
            "8964b5fe22b0453db3d8078cece80604",
            "4ddd0c94dc364b3187f1320b9c5a1a67",
            "4f065e23053d4b08a51eaf3d27a3cf02",
            "30d7be2904ca4979b2326dc2a73256b4",
            "3593c08e2aee408f9b45a4251aaf3acd"
          ]
        },
        "id": "sZ0geKLy5kaT",
        "outputId": "a9a6412c-c624-4af2-c47e-d8aba0588ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78bf88677c924138b00b06f71c7d69a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "631a84f8b821400db639d3ceabd518b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GenerationConfig {\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      101\n",
            "    ],\n",
            "    [\n",
            "      62\n",
            "    ],\n",
            "    [\n",
            "      4230\n",
            "    ],\n",
            "    [\n",
            "      13543,\n",
            "      32,\n",
            "      2260\n",
            "    ]\n",
            "  ],\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"length_penalty\": 2.0,\n",
            "  \"max_length\": 100,\n",
            "  \"min_length\": 60,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"repetition_penalty\": 1.8,\n",
            "  \"temperature\": 0.5\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare Data for Training"
      ],
      "metadata": {
        "id": "R4vyAkkv2PaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data collator for Sequence to Sequence models like BART\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"np\", padding=True, pad_to_multiple_of=128)\n",
        "\n",
        "if use_XLA:\n",
        "  generation_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"np\", pad_to_multiple_of=128)\n",
        "else:\n",
        "  generation_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"np\", padding=True, pad_to_multiple_of=128)"
      ],
      "metadata": {
        "id": "m1ygHfFP--H6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare datasets for training\n",
        "train_dataset = model.prepare_tf_dataset(\n",
        "    tokenized_data['train'],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=data_collator,\n",
        "    drop_remainder=False,\n",
        ")\n",
        "\n",
        "validation_dataset = model.prepare_tf_dataset(\n",
        "    tokenized_data['validation'],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=data_collator\n",
        ")\n",
        "\n",
        "generation_dataset = model.prepare_tf_dataset(\n",
        "    tokenized_data['validation'],\n",
        "    batch_size=2*batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=generation_data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "d8G2KNJn_A5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "optimizer = AdamWeightDecay(\n",
        "    learning_rate=learning_rate, weight_decay_rate=weight_decay\n",
        ")\n",
        "\n",
        "model.compile(optimizer=optimizer)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHtNgWTF_B29",
        "outputId": "21dc0fb9-505d-47d3-e24f-62fda333e84d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tft5_for_conditional_generation\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " shared (Embedding)          multiple                  16449536  \n",
            "                                                                 \n",
            " encoder (TFT5MainLayer)     multiple                  35330816  \n",
            "                                                                 \n",
            " decoder (TFT5MainLayer)     multiple                  41625344  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60506624 (230.81 MB)\n",
            "Trainable params: 60506624 (230.81 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "metric_callback = KerasMetricCallback(\n",
        "    metric_fn,\n",
        "    eval_dataset=generation_dataset,\n",
        "    predict_with_generate=True,\n",
        "    use_xla_generation=use_XLA\n",
        ")\n",
        "\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=save_path+\"/weights.h5\",\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True,\n",
        "    mode='min',\n",
        ")\n",
        "\n",
        "stop_early = EarlyStopping(monitor='val_loss', patience=3)"
      ],
      "metadata": {
        "id": "5ypB-dyF_JNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [metric_callback,\n",
        "             stop_early,\n",
        "             checkpoint_callback]\n",
        "\n",
        "# Train\n",
        "print('[INFO: fine-tuning model...]')\n",
        "H = model.fit(train_dataset, validation_data=validation_dataset, epochs=epochs, callbacks=callbacks)\n",
        "\n",
        "# Save the model and tokenizer to a directory\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyaSZ1H4_Ly1",
        "outputId": "b4fb5b9a-aabc-43e8-d60a-420b06bff833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO: fine-tuning model...]\n",
            "Epoch 1/14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function infer_framework at 0x7985c986b880> and will run it as-is.\n",
            "Cause: for/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function infer_framework at 0x7985c986b880> and will run it as-is.\n",
            "Cause: for/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "81/81 [==============================] - 2668s 32s/step - loss: 2.2905 - val_loss: 1.9812 - rouge1: 34.9863 - rouge2: 8.0734 - rougeL: 20.0793 - rougeLsum: 28.9358 - gen_len: 87.4815\n",
            "Epoch 2/14\n",
            "81/81 [==============================] - 2560s 32s/step - loss: 1.7611 - val_loss: 1.8934 - rouge1: 35.7379 - rouge2: 7.9414 - rougeL: 20.4990 - rougeLsum: 29.0202 - gen_len: 88.8272\n",
            "Epoch 3/14\n",
            "81/81 [==============================] - 2503s 31s/step - loss: 1.6744 - val_loss: 1.8576 - rouge1: 36.3178 - rouge2: 8.4594 - rougeL: 20.5589 - rougeLsum: 30.0522 - gen_len: 90.2654\n",
            "Epoch 4/14\n",
            "81/81 [==============================] - 2598s 32s/step - loss: 1.6163 - val_loss: 1.8377 - rouge1: 36.0608 - rouge2: 8.3480 - rougeL: 20.4621 - rougeLsum: 29.8468 - gen_len: 88.3765\n",
            "Epoch 5/14\n",
            "81/81 [==============================] - 2576s 32s/step - loss: 1.5715 - val_loss: 1.8257 - rouge1: 36.6286 - rouge2: 8.3081 - rougeL: 20.6753 - rougeLsum: 30.1969 - gen_len: 90.8025\n",
            "Epoch 6/14\n",
            "81/81 [==============================] - 2708s 34s/step - loss: 1.5285 - val_loss: 1.8218 - rouge1: 36.4586 - rouge2: 8.1229 - rougeL: 20.5036 - rougeLsum: 30.0398 - gen_len: 88.8642\n",
            "Epoch 7/14\n",
            "81/81 [==============================] - 2681s 33s/step - loss: 1.4913 - val_loss: 1.8140 - rouge1: 36.9434 - rouge2: 8.2459 - rougeL: 20.7880 - rougeLsum: 30.3181 - gen_len: 90.4568\n",
            "Epoch 8/14\n",
            "81/81 [==============================] - 2531s 32s/step - loss: 1.4540 - val_loss: 1.8204 - rouge1: 36.2859 - rouge2: 8.0618 - rougeL: 20.7384 - rougeLsum: 30.0183 - gen_len: 89.9198\n",
            "Epoch 9/14\n",
            "81/81 [==============================] - 2461s 31s/step - loss: 1.4180 - val_loss: 1.8207 - rouge1: 36.6906 - rouge2: 8.2546 - rougeL: 20.7312 - rougeLsum: 30.3023 - gen_len: 89.5617\n",
            "Epoch 10/14\n",
            "81/81 [==============================] - 2473s 31s/step - loss: 1.3832 - val_loss: 1.8265 - rouge1: 37.3137 - rouge2: 8.4947 - rougeL: 20.8898 - rougeLsum: 30.5271 - gen_len: 90.1975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 100, 'min_length': 60, 'do_sample': True, 'num_beams': 4, 'temperature': 0.5, 'repetition_penalty': 1.8, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'bad_words_ids': [[101], [62], [4230], [13543, 32, 2260]]}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/VIU/TFM/Desarrollo//Results/TLDR/T5/model_save/sampling-norep-v1/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/VIU/TFM/Desarrollo//Results/TLDR/T5/model_save/sampling-norep-v1/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/VIU/TFM/Desarrollo//Results/TLDR/T5/model_save/sampling-norep-v1/spiece.model',\n",
              " '/content/drive/MyDrive/VIU/TFM/Desarrollo//Results/TLDR/T5/model_save/sampling-norep-v1/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save training history\n",
        "with open(save_path + 'training_history.json', 'w') as file:\n",
        "    json.dump(H.history, file)"
      ],
      "metadata": {
        "id": "PBAOZb4e0e0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save graphics\n",
        "plot_graphics(H)\n",
        "plt.savefig(save_path + '/history.png')"
      ],
      "metadata": {
        "id": "cArEDqsN_SE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "gHCDrFwvNMKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select models\n",
        "name_models = {\n",
        "               'greedy-norep-v4' : 'greedy-norep-v4/',\n",
        "              'sampling-norep-v1' : 'sampling-norep-v1/'\n",
        "               }\n",
        "\n",
        "model = 'T5/'\n",
        "\n",
        "\n",
        "save_paths = {}\n",
        "models = {}\n",
        "figures = {}\n",
        "\n",
        "# Load weight models\n",
        "for name in name_models:\n",
        "  save_paths[name] = BASE_PATH + '/Results/TLDR/' + model + 'model_save/' + name_models[name]\n",
        "  models[name] = TFAutoModelForSeq2SeqLM.from_pretrained(save_paths[name])\n",
        "\n",
        "  with open(save_paths[name]+'training_history.json', 'r') as file:\n",
        "    figures[name] = json.load(file)\n",
        "\n",
        "  print(models[name].generation_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9Tjj2cjL2mE",
        "outputId": "855cfe7a-9428-476a-a1b9-f3bb6da69e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/VIU/TFM/Desarrollo//Results/TLDR/T5/model_save/greedy-norep-v4/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GenerationConfig {\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      101\n",
            "    ],\n",
            "    [\n",
            "      62\n",
            "    ],\n",
            "    [\n",
            "      4230\n",
            "    ],\n",
            "    [\n",
            "      13543,\n",
            "      32,\n",
            "      2260\n",
            "    ]\n",
            "  ],\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"diversity_penalty\": 0.5,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"length_penalty\": 2.0,\n",
            "  \"max_length\": 100,\n",
            "  \"min_length\": 60,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beam_groups\": 4,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"repetition_penalty\": 1.8\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/VIU/TFM/Desarrollo//Results/TLDR/T5/model_save/sampling-norep-v1/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GenerationConfig {\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      101\n",
            "    ],\n",
            "    [\n",
            "      62\n",
            "    ],\n",
            "    [\n",
            "      4230\n",
            "    ],\n",
            "    [\n",
            "      13543,\n",
            "      32,\n",
            "      2260\n",
            "    ]\n",
            "  ],\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"length_penalty\": 2.0,\n",
            "  \"max_length\": 100,\n",
            "  \"min_length\": 60,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"repetition_penalty\": 1.8,\n",
            "  \"temperature\": 0.5\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # Plot training history\n",
        "\n",
        "  def plot_graphics_json(H, save_path):\n",
        "\n",
        "    # Create a figure with 1 row and 2 columns, and set the figure size\n",
        "    fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
        "\n",
        "    # Finding the minimum value and its index\n",
        "    x = np.arange(0, len(H[\"loss\"]))\n",
        "    min_y = min(H[\"val_loss\"])\n",
        "    min_index = H[\"val_loss\"].index(min_y)\n",
        "    min_x = x[min_index]\n",
        "\n",
        "    # Plot the training and validation loss for each epoch in the first subplot\n",
        "    ax[0].plot(x, H[\"loss\"], label=\"Training loss\")\n",
        "    ax[0].plot(x, H[\"val_loss\"], label=\"Validation loss\")\n",
        "\n",
        "    ax[0].axvline(x=min_x, color='gray', linestyle='--')\n",
        "\n",
        "    ax[0].set_xlabel('epoch')\n",
        "    ax[0].set_ylabel('loss')\n",
        "\n",
        "    ax[1].plot(x, H[\"rouge1\"], color = 'r', label=\"ROUGE-1\")\n",
        "    ax[1].plot(x, H[\"rougeL\"], color = 'g', label=\"ROUGE-L\")\n",
        "    ax[1].plot(x, H[\"rougeLsum\"], color = 'c', label=\"ROUGE-LSUM\")\n",
        "\n",
        "    ax[1].axvline(x=min_x, color='gray', linestyle='--', label='Final model')\n",
        "\n",
        "    ax[1].set_xlabel('epoch')\n",
        "    ax[1].set_ylabel('score')\n",
        "\n",
        "    fig.legend(loc='right',  bbox_to_anchor=(1.1, 0.5))\n",
        "\n",
        "    plt.savefig(save_path + '/final_history.png', bbox_inches='tight')"
      ],
      "metadata": {
        "id": "MY5jm-89uLi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name  = 'sampling-norep-v1'\n",
        "plot_graphics_json(figures[name],  save_paths[name])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "ZJBg2o2PtvM-",
        "outputId": "aee12550-7d3f-4f5e-f6c7-031baaeacf19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, it's time to evaluate the final test rouge scores for the model selected."
      ],
      "metadata": {
        "id": "We-Bh7BR2i5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'sampling-norep-v1'\n",
        "\n",
        "generated_summaries = []\n",
        "rouge_scores = []\n",
        "accumulated_metrics = {}\n",
        "\n",
        "n = len(tokenized_data['test']['input_ids'])\n",
        "batch_size = 2 # Must be greater than 1\n",
        "\n",
        "# Last batch is dropped (just one sample if batch_size=2) to average ROUGE scores properly\n",
        "for i in range(0, n-1, batch_size):\n",
        "  if i % 10 == 0:\n",
        "    print(f'[INFO]: {i}/{n-1}')\n",
        "\n",
        "\n",
        "  generated_ids = models[name].generate(tokenized_data['test']['input_ids'][i:i+batch_size],\n",
        "                                        generation_config=models[name].generation_config,\n",
        "                                        seed=42)\n",
        "\n",
        "  reference_labels = np.array(tokenized_data['test']['labels'][i:i+batch_size])\n",
        "  predicted_labels = np.array(generated_ids)\n",
        "\n",
        "  current_metrics = metric_fn((predicted_labels, reference_labels))\n",
        "  accumulated_metrics = {k : current_metrics.get(k, 0) + accumulated_metrics.get(k, 0) for k in current_metrics.keys()}\n",
        "\n",
        "  # Predicted summaries, keep the rouge scores\n",
        "  generated_summaries.append(tokenizer.batch_decode(generated_ids, skip_special_tokens=True))\n",
        "  rouge_scores.append(current_metrics)\n",
        "\n",
        "# Undo nested list\n",
        "generated_summaries = [summary for summaries in generated_summaries for summary in summaries]\n",
        "average_rouge_scores = {k : accumulated_metrics.get(k, 0)/len(range(0, n-1, batch_size)) for k in accumulated_metrics.keys()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EisXx8nuVDQ4",
        "outputId": "5be55d5e-9777-4f5f-900f-c5f9d3d57194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]: 0/202\n",
            "[INFO]: 10/202\n",
            "[INFO]: 20/202\n",
            "[INFO]: 30/202\n",
            "[INFO]: 40/202\n",
            "[INFO]: 50/202\n",
            "[INFO]: 60/202\n",
            "[INFO]: 70/202\n",
            "[INFO]: 80/202\n",
            "[INFO]: 90/202\n",
            "[INFO]: 100/202\n",
            "[INFO]: 110/202\n",
            "[INFO]: 120/202\n",
            "[INFO]: 130/202\n",
            "[INFO]: 140/202\n",
            "[INFO]: 150/202\n",
            "[INFO]: 160/202\n",
            "[INFO]: 170/202\n",
            "[INFO]: 180/202\n",
            "[INFO]: 190/202\n",
            "[INFO]: 200/202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some statistics and additional information is calculated in the cell below."
      ],
      "metadata": {
        "id": "mj5U_9gE22Yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "updated_data_test = data_test[:-1].reset_index(drop=True)\n",
        "updated_data_test['abstractive_summary'] = pd.Series(generated_summaries)\n",
        "\n",
        "updated_data_test['number_words_abstractive'] = count_words(updated_data_test, 'abstractive_summary')\n",
        "updated_data_test['length_difference'] = updated_data_test['number_words_target'] - updated_data_test['number_words_abstractive']\n",
        "\n",
        "# Save generated test summaries  with  their corresponding statistics\n",
        "updated_data_test.to_csv(save_path + '/updated_data_test.csv', index=False)\n",
        "\n",
        "summaries = updated_data_test[['target', 'abstractive_summary']]\n",
        "\n",
        "# Save only generated test summaries\n",
        "summaries.to_csv(save_path + '/summaries.csv', index=False)\n",
        "\n",
        "# Save test rouge scores\n",
        "with open(save_path + '/average_rouge_scores.json', 'w') as json_scores:\n",
        "    json.dump(average_rouge_scores, json_scores, indent=4)"
      ],
      "metadata": {
        "id": "ms1HilZokIQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "updated_data_test['length_difference'].describe()"
      ],
      "metadata": {
        "id": "Ul2eFAgQkNEI",
        "outputId": "2196e568-e518-4b0e-c14c-baec36bfae42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    202.000000\n",
              "mean       3.737624\n",
              "std       18.918665\n",
              "min      -39.000000\n",
              "25%      -10.000000\n",
              "50%        3.500000\n",
              "75%       16.750000\n",
              "max       64.000000\n",
              "Name: length_difference, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(average_rouge_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCZBrdBLBjv4",
        "outputId": "f1d6a207-9bec-44ab-edff-c93992cdf4aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': 38.73726111167284,\n",
              " 'rouge2': 9.64914695758525,\n",
              " 'rougeL': 21.640033099597005,\n",
              " 'rougeLsum': 31.792573147907817,\n",
              " 'gen_len': 89.3069306930693}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Appendix: Tables for documentation"
      ],
      "metadata": {
        "id": "yB--NPyvv5EA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cells only contain additional information for results presentation. A few statistics tables are generated in LaTeX format. Also some histograms and graphics whcih are shown in the final document are generated here."
      ],
      "metadata": {
        "id": "V4-LU7RP4VnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load selected models\n",
        "final_models = {\n",
        "                'BART/greedy-norep-v5' : 'BART/model_save/greedy-norep-v5/',\n",
        "                'BART/sampling-norep-v3' : 'BART/model_save/sampling-norep-v3/',\n",
        "                'T5/greedy-norep-v4' : 'T5/model_save/greedy-norep-v4/',\n",
        "                'T5/sampling-norep-v0' : 'T5/model_save/sampling-norep-v0/',\n",
        "               }\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/VIU/TFM/Desarrollo/\"\n",
        "\n",
        "\n",
        "save_paths = {}\n",
        "generation_config  = {}\n",
        "rouge_scores = {}\n",
        "data_test =  {}\n",
        "\n",
        "for name in final_models:\n",
        "  save_paths[name] = BASE_PATH + '/Results/TLDR/' + final_models[name]\n",
        "\n",
        "  with open(save_paths[name] + 'generation_config.json', 'r') as file:\n",
        "    generation_config[name] = json.load(file)\n",
        "\n",
        "  with open(save_paths[name] + 'average_rouge_scores.json', 'r') as file:\n",
        "    rouge_scores[name] = json.load(file)\n",
        "\n",
        "  data_test[name] = pd.read_csv(save_paths[name]+'updated_data_test.csv')"
      ],
      "metadata": {
        "id": "dw4jYBYYWZCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_params_df = pd.DataFrame(generation_config)\n",
        "generation_params_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "olsz_wOWz9V0",
        "outputId": "6ab0714d-92d0-449b-ba13-a45a7aeaed95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       BART/greedy-norep-v5 BART/sampling-norep-v3  \\\n",
              "_from_model_config                     True                   True   \n",
              "begin_suppress_tokens                 [170]                  [170]   \n",
              "bos_token_id                              0                      0   \n",
              "decoder_start_token_id                    2                      2   \n",
              "diversity_penalty                       0.7                    NaN   \n",
              "early_stopping                         True                   True   \n",
              "eos_token_id                              2                      2   \n",
              "forced_bos_token_id                       0                      0   \n",
              "forced_eos_token_id                       2                      2   \n",
              "length_penalty                          2.0                    2.0   \n",
              "max_length                              150                    150   \n",
              "min_length                               60                     60   \n",
              "no_repeat_ngram_size                      3                      3   \n",
              "num_beam_groups                           4                    NaN   \n",
              "num_beams                                 4                      4   \n",
              "pad_token_id                              1                      1   \n",
              "repetition_penalty                      1.3                    1.8   \n",
              "suppress_tokens               [1698, 32687]          [1698, 32687]   \n",
              "transformers_version                 4.35.2                 4.35.2   \n",
              "do_sample                               NaN                   True   \n",
              "temperature                             NaN                    0.5   \n",
              "bad_words_ids                           NaN                    NaN   \n",
              "\n",
              "                                              T5/greedy-norep-v4  \n",
              "_from_model_config                                          True  \n",
              "begin_suppress_tokens                                        NaN  \n",
              "bos_token_id                                                 NaN  \n",
              "decoder_start_token_id                                         0  \n",
              "diversity_penalty                                            0.5  \n",
              "early_stopping                                               NaN  \n",
              "eos_token_id                                                   1  \n",
              "forced_bos_token_id                                          NaN  \n",
              "forced_eos_token_id                                          NaN  \n",
              "length_penalty                                               2.0  \n",
              "max_length                                                   100  \n",
              "min_length                                                    60  \n",
              "no_repeat_ngram_size                                           3  \n",
              "num_beam_groups                                                4  \n",
              "num_beams                                                      4  \n",
              "pad_token_id                                                   0  \n",
              "repetition_penalty                                           1.8  \n",
              "suppress_tokens                                              NaN  \n",
              "transformers_version                                      4.38.2  \n",
              "do_sample                                                    NaN  \n",
              "temperature                                                  NaN  \n",
              "bad_words_ids           [[101], [62], [4230], [13543, 32, 2260]]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e59eb154-6130-4bd0-9059-f71f80af5d7a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BART/greedy-norep-v5</th>\n",
              "      <th>BART/sampling-norep-v3</th>\n",
              "      <th>T5/greedy-norep-v4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>_from_model_config</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>begin_suppress_tokens</th>\n",
              "      <td>[170]</td>\n",
              "      <td>[170]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bos_token_id</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>decoder_start_token_id</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diversity_penalty</th>\n",
              "      <td>0.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>early_stopping</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eos_token_id</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>forced_bos_token_id</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>forced_eos_token_id</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>length_penalty</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max_length</th>\n",
              "      <td>150</td>\n",
              "      <td>150</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min_length</th>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>no_repeat_ngram_size</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>num_beam_groups</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>num_beams</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pad_token_id</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>repetition_penalty</th>\n",
              "      <td>1.3</td>\n",
              "      <td>1.8</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>suppress_tokens</th>\n",
              "      <td>[1698, 32687]</td>\n",
              "      <td>[1698, 32687]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>transformers_version</th>\n",
              "      <td>4.35.2</td>\n",
              "      <td>4.35.2</td>\n",
              "      <td>4.38.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>do_sample</th>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>temperature</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bad_words_ids</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[[101], [62], [4230], [13543, 32, 2260]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e59eb154-6130-4bd0-9059-f71f80af5d7a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e59eb154-6130-4bd0-9059-f71f80af5d7a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e59eb154-6130-4bd0-9059-f71f80af5d7a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-97871e19-8df7-43ed-98d1-20369cd691ac\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-97871e19-8df7-43ed-98d1-20369cd691ac')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-97871e19-8df7-43ed-98d1-20369cd691ac button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "generation_params_df",
              "summary": "{\n  \"name\": \"generation_params_df\",\n  \"rows\": 22,\n  \"fields\": [\n    {\n      \"column\": \"BART/greedy-norep-v5\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BART/sampling-norep-v3\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T5/greedy-norep-v4\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
        "\n",
        "for name in final_models:\n",
        "  print(data_test[name].columns)\n",
        "  data_test[name]['compression_ratio'] = data_test[name]['number_words_source'] / data_test[name]['number_words_abstractive']\n",
        "  data_test[name]['source_words'] = data_test[name]['source'].apply(lambda x : set(x.lower().split()))\n",
        "  data_test[name]['summary_words'] = data_test[name]['abstractive_summary'].apply(lambda x : set(x.lower().split()))\n",
        "  data_test[name]['novel_words'] = list(data_test[name]['summary_words'] - data_test[name]['source_words'])\n",
        "  data_test[name]['number_novel_words'] = data_test[name]['novel_words'].apply(lambda x : len(x))\n",
        "\n",
        "  data_test[name] = data_test[name].drop(columns=['number_words_source','number_words_extractive'])\n",
        "  columns_titles = ['number_words_target', 'number_words_abstractive', 'length_difference', 'compression_ratio', 'number_novel_words']\n",
        "  data_test[name] = data_test[name].reindex(columns=columns_titles)\n",
        "  print(data_test[name].describe().to_latex())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJiFliIv0L-u",
        "outputId": "8a546be0-b329-49f2-cee1-76d861b70261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['source', 'paper_id', 'target', 'title', 'number_words_target',\n",
            "       'extractive_summary', 'number_words_source', 'number_words_extractive',\n",
            "       'abstractive_summary', 'number_words_abstractive', 'length_difference'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-179-a2d8b501f657>:14: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
            "  print(data_test[name].describe().to_latex())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\begin{tabular}{lrrrrr}\n",
            "\\toprule\n",
            "{} &  number\\_words\\_target &  number\\_words\\_abstractive &  length\\_difference &  compression\\_ratio &  number\\_novel\\_words \\\\\n",
            "\\midrule\n",
            "count &               202.00 &                    202.00 &             202.00 &             202.00 &              202.00 \\\\\n",
            "mean  &                68.08 &                     64.09 &               3.99 &              80.62 &                5.84 \\\\\n",
            "std   &                16.75 &                      7.95 &              19.49 &              31.47 &                2.64 \\\\\n",
            "min   &                40.00 &                     44.00 &             -39.00 &               1.97 &                0.00 \\\\\n",
            "25\\%   &                56.00 &                     58.00 &              -9.75 &              61.04 &                4.00 \\\\\n",
            "50\\%   &                67.00 &                     64.00 &               3.50 &              78.44 &                5.00 \\\\\n",
            "75\\%   &                78.00 &                     69.00 &              15.00 &              94.45 &                7.00 \\\\\n",
            "max   &               124.00 &                     87.00 &              67.00 &             200.43 &               16.00 \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\n",
            "Index(['source', 'paper_id', 'target', 'title', 'number_words_target',\n",
            "       'extractive_summary', 'number_words_source', 'number_words_extractive',\n",
            "       'abstractive_summary', 'number_words_abstractive', 'length_difference'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-179-a2d8b501f657>:14: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
            "  print(data_test[name].describe().to_latex())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\begin{tabular}{lrrrrr}\n",
            "\\toprule\n",
            "{} &  number\\_words\\_target &  number\\_words\\_abstractive &  length\\_difference &  compression\\_ratio &  number\\_novel\\_words \\\\\n",
            "\\midrule\n",
            "count &               202.00 &                    202.00 &             202.00 &             202.00 &              202.00 \\\\\n",
            "mean  &                68.08 &                     66.66 &               1.42 &              78.04 &                6.59 \\\\\n",
            "std   &                16.75 &                      9.85 &              18.73 &              32.97 &                2.99 \\\\\n",
            "min   &                40.00 &                     43.00 &             -39.00 &               2.18 &                1.00 \\\\\n",
            "25\\%   &                56.00 &                     60.00 &             -12.00 &              60.47 &                5.00 \\\\\n",
            "50\\%   &                67.00 &                     68.00 &               0.50 &              74.04 &                6.00 \\\\\n",
            "75\\%   &                78.00 &                     72.00 &              14.00 &              89.33 &                8.00 \\\\\n",
            "max   &               124.00 &                    107.00 &              53.00 &             208.87 &               20.00 \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\n",
            "Index(['source', 'paper_id', 'target', 'title', 'number_words_target',\n",
            "       'extractive_summary', 'number_words_source', 'number_words_extractive',\n",
            "       'abstractive_summary', 'number_words_abstractive', 'length_difference'],\n",
            "      dtype='object')\n",
            "\\begin{tabular}{lrrrrr}\n",
            "\\toprule\n",
            "{} &  number\\_words\\_target &  number\\_words\\_abstractive &  length\\_difference &  compression\\_ratio &  number\\_novel\\_words \\\\\n",
            "\\midrule\n",
            "count &               202.00 &                    202.00 &             202.00 &             202.00 &              202.00 \\\\\n",
            "mean  &                68.08 &                     62.95 &               5.13 &              82.81 &                5.19 \\\\\n",
            "std   &                16.75 &                      9.31 &              19.15 &              33.62 &                2.91 \\\\\n",
            "min   &                40.00 &                     40.00 &             -37.00 &               1.85 &                0.00 \\\\\n",
            "25\\%   &                56.00 &                     56.00 &              -8.75 &              64.65 &                3.00 \\\\\n",
            "50\\%   &                67.00 &                     64.00 &               5.00 &              79.24 &                5.00 \\\\\n",
            "75\\%   &                78.00 &                     70.00 &              17.00 &              96.96 &                7.00 \\\\\n",
            "max   &               124.00 &                     79.00 &              62.00 &             230.88 &               17.00 \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-179-a2d8b501f657>:14: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
            "  print(data_test[name].describe().to_latex())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Words distribution\n",
        "\n",
        "name = 'T5/greedy-norep-v4'\n",
        "\n",
        "my_bins = [i for i in range(40, 130, 4)]\n",
        "plt.figure()\n",
        "plt.hist(data_test[name]['number_words_target'], my_bins, edgecolor='black', alpha=0.5, label='Gold summary')\n",
        "plt.hist(data_test[name]['number_words_abstractive'], my_bins, edgecolor='black', alpha=0.5, label='Generated summary')\n",
        "\n",
        "\n",
        "plt.xlabel('Nº of words in summary')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "vyL_PWDnKM5s",
        "outputId": "84bb3118-48ce-4243-cc3e-d6e22f184c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x78a4a3a4cdc0>"
            ]
          },
          "metadata": {},
          "execution_count": 145
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Most frequent words\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "words = []\n",
        "counter = []\n",
        "corpus  =  ' '.join(list(data_test[name]['abstractive_summary']))\n",
        "corpus_list = word_tokenize(corpus)\n",
        "\n",
        "puntuaction_marks = [',', '.', ':', '?', '!', ';', ')', '(']\n",
        "\n",
        "freq = FreqDist(word.lower() for word in corpus_list\n",
        "                if word.lower() not in stop_words+puntuaction_marks)\n",
        "\n",
        "most_common_words =  pd.Series(freq).sort_values(ascending=False)\n",
        "top30 =  most_common_words[:30]\n",
        "\n",
        "palette = 'husl'\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "sns.barplot(x=top30.values,\n",
        "            y=top30.index,\n",
        "            palette=palette)\n",
        "\n",
        "plt.xlabel('N')\n",
        "plt.ylabel('Tokens')\n",
        "plt.title('Top 30 words')"
      ],
      "metadata": {
        "id": "FEBWxuS0NFEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final table\n",
        "final_table = pd.DataFrame(rouge_scores)\n",
        "final_table = final_table.T\n",
        "\n",
        "final_table['n_params'] = ['139M', '139M', '60M']\n",
        "final_table['compression ratio'] = [data_test[name]['compression_ratio'].mean() for name in final_models]\n",
        "final_table['novel words'] = [data_test[name]['number_novel_words'].mean() for name in final_models]\n",
        "\n",
        "final_table = final_table.T\n",
        "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
        "print(final_table.style.to_latex())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edPZfloPHfy6",
        "outputId": "92a79992-3f64-44aa-a934-5a57a239a22e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\begin{tabular}{llll}\n",
            " & BART/greedy-norep-v5 & BART/sampling-norep-v3 & T5/greedy-norep-v4 \\\\\n",
            "rouge1 & 39.552036 & 40.856417 & 38.481636 \\\\\n",
            "rouge2 & 10.255110 & 10.970411 & 9.184590 \\\\\n",
            "rougeL & 22.631975 & 22.930263 & 21.460161 \\\\\n",
            "rougeLsum & 32.693150 & 33.570501 & 31.353161 \\\\\n",
            "gen_len & 81.014851 & 84.831683 & 88.574257 \\\\\n",
            "n_params & 139M & 139M & 60M \\\\\n",
            "compression ratio & 2.066000 & 2.078371 & 2.108126 \\\\\n",
            "novel words & 5.836634 & 6.594059 & 5.188119 \\\\\n",
            "\\end{tabular}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# An example\n",
        "i = 3\n",
        "print('Title: \\n')\n",
        "print(data_test['BART/greedy-norep-v5'].title[i], '\\n\\n')\n",
        "print('Target: \\n')\n",
        "print(data_test['BART/greedy-norep-v5'].target[i], '\\n\\n')\n",
        "\n",
        "for name in final_models:\n",
        "  print(f'Model: {name} \\n')\n",
        "  print(data_test[name].abstractive_summary[i], '\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6OoPY1Vr58I",
        "outputId": "0bbba378-aa2b-49b8-bb9f-f01f235214ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: \n",
            "\n",
            "Learning to Make Analogies by Contrasting Abstract Relational Structure \n",
            "\n",
            "\n",
            "Target: \n",
            "\n",
            "The most robust capacity for analogical reasoning is induced when networks learn analogies by contrasting abstract relational structures in their input domains. The paper investigates the ability of a neural network to learn analogy, showing that a simple neural network is able to solve certain analogy problems This study describes an approach to train neural networks for analogical reasoning tasks, specifically considering visual analogy and symbolic analogies. \n",
            "\n",
            "\n",
            "Model: BART/greedy-norep-v5 \n",
            "\n",
            "A novel neural network architecture that can learn to make analogies with visual and symbolic inputs, but only if they are contrasted with alternative incorrect answers that are plausible at the level of relations rather than simple perceptual attributes. This work presents a novel approach to analogical reasoning in neural networks by proposing a new training regime for neural networks that is more naturalistic than human-like. \n",
            "\n",
            "\n",
            "Model: BART/sampling-norep-v3 \n",
            "\n",
            "A novel neural network architecture that learns to make analogies with visual and symbolic inputs. This paper proposes a new approach to learning to use visual analogy, which is based on the idea of associative reasoning. The authors propose an approach to solving visual analogy problems by using visual analogy as a method for generating representations of objects. \n",
            "\n",
            "\n",
            "Model: T5/greedy-norep-v4 \n",
            "\n",
            "An analogy-like model that learns from random candidates is perceptually plausible, so that the problem can be solved trivially by matching the correct answer to one of the answers. This work studies the problem of contrasting abstract relational structures in neural network architectures using an analogy regime and a novel approach to interpolation. The authors present a model for neural network learning from random candidate answers which uses a link between the two domains. \n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "authorship_tag": "ABX9TyOuzLNtd4t0fri4lz9MrYo7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "019a29f1b10145c8abc20308424e20ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87bd56f9f9db417c81d87b260e64717a",
              "IPY_MODEL_e953775064244191a3245084abd7b949",
              "IPY_MODEL_3e0d973080be48c3a61ca7bec49f30f0"
            ],
            "layout": "IPY_MODEL_32ac86f5ff984aedbefd8393f1953c92"
          }
        },
        "87bd56f9f9db417c81d87b260e64717a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_255e5a72897049f9b2d16f5f717a7abc",
            "placeholder": "​",
            "style": "IPY_MODEL_4edaa22c96884cf6a629cc6e8b277cbd",
            "value": "Map: 100%"
          }
        },
        "e953775064244191a3245084abd7b949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d41ba5b64e441caa852290dd525bf5e",
            "max": 647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb71b0e1b402499095482662879aeab5",
            "value": 647
          }
        },
        "3e0d973080be48c3a61ca7bec49f30f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_223fc245f51a45e39b4f896fab8b139a",
            "placeholder": "​",
            "style": "IPY_MODEL_578becc7bb2146c587dca97aea75ad16",
            "value": " 647/647 [00:03&lt;00:00, 163.54 examples/s]"
          }
        },
        "32ac86f5ff984aedbefd8393f1953c92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "255e5a72897049f9b2d16f5f717a7abc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4edaa22c96884cf6a629cc6e8b277cbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d41ba5b64e441caa852290dd525bf5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb71b0e1b402499095482662879aeab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "223fc245f51a45e39b4f896fab8b139a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "578becc7bb2146c587dca97aea75ad16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e7407be543141a5b2157b3026af7bfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcaa9abbccee4df0bdee6114eff41c45",
              "IPY_MODEL_61672ed9c6d74592a1a8b1c6a0b5fe9c",
              "IPY_MODEL_a7feab89338642ec8b2cd300bf1494bd"
            ],
            "layout": "IPY_MODEL_d6a8ec6ba5ad4b2cb30f24a0daa5fc94"
          }
        },
        "fcaa9abbccee4df0bdee6114eff41c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22130b81744c410093e46123bc3d58df",
            "placeholder": "​",
            "style": "IPY_MODEL_90a902c031ac467d9b1dd1096f161a83",
            "value": "Map: 100%"
          }
        },
        "61672ed9c6d74592a1a8b1c6a0b5fe9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03c6a89889cb44d98b1a9ce788088a10",
            "max": 162,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_505a0197233e4c5aa7c6e6e98e11e245",
            "value": 162
          }
        },
        "a7feab89338642ec8b2cd300bf1494bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ef4b357bbd64bdaa10197bae69d7bac",
            "placeholder": "​",
            "style": "IPY_MODEL_844f27566bfd47b187c53cf95f6892d2",
            "value": " 162/162 [00:01&lt;00:00, 141.59 examples/s]"
          }
        },
        "d6a8ec6ba5ad4b2cb30f24a0daa5fc94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22130b81744c410093e46123bc3d58df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90a902c031ac467d9b1dd1096f161a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03c6a89889cb44d98b1a9ce788088a10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "505a0197233e4c5aa7c6e6e98e11e245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ef4b357bbd64bdaa10197bae69d7bac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "844f27566bfd47b187c53cf95f6892d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6394854b894b4ed08ea6a7d7aebda655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9384ed494d04b6986b1288ef98535f3",
              "IPY_MODEL_5cafb00bc5174d908ebb62d3a89b4d6a",
              "IPY_MODEL_9ff9f762ab8e4d799896bd7a076dcc62"
            ],
            "layout": "IPY_MODEL_c56297bd321b4449bb3417bb14056f99"
          }
        },
        "b9384ed494d04b6986b1288ef98535f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b3b6d5112d849808328064301c54043",
            "placeholder": "​",
            "style": "IPY_MODEL_b25f5c2839a441b89d956388bae8671b",
            "value": "Map: 100%"
          }
        },
        "5cafb00bc5174d908ebb62d3a89b4d6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8d0f972937443df86c046c5fac48036",
            "max": 203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dea14f2b97b8496dbcfd30a1bde8ba1a",
            "value": 203
          }
        },
        "9ff9f762ab8e4d799896bd7a076dcc62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54caed64fa214117966f4e064f8f9f50",
            "placeholder": "​",
            "style": "IPY_MODEL_e50da815fbe040e5aa64c04aac264700",
            "value": " 203/203 [00:01&lt;00:00, 143.46 examples/s]"
          }
        },
        "c56297bd321b4449bb3417bb14056f99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b3b6d5112d849808328064301c54043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b25f5c2839a441b89d956388bae8671b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8d0f972937443df86c046c5fac48036": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dea14f2b97b8496dbcfd30a1bde8ba1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54caed64fa214117966f4e064f8f9f50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e50da815fbe040e5aa64c04aac264700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "919460898d50479dbacfd6b154432db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea0db1df40844b81926b993f912d3541",
              "IPY_MODEL_e43e0ce08f1e418893c90058d1d2fd6b",
              "IPY_MODEL_376b1761f5ed497482f4ee5f67ad0556"
            ],
            "layout": "IPY_MODEL_c1c512568fff4e17866a21a789a54bf0"
          }
        },
        "ea0db1df40844b81926b993f912d3541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c22a9d0db20343a084fa0eaf11f31bb9",
            "placeholder": "​",
            "style": "IPY_MODEL_522f6171ad5e4b3bb765f7e60fae426d",
            "value": "Downloading builder script: "
          }
        },
        "e43e0ce08f1e418893c90058d1d2fd6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94ab1479d9454e0b96125e141a2a7242",
            "max": 2169,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3a531e9408a4346a9be5ba5d0e2a20f",
            "value": 2169
          }
        },
        "376b1761f5ed497482f4ee5f67ad0556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d036d181946742c2878211e72e694b9d",
            "placeholder": "​",
            "style": "IPY_MODEL_4c5960b058154637abcb228b4edf1aec",
            "value": " 5.65k/? [00:00&lt;00:00, 422kB/s]"
          }
        },
        "c1c512568fff4e17866a21a789a54bf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c22a9d0db20343a084fa0eaf11f31bb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "522f6171ad5e4b3bb765f7e60fae426d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94ab1479d9454e0b96125e141a2a7242": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3a531e9408a4346a9be5ba5d0e2a20f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d036d181946742c2878211e72e694b9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c5960b058154637abcb228b4edf1aec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cd824d319bd41f1ab451a35e350bcd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d11a588d2b08407a998f1a8fe87c85f2",
              "IPY_MODEL_a8957bb5aec14d018717749e5f2bf56f",
              "IPY_MODEL_1feee70235aa41d2bc884f5e451f2e47"
            ],
            "layout": "IPY_MODEL_9b4a75ac6b9b41f5934db2f58d88acbd"
          }
        },
        "d11a588d2b08407a998f1a8fe87c85f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22cc4157957d43e481cd5c78190020d3",
            "placeholder": "​",
            "style": "IPY_MODEL_e2891dcf221c4b939253574d485eca14",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a8957bb5aec14d018717749e5f2bf56f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4888a2f3786e478f81ee225cdb660977",
            "max": 2324,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8a0e297ac004fb49487524b0d2afee5",
            "value": 2324
          }
        },
        "1feee70235aa41d2bc884f5e451f2e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd99be58c0584f90ab25f81156e38b6f",
            "placeholder": "​",
            "style": "IPY_MODEL_f3c9497e4cb44bf491ebebbfb1570246",
            "value": " 2.32k/2.32k [00:00&lt;00:00, 159kB/s]"
          }
        },
        "9b4a75ac6b9b41f5934db2f58d88acbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22cc4157957d43e481cd5c78190020d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2891dcf221c4b939253574d485eca14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4888a2f3786e478f81ee225cdb660977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8a0e297ac004fb49487524b0d2afee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd99be58c0584f90ab25f81156e38b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3c9497e4cb44bf491ebebbfb1570246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea3f01eca525475786c05d7747ebb259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8644b943c844aa1a96933a34c177eed",
              "IPY_MODEL_28a4f11edc0b4891a8ec4a4def97f82f",
              "IPY_MODEL_28267a69904a40fb8bee9f3cc5985c32"
            ],
            "layout": "IPY_MODEL_df3d640f660c4313a4f3caa1def94031"
          }
        },
        "e8644b943c844aa1a96933a34c177eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eba9d34b5f5a4c59a0c6fe36591586a3",
            "placeholder": "​",
            "style": "IPY_MODEL_6cdfa1948fd240ef834893400687854b",
            "value": "spiece.model: 100%"
          }
        },
        "28a4f11edc0b4891a8ec4a4def97f82f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36b99122c96a46669e7ec15110da2c76",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c850446bc854ba59277cb710521aac7",
            "value": 791656
          }
        },
        "28267a69904a40fb8bee9f3cc5985c32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe9201c1f5034322a804642d4b8c24fd",
            "placeholder": "​",
            "style": "IPY_MODEL_1ef37ae55d8f4c3799f7157e97e63e15",
            "value": " 792k/792k [00:00&lt;00:00, 12.5MB/s]"
          }
        },
        "df3d640f660c4313a4f3caa1def94031": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eba9d34b5f5a4c59a0c6fe36591586a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cdfa1948fd240ef834893400687854b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36b99122c96a46669e7ec15110da2c76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c850446bc854ba59277cb710521aac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe9201c1f5034322a804642d4b8c24fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ef37ae55d8f4c3799f7157e97e63e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48ccb275c1c54a52aa0e6dd5a8b20061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a4244596c4740909a3d3c1e4641ff95",
              "IPY_MODEL_3dba0693ae4949de864931dff86e4cf8",
              "IPY_MODEL_4af6e28d76034bafb1ab806778f32d3e"
            ],
            "layout": "IPY_MODEL_f3389674c20b4089b0740860824aa4fd"
          }
        },
        "9a4244596c4740909a3d3c1e4641ff95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9e2093edfbf46079c62ba9acd0c731b",
            "placeholder": "​",
            "style": "IPY_MODEL_16518ed1aa224d59b7bf02dc4fbf42a8",
            "value": "tokenizer.json: 100%"
          }
        },
        "3dba0693ae4949de864931dff86e4cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2bba5e942d94a76a7076a23b6233e12",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c3db9ff82c1466490f1d79c41f810ad",
            "value": 1389353
          }
        },
        "4af6e28d76034bafb1ab806778f32d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7642d7ed62194028b113c9c52b13282c",
            "placeholder": "​",
            "style": "IPY_MODEL_4703db19fd39400c9730b4d58b8c7244",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 47.0MB/s]"
          }
        },
        "f3389674c20b4089b0740860824aa4fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9e2093edfbf46079c62ba9acd0c731b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16518ed1aa224d59b7bf02dc4fbf42a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2bba5e942d94a76a7076a23b6233e12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c3db9ff82c1466490f1d79c41f810ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7642d7ed62194028b113c9c52b13282c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4703db19fd39400c9730b4d58b8c7244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b73e2b36234942a1a444685d154b0a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f398b65a3b9d46c8a3251ce1f9dd9b15",
              "IPY_MODEL_bf941671e3754310943d1a9b55efbed1",
              "IPY_MODEL_f79cd33c036b46f4b8be296502a919e1"
            ],
            "layout": "IPY_MODEL_4438a82fd04c4d878be7c071b177841b"
          }
        },
        "f398b65a3b9d46c8a3251ce1f9dd9b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f80e15c1b0f64e3f8c37cfb2f98c42b8",
            "placeholder": "​",
            "style": "IPY_MODEL_473494171ea94d8c931dae7c13843443",
            "value": "Map: 100%"
          }
        },
        "bf941671e3754310943d1a9b55efbed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bed0e0341d546b1b83a1de3ac08f41c",
            "max": 647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db4d0618596c4404abfac4c67f8a3fdf",
            "value": 647
          }
        },
        "f79cd33c036b46f4b8be296502a919e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_602dc082c30144939220912b49243280",
            "placeholder": "​",
            "style": "IPY_MODEL_fb97e778d5b1408388cecd12801f095a",
            "value": " 647/647 [00:02&lt;00:00, 218.96 examples/s]"
          }
        },
        "4438a82fd04c4d878be7c071b177841b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f80e15c1b0f64e3f8c37cfb2f98c42b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "473494171ea94d8c931dae7c13843443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bed0e0341d546b1b83a1de3ac08f41c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db4d0618596c4404abfac4c67f8a3fdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "602dc082c30144939220912b49243280": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb97e778d5b1408388cecd12801f095a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d6cfb420aaa46129398217426697252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87e15a5d6b6e4f929c3958fb72a95703",
              "IPY_MODEL_3374ac16e49f4906ad48aa0a299abc18",
              "IPY_MODEL_a3d868187b574662a58d26e3862a56e8"
            ],
            "layout": "IPY_MODEL_8f4ad1598d7746019905d090be8780e1"
          }
        },
        "87e15a5d6b6e4f929c3958fb72a95703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55146773c79b480a855bae1a7ff3b1dd",
            "placeholder": "​",
            "style": "IPY_MODEL_d82b49f6f6ee4f25bdd373b9024735d7",
            "value": "Map: 100%"
          }
        },
        "3374ac16e49f4906ad48aa0a299abc18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da821d597a9946999b2360e0ac0c32bc",
            "max": 162,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d61df4623da43c5957c2c2aa956bf90",
            "value": 162
          }
        },
        "a3d868187b574662a58d26e3862a56e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0c97490bf4e4d8d80d467fa347fc4fd",
            "placeholder": "​",
            "style": "IPY_MODEL_a560d88b15ae41309069e75c6d257174",
            "value": " 162/162 [00:00&lt;00:00, 228.75 examples/s]"
          }
        },
        "8f4ad1598d7746019905d090be8780e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55146773c79b480a855bae1a7ff3b1dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d82b49f6f6ee4f25bdd373b9024735d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da821d597a9946999b2360e0ac0c32bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d61df4623da43c5957c2c2aa956bf90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0c97490bf4e4d8d80d467fa347fc4fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a560d88b15ae41309069e75c6d257174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf75e87292774d638d83f63d8bea1a5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9418ae533924330a790a6bfeadec59e",
              "IPY_MODEL_a381a311e36e40f8a0f6f1f665da3d0d",
              "IPY_MODEL_2f263e4031594056ac8cf92e07ddc2ce"
            ],
            "layout": "IPY_MODEL_1b5bbfb3591b4911b90071c971fd765f"
          }
        },
        "e9418ae533924330a790a6bfeadec59e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0fe8feb4386497888f5ba22f6192a0e",
            "placeholder": "​",
            "style": "IPY_MODEL_8b685f4ae450405ba6dd80284e894008",
            "value": "Map: 100%"
          }
        },
        "a381a311e36e40f8a0f6f1f665da3d0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c8bf63efa284f2c89cc83aab2d3c1b9",
            "max": 203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a635e300eb04e1a9d79915bcfe36b85",
            "value": 203
          }
        },
        "2f263e4031594056ac8cf92e07ddc2ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73c2adc886454979b2cbca484512f4cb",
            "placeholder": "​",
            "style": "IPY_MODEL_72546f7ba1e641d59b29f9c5dd4a7c53",
            "value": " 203/203 [00:00&lt;00:00, 216.57 examples/s]"
          }
        },
        "1b5bbfb3591b4911b90071c971fd765f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0fe8feb4386497888f5ba22f6192a0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b685f4ae450405ba6dd80284e894008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c8bf63efa284f2c89cc83aab2d3c1b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a635e300eb04e1a9d79915bcfe36b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73c2adc886454979b2cbca484512f4cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72546f7ba1e641d59b29f9c5dd4a7c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78bf88677c924138b00b06f71c7d69a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c02c0f802b340d9a8e6e29d95b08e43",
              "IPY_MODEL_e7e011899aa7412494bd6f538f715166",
              "IPY_MODEL_01dc4c08eeb646429535e62090051ad1"
            ],
            "layout": "IPY_MODEL_de50e04035574ac2ba5dcb22f482b8ee"
          }
        },
        "0c02c0f802b340d9a8e6e29d95b08e43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ee02a72c04544bfbe7d5f696386801f",
            "placeholder": "​",
            "style": "IPY_MODEL_64c8f77917804ceea5b35eb074e358d7",
            "value": "config.json: 100%"
          }
        },
        "e7e011899aa7412494bd6f538f715166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f89804a3b18448c1b95873ca9a4d15e3",
            "max": 1206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b225a6d8e4349df8526c09e39041422",
            "value": 1206
          }
        },
        "01dc4c08eeb646429535e62090051ad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0b4722f85fc4de1bad9a5c33de311d7",
            "placeholder": "​",
            "style": "IPY_MODEL_858b48f3ebdd4deab832fef2e456cbb9",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 88.2kB/s]"
          }
        },
        "de50e04035574ac2ba5dcb22f482b8ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ee02a72c04544bfbe7d5f696386801f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64c8f77917804ceea5b35eb074e358d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f89804a3b18448c1b95873ca9a4d15e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b225a6d8e4349df8526c09e39041422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0b4722f85fc4de1bad9a5c33de311d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "858b48f3ebdd4deab832fef2e456cbb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "631a84f8b821400db639d3ceabd518b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4d7c155d7f9467491d0a14e3438fb51",
              "IPY_MODEL_4c42cd41dd6c4cd99f8fce765bdf0856",
              "IPY_MODEL_01d584f403a54e2080d9a811f5feffcb"
            ],
            "layout": "IPY_MODEL_9ba2653466b142af965e370c61b30923"
          }
        },
        "e4d7c155d7f9467491d0a14e3438fb51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f41a8d0df7f84418801ead216cddb95b",
            "placeholder": "​",
            "style": "IPY_MODEL_8964b5fe22b0453db3d8078cece80604",
            "value": "model.safetensors: 100%"
          }
        },
        "4c42cd41dd6c4cd99f8fce765bdf0856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ddd0c94dc364b3187f1320b9c5a1a67",
            "max": 242043056,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f065e23053d4b08a51eaf3d27a3cf02",
            "value": 242043056
          }
        },
        "01d584f403a54e2080d9a811f5feffcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30d7be2904ca4979b2326dc2a73256b4",
            "placeholder": "​",
            "style": "IPY_MODEL_3593c08e2aee408f9b45a4251aaf3acd",
            "value": " 242M/242M [00:01&lt;00:00, 167MB/s]"
          }
        },
        "9ba2653466b142af965e370c61b30923": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f41a8d0df7f84418801ead216cddb95b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8964b5fe22b0453db3d8078cece80604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ddd0c94dc364b3187f1320b9c5a1a67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f065e23053d4b08a51eaf3d27a3cf02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30d7be2904ca4979b2326dc2a73256b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3593c08e2aee408f9b45a4251aaf3acd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}